
<!DOCTYPE html>
<html lang="en">

<!-- Head -->
<head>

        <!-- Required metadata tags -->
        <meta charset="utf-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />

        <!-- Default metadata -->
    <meta name="author" content="Jerry Su" />
    <meta name="description" content="CLIP（Contrastive Language-Image Pretraining） Vision Vocabulary：CLIP的视觉字典是指该模型通过对比学习从大规模图像和文本数据中学到的关于图像的表示和语义信息的集合。 在训练过程中，CLIP学会了将图像嵌入（embed）到一个高维空间中，并在该空间中通过文本描述对图像进行分类或检索。这个视觉字 …" />
    <meta name="keywords" content="LLM">
<meta property="og:site_name" content="JERRYLSU" />
<meta property="og:title" content="CLIP" />
<meta property="og:description" content="CLIP（Contrastive Language-Image Pretraining） Vision Vocabulary：CLIP的视觉字典是指该模型通过对比学习从大规模图像和文本数据中学到的关于图像的表示和语义信息的集合。 在训练过程中，CLIP学会了将图像嵌入（embed）到一个高维空间中，并在该空间中通过文本描述对图像进行分类或检索。这个视觉字 …" />
<meta property="og:locale" content="en_US" />
<meta property="og:url" content="../articles/CLIP.html" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-01-04 11:17:17+08:00" />
<meta property="article:modified_time" content="" />
<meta property="article:author" content="../author/jerry-su.html">
<meta property="article:section" content="NLP" />
	<meta property="article:tag" content="LLM" />
	<meta property="og:image" content="../jerry.jpg">

        <!-- Site Claim -->


        <!-- Title -->
        <title>
    CLIP &ndash; JERRYLSU
        </title>
        
        <!-- Icon -->
        <link rel="shortcut icon" href="../favicon.ico" type="image/x-icon">
        <link rel="icon" href="../favicon.ico" type="image/x-icon">

        <!-- Search engine -->
            <meta name="robots" content="" />

        <!-- Feeds -->








        <!-- Styles -->
        <!--
        <link rel="stylesheet" href="https://ajax.aspnetcdn.com/ajax/bootstrap/4.3.1/css/bootstrap.min.css">
        -->
        <link rel="stylesheet" href="../theme/bootstrap/bootstrap.min.css">
        <!--
        <link rel="stylesheet" href="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.css">
        -->
            <link rel="stylesheet" href="../theme/extra/bootstrap-toc.min.css">
        <link rel="stylesheet" href="../theme/pygment/friendly.min.css">
        <!--
        <link rel="stylesheet" href="../theme/extra/admonition.min.css">
        -->
        <link rel="stylesheet" href="../theme/style.css">

        <!-- Google Analytics -->
<script>
(function(i, s, o, g, r, a, m) { i['GoogleAnalyticsObject'] = r;
    i[r] = i[r] || function() {
        (i[r].q = i[r].q || []).push(arguments) }, i[r].l = 1 * new Date();
    a = s.createElement(o), m = s.getElementsByTagName(o)[0];
    a.async = 1;
    a.src = g;
    m.parentNode.insertBefore(a, m) })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
ga('create', 'UA-42618265-2', 'auto');
ga('send', 'pageview');
</script>
        <!-- Google Global Site Tag -->

        <!-- Google Tag Manager -->

        <!-- Google Adsense -->

        <!-- Heap Analytic -->

        <!-- Piwik Tracking -->

        <!-- Matomo Tracking -->

</head>

<!-- Body -->
<body class="d-flex flex-column" data-spy="scroll" data-target="#toc" data-offset="0" style="position: relative;">
    <!-- Top anchor -->
    <a href="#" id="backToTop" style="display: none; z-index: 1;" title="Back to top"><span></span></a>

    <!-- Google tag manager -->

    <!-- Navigation -->
    <nav class="flex-shrink-0 navbar navbar-expand-md navbar-expand-lg navbar-dark bg-dark text-light shadow-sm">
        <!-- Logo -->
        <a class="navbar-brand" href="..">JERRYLSU.NET</a>

        <!-- Collapse button -->
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarMenu" aria-controls="navbarMenu" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon small"></span>
        </button>

        <!-- Collapsible content -->
        <div class="collapse navbar-collapse" id="navbarMenu">

            <!-- i18n subsites -->

            <!-- Page links -->
            <ul class="navbar-nav mr-auto text-center">
                <li class="nav-item ">                           
                    <a class="nav-link" href="..">
                        <svg class="nav-icon" xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24">
                            <path d="M21 13v10h-6v-6h-6v6h-6v-10h-3l12-12 12 12h-3zm-1-5.907v-5.093h-3v2.093l3 3z" fill="currentColor"></path>
                        </svg>
                        Home <span class="sr-only">(current)</span>
                    </a>
                </li>
                <li class="nav-item ">
                    <a class="nav-link" href="../categories.html">
                        <svg class="nav-icon" xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24">
                            <path d="M16 6h-8v-6h8v6zm-8 12h-8v6h8v-6zm16 0h-8v6h8v-6zm-11-7v-3h-2v3h-8v5h2v-3h14v3h2v-5h-8z" fill="currentColor"></path>
                        </svg>
                        Categories
                    </a>
                </li>
                <li class="nav-item ">
                    <a class="nav-link" href="../tags.html">
                        <svg class="nav-icon" xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24">
                            <path d="M10.605 0h-10.605v10.609l13.391 13.391 10.609-10.604-13.395-13.396zm-4.191 6.414c-.781.781-2.046.781-2.829.001-.781-.783-.781-2.048 0-2.829.782-.782 2.048-.781 2.829-.001.782.782.781 2.047 0 2.829z" fill="currentColor"></path>
                        </svg>
                        Tags
                    </a>
                </li>
                <li class="nav-item ">
                    <a class="nav-link" href="../archives.html">
                        <svg class="nav-icon" xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24">
                            <path d="M1.8 9l-.8-4h22l-.8 4h-2.029l.39-2h-17.122l.414 2h-2.053zm18.575-6l.604-2h-17.979l.688 2h16.687zm3.625 8l-2 13h-20l-2-13h24zm-8 4c0-.552-.447-1-1-1h-6c-.553 0-1 .448-1 1s.447 1 1 1h6c.553 0 1-.448 1-1z" fill="currentColor"></path>
                        </svg>
                        Archives
                    </a>
                </li>
                <li class="nav-item ">
                    <a class="nav-link" href="../pages/about.html">
                        <svg class="nav-icon" xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24">
                            <path d="M20.822 18.096c-3.439-.794-6.64-1.49-5.09-4.418 4.72-8.912 1.251-13.678-3.732-13.678-5.082 0-8.464 4.949-3.732 13.678 1.597 2.945-1.725 3.641-5.09 4.418-3.073.71-3.188 2.236-3.178 4.904l.004 1h23.99l.004-.969c.012-2.688-.092-4.222-3.176-4.935z" fill="currentColor"></path>
                        </svg>
                        About
                    </a>
                </li>
            </ul>

            <!-- Search form -->
            <form class="form-inline text-center" action="../search.html">
                <input class="form-control w-100 bg-dark text-light text-center border-0 p-2" type="text" name="q" pattern=".{3,}" title="At least 3 characters" required="" placeholder="Type here to search" aria-label="Search">
            </form>

            <!-- Social links -->
            <ul class="navbar-nav text-center">
                <li class="nav-item">
                    <a class="nav-link" href="">
                        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24">
                            <title>Facebook</title>
                            <path d="M12 0c-6.627 0-12 5.373-12 12s5.373 12 12 12 12-5.373 12-12-5.373-12-12-12zm3 8h-1.35c-.538 0-.65.221-.65.778v1.222h2l-.209 2h-1.791v7h-3v-7h-2v-2h2v-2.308c0-1.769.931-2.692 3.029-2.692h1.971v3z" fill="currentColor"></path>
                        </svg>
                    </a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="https://github.com/jerrylsu">
                        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24">
                            <title>Github</title>
                            <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z" fill="currentColor"></path>
                        </svg>
                    </a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="https://www.linkedin.com/in/jerrylsu">
                        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24">
                            <title>Linkedin</title>
                            <path d="M12 0c-6.627 0-12 5.373-12 12s5.373 12 12 12 12-5.373 12-12-5.373-12-12-12zm-2 16h-2v-6h2v6zm-1-6.891c-.607 0-1.1-.496-1.1-1.109 0-.612.492-1.109 1.1-1.109s1.1.497 1.1 1.109c0 .613-.493 1.109-1.1 1.109zm8 6.891h-1.998v-2.861c0-1.881-2.002-1.722-2.002 0v2.861h-2v-6h2v1.093c.872-1.616 4-1.736 4 1.548v3.359z" fill="currentColor"></path>
                        </svg>
                    </a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="https://twitter.com/Jerrylsu666">
                        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24">
                            <title>Twitter</title>
                            <path d="M12 0c-6.627 0-12 5.373-12 12s5.373 12 12 12 12-5.373 12-12-5.373-12-12-12zm6.066 9.645c.183 4.04-2.83 8.544-8.164 8.544-1.622 0-3.131-.476-4.402-1.291 1.524.18 3.045-.244 4.252-1.189-1.256-.023-2.317-.854-2.684-1.995.451.086.895.061 1.298-.049-1.381-.278-2.335-1.522-2.304-2.853.388.215.83.344 1.301.359-1.279-.855-1.641-2.544-.889-3.835 1.416 1.738 3.533 2.881 5.92 3.001-.419-1.796.944-3.527 2.799-3.527.825 0 1.572.349 2.096.907.654-.128 1.27-.368 1.824-.697-.215.671-.67 1.233-1.263 1.589.581-.07 1.135-.224 1.649-.453-.384.578-.87 1.084-1.433 1.489z" fill="currentColor"></path>
                        </svg>
                    </a>
                </li>
            </ul>
        </div>
    </nav>

    <!-- Full page -->
    <div class="flex-shrink-0 flex-grow-1">

        <!-- Header -->
        <header class="bg-dark text-light shadow-sm pt-3 pb-2">
	<div class="container">
		<h3 id="CLIP"><span class="caps">CLIP</span></h3>
		<p style="font-size:larger;"><h3 id="clipcontrastive-language-image-pretraining"><span class="caps">CLIP</span>（Contrastive Language-Image&nbsp;Pretraining）</h3>
<p><strong>Vision Vocabulary</strong>：CLIP的视觉字典是指该模型通过对比学习从大规模图像和文本数据中学到的关于图像的表示和语义信息的集合。<br>&nbsp;在训练过程中，CLIP学会了将图像嵌入（embed）到一个高维空间中，并在该空间中通过文本描述对图像进行分类或检索。这个视觉字 …</p></p>
        <div class="row mx-auto mt-3">
            <div class="col-xs-12 col-sm-12 col-md-6 text-left" style="padding: 0">
                <a href="../author/jerry-su.html" class="card-link">Jerry Su</a>
                <span class="card-link text-success">
                    <span class="post-date" title="Post date">Jan 04, 2024</span>
                    <span class="text-info modified-date" title="Updated date">
                            Jan 04, 2024
                    </span>
                </span>
                    <span class="card-link text-secondary" title="~709 words">3 mins</span>
            </div>
            <div class="col-xs-12 col-sm-12 col-md-6 text-right" style="padding: 0">
                <a class="badge badge-success" href="../category/nlp.html">nlp</a>
                    <a class="badge badge-info" href="../tag/llm.html">llm</a>
            </div>
        </div>
	</div>
        </header>

        <!-- Main -->
        <main class="py-3">
                <div class="container">
                    <!-- Sharing -->

                    <!-- Content -->
    <!-- 2 columns layout -->
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-10">

                <!-- Sharing -->
                    <div class="text-right mb-2 small" style="height: 26px">
                        <div class="addthis_inline_share_toolbox"></div>
                    </div>

                <!-- Article -->
                <h3 id="clipcontrastive-language-image-pretraining"><span class="caps">CLIP</span>（Contrastive Language-Image&nbsp;Pretraining）</h3>
<p><strong>Vision Vocabulary</strong>：CLIP的视觉字典是指该模型通过对比学习从大规模图像和文本数据中学到的关于图像的表示和语义信息的集合。<br>&nbsp;在训练过程中，CLIP学会了将图像嵌入（embed）到一个高维空间中，并在该空间中通过文本描述对图像进行分类或检索。这个视觉字典的结构是通过模型的架构和训练数据来定义的。</p>
<h2 id="1-data">1.&nbsp;Data</h2>
<h3 id="11-image_processor">1.1&nbsp;image_processor</h3>
<div class="highlight"><pre><span></span><code><span class="c1"># 1.The first processor, usually is the clip pretrained model (vit)</span>
<span class="c1"># 224*224</span>
<span class="c1"># image_processor do not used in opt</span>
<span class="kn">from</span> <span class="nn">transformers.models.clip.image_processing_clip</span> <span class="kn">import</span> <span class="n">CLIPImageProcessor</span><span class="o">.</span><span class="n">preprocess</span>
<span class="n">image_processor</span> <span class="o">=</span> <span class="n">CLIPImageProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;~/.cache/huggingface/hub/models-openai-clip-vit-large-patch14&quot;</span><span class="p">)</span>
<span class="n">processor</span> <span class="o">=</span> <span class="n">image_processor</span>          
<span class="n">image</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">&#39;pt&#39;</span><span class="p">)[</span><span class="s1">&#39;pixel_values&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># 2.The second processor_high, usually is the designed image encoder (sam/swin/cnn)</span>
<span class="c1"># 1024*1024</span>
<span class="kn">from</span> <span class="nn">vary.model.plug.transforms</span> <span class="kn">import</span> <span class="n">train_transform</span>
<span class="n">image_processor_high</span> <span class="o">=</span> <span class="n">train_transform</span>
<span class="n">processor_high</span> <span class="o">=</span> <span class="n">image_processor_high</span>
<span class="n">image_high</span> <span class="o">=</span> <span class="n">processor_high</span><span class="p">(</span><span class="n">image_high</span><span class="p">)</span>
</code></pre></div>

<h3 id="12-multimodal_processor">1.2&nbsp;multimodal_processor</h3>
<div class="highlight"><pre><span></span><code><span class="nt">&lt;image&gt;</span> -&gt; <span class="nt">&lt;img&gt;</span> + [<span class="nt">&lt;imgpad&gt;</span>] * 256 + <span class="nt">&lt;/img&gt;</span>
</code></pre></div>

<h3 id="13-token_processor">1.3&nbsp;token_processor</h3>
<div class="highlight"><pre><span></span><code><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Given a list of sources, each is a conversation list. This transform:</span>
<span class="sd">    1. Add signal &#39;### &#39; at the beginning each sentence, with end signal &#39;\n&#39;;</span>
<span class="sd">    2. Concatenate conversations together;</span>
<span class="sd">    3. Tokenize the concatenated conversation;</span>
<span class="sd">    4. Make a deepcopy as the target. Mask human words with IGNORE_INDEX.</span>
<span class="sd">    &quot;&quot;&quot;</span><span class="w"></span>
<span class="w">    </span><span class="n">DEFAULT_IM_START_TOKEN</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&lt;</span><span class="n">img</span><span class="o">&gt;</span><span class="w"></span>
<span class="w">    </span><span class="n">DEFAULT_IM_END_TOKEN</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&lt;/</span><span class="n">img</span><span class="o">&gt;</span><span class="w"></span>

<span class="w">    </span><span class="n">conversation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="w"></span>
<span class="w">        </span><span class="p">{</span><span class="w"></span>
<span class="w">            </span><span class="s1">&#39;from&#39;</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;human&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w">            </span><span class="s1">&#39;value&#39;</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;&lt;img&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;imgpad&gt;&lt;/img&gt;&#39;</span><span class="w"></span>
<span class="w">        </span><span class="p">},</span><span class="w"> </span>
<span class="w">        </span><span class="p">{</span><span class="w"></span>
<span class="w">            </span><span class="s1">&#39;from&#39;</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;gpt&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w">            </span><span class="s1">&#39;value&#39;</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;The man is sitting on top of piled objects or belongings loaded into the back of a pickup truck.&#39;</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="s1">&#39;from&#39;</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;human&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;value&#39;</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;Is the man holding anything in his hands?&#39;</span><span class="w"></span>
<span class="w">        </span><span class="p">},</span><span class="w"> </span>
<span class="w">        </span><span class="p">{</span><span class="w"></span>
<span class="w">            </span><span class="s1">&#39;from&#39;</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;gpt&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w">            </span><span class="s1">&#39;value&#39;</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;Yes, the man is holding a beer in his hand while sitting on top of the objects in the back of the pickup truck.&#39;</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="s1">&#39;from&#39;</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;human&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;value&#39;</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;What color is the pickup truck?&#39;</span><span class="w"></span>
<span class="w">        </span><span class="p">},</span><span class="w"> </span>
<span class="w">        </span><span class="p">{</span><span class="w"></span>
<span class="w">            </span><span class="s1">&#39;from&#39;</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;gpt&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w">            </span><span class="s1">&#39;value&#39;</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;The pickup truck is white.&#39;</span><span class="w"></span>
<span class="w">        </span><span class="p">},</span><span class="w"> </span>
<span class="w">        </span><span class="p">{</span><span class="w"></span>
<span class="w">            </span><span class="s1">&#39;from&#39;</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;human&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w">            </span><span class="s1">&#39;value&#39;</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;Is the man sitting or standing?&#39;</span><span class="w"></span>
<span class="w">        </span><span class="p">},</span><span class="w"> </span>
<span class="w">        </span><span class="p">{</span><span class="w"></span>
<span class="w">            </span><span class="s1">&#39;from&#39;</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;gpt&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w">            </span><span class="s1">&#39;value&#39;</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;The man is sitting on top of the piled objects in the back of the pickup truck.&#39;</span><span class="w"></span>
<span class="w">        </span><span class="p">},</span><span class="w"> </span>
<span class="w">        </span><span class="p">{</span><span class="w"></span>
<span class="w">            </span><span class="s1">&#39;from&#39;</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;human&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w">            </span><span class="s1">&#39;value&#39;</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;What could be the possible reasons for the man sitting on top of the possessions in the back of the pickup truck?&#39;</span><span class="w"></span>
<span class="w">        </span><span class="p">},</span><span class="w"> </span>
<span class="w">        </span><span class="p">{</span><span class="w"></span>
<span class="w">            </span><span class="s1">&#39;from&#39;</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;gpt&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w">            </span><span class="s1">&#39;value&#39;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;There could be several reasons for the man sitting on top of his possessions in the back of the pickup truck:</span><span class="se">\n\n</span><span class="s2">1. Moving: The man might be moving to a new location and needed to transport his items in a pickup truck, utilizing available space efficiently. By sitting on top of the belongings, he could be helping to stabilize and secure the items during the move, preventing them from falling or shifting during transportation.</span><span class="se">\n\n</span><span class="s2">2. Lack of seating: If the cab of the pickup truck is already at full capacity or there isn&#39;t enough space for him to sit inside, the man may have chosen to sit on his possessions as an alternative seating arrangement.</span><span class="se">\n\n</span><span class="s2">3. Road trip or outing: The man might be on a road trip or a casual outing with friends or family, where he is using the back of the pickup truck as an open-air seating area. By sitting on top of the loaded items, he may be enjoying the journey while savoring his beer.</span><span class="se">\n\n</span><span class="s2">4. Keeping an eye on belongings: The man could be safeguarding his possessions by staying close to them, ensuring that no items are lost, stolen or damaged during the journey.</span><span class="se">\n\n</span><span class="s2">Regardless of the specific reason, the image shows a person making the most of their situation, adding a touch of lightheartedness or adventure to an otherwise mundane scene.&quot;</span><span class="w"></span>
<span class="w">        </span><span class="p">}</span><span class="w"></span>
<span class="w">    </span><span class="p">]</span><span class="w"></span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">conversation</span><span class="p">[</span><span class="s2">&quot;value&quot;</span><span class="p">])</span> <span class="o">+</span> <span class="s2">&quot;&lt;/s&gt;&quot;</span>    <span class="c1"># # pseudo code</span>

<span class="n">tokenized_list</span> <span class="o">=</span> <span class="p">[</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">text</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;longest&quot;</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">,</span>
        <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">strings</span>
<span class="p">]</span>

<span class="c1"># input_ids = labels </span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">tokenized</span><span class="o">.</span><span class="n">input_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">tokenized</span> <span class="ow">in</span> <span class="n">tokenized_list</span>
<span class="p">]</span>

<span class="c1"># labels.repalce(&quot;...&quot;, -100)</span>
<span class="n">IGNORE_INDEX</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>
<span class="n">lables</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;&lt;imgpad&gt;&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">100</span><span class="p">)</span>  <span class="c1"># pseudo code</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>
</code></pre></div>

<h2 id="2model">2.Model</h2>
<h3 id="varyoptmodel-optmodel-optdecoder-optdecoderlayer">varyOPTModel -&gt; OPTModel -&gt; OPTDecoder -&gt;&nbsp;OPTDecoderLayer</h3>
<h3 id="21-varyoptmodel">2.1&nbsp;varyOPTModel</h3>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">varyOPTModel</span><span class="p">(</span><span class="n">OPTModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">OPTConfig</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">varyOPTModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">vision_tower</span> <span class="o">=</span> <span class="n">build_sam_vit_b</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mm_projector</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">768</span><span class="p">)</span>
</code></pre></div>

<h3 id="22-optmodel">2.2&nbsp;OPTModel</h3>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">OPTModel</span><span class="p">(</span><span class="n">OPTPreTrainedModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">OPTConfig</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">OPTDecoder</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</code></pre></div>

<h3 id="23-optdecoder">2.3&nbsp;OPTDecoder</h3>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">OPTDecoder</span><span class="p">(</span><span class="n">OPTPreTrainedModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transformer decoder consisting of *config.num_hidden_layers* layers. Each layer is a [`OPTDecoderLayer`]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embed_tokens</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">word_embed_proj_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embed_positions</span> <span class="o">=</span> <span class="n">OPTLearnedPositionalEmbedding</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">max_position_embeddings</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">OPTDecoderLayer</span><span class="p">(</span><span class="n">config</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">num_hidden_layers</span><span class="p">)])</span>
</code></pre></div>

<h3 id="24-optdecoderlayer">2.4&nbsp;OPTDecoderLayer</h3>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">OPTDecoderLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span> <span class="o">=</span> <span class="n">OPTAttention</span><span class="p">(</span>
            <span class="n">embed_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span>
            <span class="n">num_heads</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">attention_dropout</span><span class="p">,</span>
            <span class="n">is_decoder</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">bias</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">enable_bias</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">activation_fn</span> <span class="o">=</span> <span class="n">ACT2FN</span><span class="p">[</span><span class="n">config</span><span class="o">.</span><span class="n">activation_function</span><span class="p">]</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">self_attn_layer_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">layer_norm_elementwise_affine</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">ffn_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">enable_bias</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">ffn_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">enable_bias</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">final_layer_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">layer_norm_elementwise_affine</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1"># vision tower build as below!!!</span>
<span class="bp">self</span><span class="o">.</span><span class="n">vision_tower</span> <span class="o">=</span> <span class="n">build_sam_vit_b</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">build_sam_vit_b</span><span class="p">(</span><span class="n">checkpoint</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_build_sam</span><span class="p">(</span>
        <span class="n">encoder_embed_dim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
        <span class="n">encoder_depth</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">encoder_num_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">encoder_global_attn_indexes</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span>
        <span class="n">checkpoint</span><span class="o">=</span><span class="n">checkpoint</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">_build_sam</span><span class="p">(</span>
    <span class="n">encoder_embed_dim</span><span class="p">,</span>
    <span class="n">encoder_depth</span><span class="p">,</span>
    <span class="n">encoder_num_heads</span><span class="p">,</span>
    <span class="n">encoder_global_attn_indexes</span><span class="p">,</span>
<span class="p">):</span>
    <span class="n">prompt_embed_dim</span> <span class="o">=</span> <span class="mi">256</span>
    <span class="n">image_size</span> <span class="o">=</span> <span class="mi">1024</span>
    <span class="n">vit_patch_size</span> <span class="o">=</span> <span class="mi">16</span>

    <span class="c1"># This class of ImageEncoderViT and its supporting functions below lightly adapted from the ViTDet backbone available at: https://github.com/facebookresearch/detectron2/blob/main/detectron2/modeling/backbone/vit.py # noqa</span>

    <span class="n">image_encoder</span><span class="o">=</span><span class="n">ImageEncoderViT</span><span class="p">(</span>
            <span class="n">depth</span><span class="o">=</span><span class="n">encoder_depth</span><span class="p">,</span>
            <span class="n">embed_dim</span><span class="o">=</span><span class="n">encoder_embed_dim</span><span class="p">,</span>
            <span class="n">img_size</span><span class="o">=</span><span class="n">image_size</span><span class="p">,</span>
            <span class="n">mlp_ratio</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
            <span class="n">norm_layer</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">),</span>
            <span class="n">num_heads</span><span class="o">=</span><span class="n">encoder_num_heads</span><span class="p">,</span>
            <span class="n">patch_size</span><span class="o">=</span><span class="n">vit_patch_size</span><span class="p">,</span>
            <span class="n">qkv_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">use_rel_pos</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">global_attn_indexes</span><span class="o">=</span><span class="n">encoder_global_attn_indexes</span><span class="p">,</span>
            <span class="n">window_size</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span>
            <span class="n">out_chans</span><span class="o">=</span><span class="n">prompt_embed_dim</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">image_encoder</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1"># image embed + text embed</span>
<span class="n">input_embeds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                        <span class="p">(</span>
                            <span class="n">input_embeds</span><span class="p">[:</span><span class="n">image_start_token_pos</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> 
                            <span class="n">image_features</span><span class="p">,</span>    <span class="n">num_patches</span><span class="p">:</span> <span class="mi">256</span>
                            <span class="n">input_embeds</span><span class="p">[</span><span class="n">image_start_token_pos</span> <span class="o">+</span> <span class="n">num_patches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span>
                        <span class="p">),</span> 
                        <span class="n">dim</span><span class="o">=</span><span class="mi">0</span>
                    <span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">!</span><span class="n">jupyter</span> <span class="n">nbconvert</span> <span class="o">--</span><span class="n">to</span> <span class="n">markdown</span> <span class="mi">2024</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">04</span><span class="o">-</span><span class="n">Vary</span><span class="o">.</span><span class="n">ipynb</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="o">[</span><span class="n">NbConvertApp</span><span class="o">]</span><span class="w"> </span><span class="n">WARNING</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">Config</span><span class="w"> </span><span class="k">option</span><span class="w"> </span><span class="err">`</span><span class="n">kernel_spec_manager_class</span><span class="err">`</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">recognized</span><span class="w"> </span><span class="k">by</span><span class="w"> </span><span class="err">`</span><span class="n">NbConvertApp</span><span class="err">`</span><span class="p">.</span><span class="w"></span>
<span class="o">[</span><span class="n">NbConvertApp</span><span class="o">]</span><span class="w"> </span><span class="n">Converting</span><span class="w"> </span><span class="n">notebook</span><span class="w"> </span><span class="mi">2024</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">04</span><span class="o">-</span><span class="n">Vary</span><span class="p">.</span><span class="n">ipynb</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">markdown</span><span class="w"></span>
<span class="o">[</span><span class="n">NbConvertApp</span><span class="o">]</span><span class="w"> </span><span class="n">Writing</span><span class="w"> </span><span class="mi">10547</span><span class="w"> </span><span class="n">bytes</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="mi">2024</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">04</span><span class="o">-</span><span class="n">Vary</span><span class="p">.</span><span class="n">md</span><span class="w"></span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>
</code></pre></div>

                <!-- Neighbors -->
                    <br>
                    <b>Read more:</b><br>
<div class="pagination">
    <a class="w-50" href="../articles/Concurrent-http-requests-using-asyncio-and-aiohttp.html">
&ll; Concurrent http requests using asyncio and&nbsp;aiohttp
    </a>
    <a class="w-50 text-right" href="../articles/Nucleus Sampling Top-p Sampling.html">
        Nucleus Sampling Top-p&nbsp;Sampling &gg;    </a>
</div>
                <!-- Google Adsense -->
            </div>

            <!-- Sidebar -->
            <div class="col-md-2 d-none d-md-block small">
                <div class="sticky-top">
                    <!-- ToC -->
                    <nav id="toc" data-toggle="toc" ></nav>

                    <!-- Share post -->

                    <!-- Google Adsense -->
                </div>
            </div>
        </div>

    <!-- Releated posts -->
        <hr>
        <div>
            <h5>Related posts:</h5>
            <ul>
                <li><a href="../articles/GPT-Train.html"><span class="caps">GPT</span>&nbsp;Training</a></li>
                <li><a href="../articles/Nucleus Sampling Top-p Sampling.html">Nucleus Sampling Top-p&nbsp;Sampling</a></li>
                <li><a href="../articles/Self-Instruct.html"><span class="caps">SELF</span>-<span class="caps">INSTRUCT</span>: Aligning Language Model with Self Generated&nbsp;Instructions</a></li>
            </ul>
        </div>

    <!-- Comments -->
        <hr>
<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'jerrylsu-github-io';
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>                </div>
        </main>

    </div>

    <!-- Footer -->
    <footer class="flex-shrink-0 bg-dark text-light small py-1">
        <div class="container text-center">
            &copy; 2024 <a href="..">JERRYLSU</a> by <a href="../pages/about.html">JERRY</a>. Powered by <a href="http://getpelican.com">Pelican</a>, <a href="http://python.org">Python</a>, <a href="https://getbootstrap.com">Bootstrap 4</a><br>
            <!-- Do not remove below license sentence -->
            License: <a href="https://spdx.org/licenses/CC-BY-4.0.html">CC-BY-4.0</a>, based on <a href="https://github.com/vuquangtrong/simplify-theme">Simplify Bootstrap Theme</a>
        </div>
    </footer>

    <!-- Scripts -->
    <!--
    <script src="https://ajax.aspnetcdn.com/ajax/jQuery/jquery-3.4.1.min.js"></script>
    -->
    <script type="text/javascript" src="../theme/jquery/jquery-3.4.1.min.js"></script>
    <!--
    <script src="https://ajax.aspnetcdn.com/ajax/bootstrap/4.3.1/bootstrap.min.js"></script>
    -->
    <script type="text/javascript" src="../theme/bootstrap/bootstrap.min.js"></script>
    <!--
    <script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script>
    -->
        <script type="text/javascript" src="../theme/extra/bootstrap-toc.min.js"></script>
    <script type="text/javascript" src="../theme/style.js"></script>

    <!-- Sharing -->
        <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5d9ffca0db80069e"></script>

    <!-- JSON LD -->
<script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "name": "CLIP",
    "headline": "CLIP",
    "datePublished": "2024-01-04 11:17:17+08:00",
    "dateModified": "",
    "author": {
        "@type": "Person",
        "name": "Jerry Su",
        "url": "../author/jerry-su.html"
    },
    "image": "../jerry.jpg",
    "url": "../articles/CLIP.html",
    "description": "CLIP（Contrastive Language-Image Pretraining） Vision Vocabulary：CLIP的视觉字典是指该模型通过对比学习从大规模图像和文本数据中学到的关于图像的表示和语义信息的集合。 在训练过程中，CLIP学会了将图像嵌入（embed）到一个高维空间中，并在该空间中通过文本描述对图像进行分类或检索。这个视觉字 …"
}
</script>
    <!-- Disqus count -->
</body>

</html>