var tipuesearch = {"pages":[{"title":"Docker Python Mysql","text":"docker pull mysql:5.7 docker run -itd -p 8070:3306 -v /hadoop-data/work/sl/project/mysql/data:/var/lib/mysql -v /hadoop-data/work/sl/project/mysql/conf.d:/etc/mysql/conf.d --name=qa_mysql -e MYSQL_ROOT_PASSWORD=123456 mysql:5.7 mysql -h host_ip -P port -u root -p123456 show databases ; show tables from database_name ; # use database_name; show tables; show columns from table_name ; # desc table_name; seletc * from table_name limit n ; # head n row data select * from table_name where id = 0 ; # conditional search select count ( id ) from table_name ; # data total delete from table_name ; # delete table data 1. pymysql.err.DataError: (1366, \"Incorrect string value: â€˜\\xE5\\xA4\\xA9\\xE6\\xB9\\x96â€¦' for column â€˜question' at row 1\") åŸå› ï¼šç”±äºå»ºè¡¨çš„æ—¶å€™æ²¡æœ‰æŒ‡å®šæ•°æ®åº“å­—ç¬¦é›†, ä¿å­˜ä¸­æ–‡çš„æ—¶å€™å°±ä¼šæŠ¥é”™ï¼špymysql.err.InternalError: (1366, â€¦) mysql>ALTER TABLE your_table CONVERT TO CHARACTER SET utf8 COLLATE utf8_general_ci; or mysql>alter table è¡¨å convert to character set utf8mb4; 2.(2006, \"MySQL server has gone away (BrokenPipeError(32, â€˜Broken pipe'))\"); é»˜è®¤è¶…8å°æ—¶ï¼Œè¿æ¥è‡ªåŠ¨æ–­å¼€ def _is_alive ( self ) : \"\"\"æ£€æŸ¥è¿æ¥æ˜¯å¦å¤±æ´»\"\"\" try : self . conn . ping ( reconnect = True ) except : self . conn = pymysql . connect ( host = MYSQL_HOST , user = MYSQL_USER , port = MYSQL_PORT , password = MYSQL_PWD , database = MYSQL_DB , charset = 'utf8mb4' , local_infile = True ) self . cursor = self . conn . cursor ()","tags":"Programming","url":"articles/Docker-Python-Mysql.html","loc":"articles/Docker-Python-Mysql.html"},{"title":"Docker build","text":"é—®é¢˜æè¿°ï¼š >>> docker build - t image_name : v1 . Sending build context to Docker daemon 2.229 MB Step 1 / 4 : FROM nvidia / cuda : 10.0 - cudnn7 - runtime - centos7 ---> Running in 7 d171c998c6a Removing intermediate container 7 d171c998c6a ---> 494 b7b9cbb47 Step 3 / 4 : RUN yum - y install vim ---> Running in 1129 f4d0c210 Loaded plugins : fastestmirror , ovl , versionlock Determining fastest mirrors * base : mirrors . cn99 . com * extras : mirrors . cn99 . com * updates : mirrors . cn99 . com http : // mirrors . cn99 . com / centos / 7.9 . 2009 / os / x86_64 / repodata / repomd . xml : [ Errno 12 ] Timeout on http : // mirrors . cn99 . com / centos / 7.9 . 2009 / os / x86_64 / repodata / repomd . xml : ( 28 , 'Operation too slow. Less than 1000 bytes/sec transferred the last 30 seconds' ) Trying other mirror . https : // developer . download . nvidia . com / compute / cuda / repos / rhel7 / x86_64 / repodata / repomd . xml : [ Errno 12 ] Timeout on https : // developer . download . nvidia . com / compute / cuda / repos / rhel7 / x86_64 / repodata / repomd . xml : ( 28 , 'Operation timed out after 30001 milliseconds with 0 out of 0 bytes received' ) Trying other mirror . https : // developer . download . nvidia . com / compute / cuda / repos / rhel7 / x86_64 / repodata / repomd . xml : [ Errno 12 ] Timeout on https : // developer . download . nvidia . com / compute / cuda / repos / rhel7 / x86_64 / repodata / repomd . xml : ( 28 , 'Operation timed out after 30000 milliseconds with 0 out of 0 bytes received' ) Trying other mirror . åœ¨å®¹å™¨ä¸­yumå®‰è£…å·¥å…·ä¸€åˆ‡æ­£å¸¸ï¼Œåœ¨Dockerfileä¸­æ„å»ºé•œåƒæ—¶ï¼Œå‡ºç°ç½‘ç»œè¶…æ—¶é—®é¢˜ã€‚ ç”±äºåœ¨èµ·å®¹å™¨æ˜¯ docker run --net=host è§£å†³æ–¹æ¡ˆï¼šåœ¨åˆ¶ä½œé•œåƒæ—¶è®¾ç½®ä¸ä¸»æœºåŒä¸€ç½‘ç»œ docker build --network=host -t image_name:v1 .","tags":"Tools","url":"articles/Docker-build.html","loc":"articles/Docker-build.html"},{"title":"Docker export vs commit","text":"é—®é¢˜æè¿°ï¼š 2021 - 09 - 04 14 : 12 : 08.686281 : I tensorflow / stream_executor / platform / default / dso_loader . cc : 53 ] Could not dlopen library 'libcuda.so.1' ; dlerror : / lib64 / libcuda . so . 1 : file too short 2021 - 09 - 04 14 : 12 : 08.686315 : E tensorflow / stream_executor / cuda / cuda_driver . cc : 318 ] failed call to cuInit : UNKNOWN ERROR ( 303 ) 2021 - 09 - 04 14 : 12 : 08.686354 : I tensorflow / stream_executor / cuda / cuda_diagnostics . cc : 169 ] retrieving CUDA diagnostic information for host : jerry 2021 - 09 - 04 14 : 12 : 08.686366 : I tensorflow / stream_executor / cuda / cuda_diagnostics . cc : 176 ] hostname : jerry 2021 - 09 - 04 14 : 12 : 08.686403 : I tensorflow / stream_executor / cuda / cuda_diagnostics . cc : 200 ] libcuda reported version is : Not found : was unable to find libcuda . so DSO loaded into this program 2021 - 09 - 04 14 : 12 : 08.686568 : I tensorflow / stream_executor / cuda / cuda_diagnostics . cc : 204 ] kernel reported version is : 418.126 . 2 2021 - 09 - 04 14 : 12 : 08.702025 : I tensorflow / core / platform / profile_utils / cpu_utils . cc : 94 ] CPU Frequency : 2400000000 Hz 2021 - 09 - 04 14 : 12 : 08.717327 : I tensorflow / compiler / xla / service / service . cc : 168 ] XLA service 0x3aade70 executing computations on platform Host . Devices : 2021 - 09 - 04 14 : 12 : 08.717385 : I tensorflow / compiler / xla / service / service . cc : 175 ] StreamExecutor device ( 0 ): < undefined > , < undefined > False åŸºç¡€é•œåƒ nvidia/cuda:10.0-cudnn7-runtime-centos7 èµ·å®¹å™¨é…ç½®åï¼Œé€šè¿‡å‘½ä»¤ docker export åˆ¶ä½œé•œåƒï¼Œåˆ†å‘ä½¿ç”¨å…¶å®¹å™¨ä¸èƒ½é©±åŠ¨gpuï¼ŒæŠ¥é”™ Could not dlopen library 'libcuda.so.1'; dlerror: /lib64/libcuda.so.1: file too short è§£å†³æ–¹æ¡ˆï¼š docker commit . çŸ¥è¯†ç‚¹ï¼š docker export vs docker commit","tags":"Tools","url":"articles/Docker-export-commit.html","loc":"articles/Docker-export-commit.html"},{"title":"Docker Build GPU Base Image","text":"https://docs.docker.com/engine/reference/commandline/docker/ 1.åŸºç¡€é•œåƒé€‰æ‹© https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/user-guide.html é€‰æ‹©Nvidia cudaæ”¯æŒgpuï¼š https://hub.docker.com/r/nvidia/cuda/tags?page=1&ordering=last_updated&name=10.0 runtimeç‰ˆï¼šç”¨äºæœåŠ¡éƒ¨ç½²ï¼Œ å¤§å°1.7Gï¼›develç‰ˆï¼šç”¨äºå¼€å‘ï¼ŒåŠŸèƒ½å®Œæ•´ï¼Œå¤§å°3Gã€‚ docker pull nvidia/cuda:10.0-cudnn7-runtime-centos7 docker pull nvidia/cuda:10.0-cudnn7-devel-centos7 2.yumæ¢æº å¯åŠ¨å®¹å™¨ï¼šdocker run -itd â€”gpus=all â€”net=host â€”name=temp -v /docker_tmp:/server_api 1ba4e7500fa3 /bin/bash è¿›å…¥å®¹å™¨ï¼šdocker exec -it temp /bin/bash å¤‡ä»½yumåŸå§‹çš„æºï¼šmv /etc/yum.repos.d /etc/yum.repos.d.bk åˆ›å»ºyumæºç›®å½•ï¼šmkdir /etc/yum.repos.d ä¸‹è½½é˜¿é‡Œäº‘yumæºï¼šwget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo é‡å»ºç¼“å­˜ï¼šyum clean all && yum makecache 3.å®‰è£…python3 å®‰è£…pythonç¯å¢ƒç¼–è¯‘å·¥å…· yum -y install openssl-devel bzip2-devel expat-devel gdbm-devel readline-devel sqlite-devel yum -y install gcc automake autoconf libtool make wget vim ç§»é™¤centosè‡ªå¸¦pythonè½¯è¿æ¥ï¼ˆè½¯é“¾åˆ°python2çš„ï¼‰ cd /usr/bin && mv python python.bk ä¸‹è½½python3æºç  mkdir -p /usr/local/python/python3 cd /usr/local wget https://www.python.org/ftp/python/3.6.8/Python-3.6.8.tgz tar - xzvf Python-3.6.8.tgz ç¼–è¯‘python3æºç  cd /usr/local/Python-3.6.8 ./configure â€”prefix=/usr/local/python/python3 make && make install ç›´æ¥make && make installä¼šæŠ¥é”™ï¼šzipimport.ZipImportError: can't decompress data; zlib not availableï¼Œå…ˆå¦‚ä¸‹è§£å†³ï¼š vim Modules/Setup # æŠŠ#zlib zlibmodule.c -I$(prefix)/include -L$(exec_prefix)/lib -lz æ³¨é‡Šå»æ‰ cd /usr/local/Python-3.6.8/Modules/zlib && ./configure && make install cd /usr/local/Python-3.6.8 è®¾ç½®è½¯é“¾æ¥ ln -s /usr/local/python/python3/bin/python3 /usr/bin/python éªŒè¯å®‰è£… python -V ä¿®æ”¹yum æ³¨æ„:ç”±äºcentos7çš„yumè¦ä½¿ç”¨åˆ°python2.7.5çš„ç¯å¢ƒï¼Œæˆ‘ä»¬è¦æŒ‡å®šyumä½¿ç”¨çš„pythonçš„ç‰ˆæœ¬ï¼Œä¸ç„¶ä½¿ç”¨äº†3.6.8å¯èƒ½ä¼šå¯¼è‡´yumå‘½ä»¤æ— æ³•ä½¿ç”¨ï¼Œä¿®æ”¹å¤´éƒ¨è®¾ç½®ä¸ºä½¿ç”¨python2.7 vim /usr/bin/yum #!/usr/bin/python -â†’ #!/usr/bin/python2.7 4.å®‰è£…pipå·¥å…· cd /usr/local wget http://bootstrap.pypa.io/get-pip.py python get-pip.py ln -s /usr/local/python/python3/bin/pip3 /usr/bin/pip pip -V 5.ä¸­æ–‡æ”¯æŒ echo \"export LC_ALL=en_US. UTF -8\" >> /etc/profile source /etc/profile echo \"export LC_ALL=en_US. UTF -8\" >> ~/.bashrc source ~/.bashrc 6.åˆ¶ä½œé•œåƒ docker export -o gpu_python3.tar 8020a9753211(å®¹å™¨å·) docker import gpu_python3.tar nvidia/cuda:1.9.0-cuda10.2-cudnn7-runtime-python3 docker tag nvidia/cuda:1.9.0-cuda10.2-cudnn7-runtime-python3 image:tag","tags":"Tools","url":"articles/Docker-Build-GPU-Base-Image.html","loc":"articles/Docker-Build-GPU-Base-Image.html"},{"title":"Google-android","text":"ADB Goè°·æ­Œå®‰è£…å™¨ GMSå®‰è£…å™¨ ä¸å»ºè®®é‡‡ç”¨ä»¥ä¸Šä¸€é”®å®‰è£… ç–‘éš¾é—®é¢˜ ADB adb version adb devices æŸ¥çœ‹æ‰€æœ‰åº”ç”¨åˆ—è¡¨ï¼šadb shell pm list packages æŸ¥çœ‹ç³»ç»Ÿåº”ç”¨åˆ—è¡¨ï¼šadb shell pm list packages -s # com.google.android.gmsï¼Œcom.google.android.gsfï¼Œcom.google.android.partnersetupï¼Œ # com.google.android.backuptransportï¼Œcom.google.android.onetimeinitializer åˆ é™¤åº”ç”¨ï¼šadb shell pm uninstall --user 0 com.baidu.input_huawei Goè°·æ­Œå®‰è£…å™¨ æ³¨æ„Goè°·æ­Œå®‰è£…å™¨4.8.4åªæ”¯æŒå®‰å“7.0ã€7.1ã€8.0ã€9.0ï¼Œå°è¯•è¿‡å®‰å“8.1æ€»æ˜¯å¤±è´¥ï¼ GMSå®‰è£…å™¨ ä¸å»ºè®®é‡‡ç”¨ä»¥ä¸Šä¸€é”®å®‰è£… ä¼˜ç‚¹æ–¹ä¾¿ï¼Œç¼ºç‚¹é»˜è®¤è£…çš„è°·æ­Œä¸‰ä»¶å¥—ï¼šè°·æ­Œæ¡†æ¶ï¼Œè°·æ­ŒplayæœåŠ¡ï¼Œè°·æ­Œplayå•†åŸå­˜åœ¨ä¸æ‰‹æœºå®‰å“ç³»ç»Ÿä¸åŒ¹é…ï¼Œå»ºè®®å•ç‹¬ä¸‹è½½å®‰è£…ã€‚ https://www.apkmirror.com/ apkpure.com https://www.olocat.cn/?p=45 ç–‘éš¾é—®é¢˜ google playç™»é™†æ ¸éªŒä¿¡æ¯é»‘å±é€€å‡º @ æ‰€æœ‰ google å†…å»ºåŒ… @ adb shell pm list packages @ adb shell pm list packages - s adb shell pm uninstall -- user 0 com . google . android . gms adb shell pm uninstall -- user 0 com . google . android . gsf adb shell pm uninstall -- user 0 com . google . android . backuptransport adb shell pm uninstall -- user 0 com . google . android . onetimeinitializer adb shell pm uninstall -- user 0 com . android . vending @ google play adb shell pm uninstall -- user 0 com . google . android . gms . policy_sidecar_aps adb shell pm uninstall -- user 0 com . google . android . printservice . recommendation adb shell pm uninstall -- user 0 com . google . android . overlay . contactproviderconfig adb shell pm uninstall -- user 0 com . google . android . partnersetup adb shell pm uninstall -- user 0 com . google . android . webview adb shell pm uninstall -- user 0 com . google . android . overlay . settingsConfig adb shell pm uninstall -- user 0 com . google . android . syncadapters . contacts adb shell pm uninstall -- user 0 com . google . android . ext . services adb shell pm uninstall -- user 0 com . google . android . overlay . gmsconfig adb shell pm uninstall -- user 0 com . google . android . configupdater adb shell pm uninstall -- user 0 com . google . android . marvin . talkback adb shell pm uninstall -- user 0 com . google . android . ext . shared adb shell pm uninstall -- user 0 com . google . ar . core adb shell pm uninstall -- user 0 com . google . android . gsf . login adb shell pm uninstall -- user 0 com . google . android . overlay . settingsProvider adb shell pm list packages pause","tags":"Tools","url":"articles/Google-Android.html","loc":"articles/Google-Android.html"},{"title":"Convert pytorch checkpoint to tensorflow2","text":"https://github.com/huggingface/transformers/issues/6124 from transformers import TFBertModel model = TFBertModel . from_pretrained ( \"./rubert-base-cased-pt\" , from_pt = True ) model . save ( \"./rubert-base-cased\" ) # this adds a TF model file (tf_model.h5) to your directory","tags":"NLP","url":"articles/Convert-pytorch-model-to-tensorflow2.html","loc":"articles/Convert-pytorch-model-to-tensorflow2.html"},{"title":"CMRC Metric","text":"F1 # find longest common string def find_lcs ( s1 , s2 ): m = [[ 0 for i in range ( len ( s2 ) + 1 )] for j in range ( len ( s1 ) + 1 )] mmax = 0 p = 0 for i in range ( len ( s1 )): for j in range ( len ( s2 )): if s1 [ i ] == s2 [ j ]: m [ i + 1 ][ j + 1 ] = m [ i ][ j ] + 1 if m [ i + 1 ][ j + 1 ] > mmax : mmax = m [ i + 1 ][ j + 1 ] p = i + 1 return s1 [ p - mmax : p ], mmax def calc_f1_score ( answers , prediction ): f1_scores = [] for ans in answers : ans_segs = mixed_segmentation ( ans , rm_punc = True ) prediction_segs = mixed_segmentation ( prediction , rm_punc = True ) lcs , lcs_len = find_lcs ( ans_segs , prediction_segs ) if lcs_len == 0 : f1_scores . append ( 0 ) continue precision = 1.0 * lcs_len / len ( prediction_segs ) recall = 1.0 * lcs_len / len ( ans_segs ) f1 = ( 2 * precision * recall ) / ( precision + recall ) f1_scores . append ( f1 ) return max ( f1_scores ) EM # remove punctuation def remove_punctuation ( in_str ): in_str = in_str . lower () . strip () sp_char = [ '-' , ':' , '_' , '*' , '&#94;' , '/' , ' \\\\ ' , '~' , '`' , '+' , '=' , 'ï¼Œ' , 'ã€‚' , 'ï¼š' , 'ï¼Ÿ' , 'ï¼' , '\"' , '\"' , 'ï¼›' , ''' , 'ã€Š' , 'ã€‹' , 'â€¦â€¦' , 'Â·' , 'ã€' , 'ã€Œ' , 'ã€' , 'ï¼ˆ' , 'ï¼‰' , 'ï¼' , 'ï½' , 'ã€' , 'ã€' ] out_segs = [] for char in in_str : if char in sp_char : continue else : out_segs . append ( char ) return '' . join ( out_segs ) def calc_em_score ( answers , prediction ): em = 0 for ans in answers : ans_ = remove_punctuation ( ans ) prediction_ = remove_punctuation ( prediction ) if ans_ == prediction_ : em = 1 break return em","tags":"NLP","url":"articles/CMRC-Metric.html","loc":"articles/CMRC-Metric.html"},{"title":"JDMDC2020","text":"2020äº¬ä¸œå¤šæ¨¡æ€å¯¹è¯JDMDC2020ç¬¬äºŒåè§£å†³æ–¹æ¡ˆ æ•°æ®å·¥ä½œ æ•°æ®é›†æ¢ç´¢ æ•°æ®é¢„å¤„ç† è®­ç»ƒæ•°æ®æ„é€  èåˆå¤šæ¨¡æ€ä¸çŸ¥è¯†åº“ æŠ€æœ¯æ–¹æ¡ˆ åŸºçº¿æ¨¡å‹MHRED æœ€ä½³æ¨¡å‹VLGPT æ€»ç»“ä¸å¼•ç”¨ 2020äº¬ä¸œå¤šæ¨¡æ€å¯¹è¯JDMDC2020ç¬¬äºŒåè§£å†³æ–¹æ¡ˆ CCL2020 : ä¸­å›½è®¡ç®—è¯­è¨€å­¦å¤§ä¼šï¼ˆ CCL 2020ï¼‰æŠ€æœ¯è¯„æµ‹ç»“æœ JDMDC2020 RANK ï¼š https://jddc.jd.com/rank Code: JDMDC2020 -Solution-2nd Hibotå›¢é˜Ÿæˆç»©ï¼šåˆèµ›ç¬¬ä¸‰ï¼Œå†³èµ›ç¬¬äºŒ Hiboté˜Ÿå‘˜ï¼šæ—å…‹ï¼ŒèŒ¸èŒ¸ï¼Œé˜¿å¸ƒï¼Œæ°ç‘ æ•°æ®å·¥ä½œ æ•°æ®é›†æ¢ç´¢ æ•°æ®åˆ†ä¸ºäº”ä¸ªå­—æ®µï¼šä¼šè¯ID, åº—é“ºç±»åˆ«ï¼Œ å•†å“IDï¼Œ å¯¹è¯æ–‡æœ¬ï¼ˆåŒ…å«å›¾ç‰‡IDï¼‰ï¼Œ å¯¹è¯è§’è‰²ã€‚é€šè¿‡å•†å“IDä¸å›¾ç‰‡IDï¼Œæ¥å¼•ç”¨å•†å“çŸ¥è¯†åº“æ•°æ®å’Œå›¾ç‰‡æ¨¡æ€æ•°æ®ã€‚ ç»Ÿè®¡åŸå§‹ä¼šè¯ï¼ˆè¿ç»­QQAAæœªåˆå¹¶ï¼‰è½®æ•°é•¿åº¦ä»¥åŠå•å¥æ–‡æœ¬é•¿åº¦ï¼ˆæŒ‰å­—ï¼‰ã€‚ æ•°æ®é¢„å¤„ç† è®­ç»ƒæ•°æ®æ„é€  èåˆå¤šæ¨¡æ€ä¸çŸ¥è¯†åº“ æŠ€æœ¯æ–¹æ¡ˆ åŸºçº¿æ¨¡å‹MHRED å®˜æ–¹æä¾›åŸºçº¿ç”Ÿæˆæ¨¡å‹MHREDï¼šhttps://github.com/jd-aig/nlp_baai/tree/master/jddc2020_baseline/mhred/pytorch åŸºçº¿æ¨¡å‹MHREDå¤ç°BLEUåˆ†ä¸ºï¼š3.3853ï¼Œåœ¨åŸºçº¿çš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬åŠ å…¥äº†æ³¨æ„åŠ›æœºåˆ¶BLEUæåˆ†åˆ°ï¼š5.6237ã€‚ æœ€ä½³æ¨¡å‹VLGPT æ€»ç»“ä¸å¼•ç”¨ What did work å»é™¤ä¸Šä¸‹æ–‡ä¸ºç©ºçš„æ•°æ® å»é™¤æ— æ„ä¹‰å›å¤ï¼Œä¾‹å¦‚å¥½çš„ï¼Œå—¯å—¯ï¼Œå“¦â€¦ æ ¹æ®æ•°æ®é›†è‡ªå®šä¹‰å­—å…¸ï¼ŒOOVé—®é¢˜ å¸¦æ©ç çš„Lossï¼Œmasked answer labels å¢åŠ token type embeddingåŒºåˆ†è§’è‰² BaseåŸºç¡€GPTæ¨¡å‹ å„ç§æ³¨æ„åŠ›æœºåˆ¶Self-Attention, Context-Attention, Masked SeLf-Attention[5][12] What didn't work åˆ é™¤é€šç”¨æ¨¡æ¿å›å¤ Label Smoothingæå‡å¾®å¼± [13] å¤šå¤´ä»»åŠ¡å­¦ä¹ DoubleHead GPT (ç”Ÿæˆä»»åŠ¡+æ˜¯å¦ä¸ºä¸‹ä¸€å¥) [14] BERTä¸­æ–‡wikié¢„è®­ç»ƒæ¨¡å‹ [15] GPTä¸­æ–‡wiki[16]ä¸æ¸…åå¼€æºé¢„è®­ç»ƒæ¨¡å‹ [17][18] Mediumä¸­å‹GPTæ¨¡å‹ æœ€å¤§äº’ä¿¡æ¯Maximum Mutual Information( MMI ) [19] [1] Kishore Papineni, Salim Roukos, et al. BLEU : a Method for Automatic Evaluation of Machine Translation [2] Boxing Chen, Colin Cherry et al. A Systematic Comparison of Smoothing Techniques for Sentence-Level BLEU [3] Amrita Saha, Mitesh Khapra, et al. Towards Building Large Scale Multimodal Domain-Aware Conversation Systems [4] Minh-Thang Luong, Hieu Pham, et al. Effective Approaches to Attention-based Neural Machine Translation [5] Ashish Vaswani, Noam Shazeer, et al. Attention Is All You Need [6] Jacob Devlin, Ming-Wei Chang, et al. BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding [7] Alec Radford, Karthik Narasimhan, et al. Improving Language Understanding by Generative Pre-Training [8] Alec Radford, Jeffrey Wu, et al. Language Models are Unsupervised Multitask Learners [9] https://huggingface.co - transformers [10] Thomas Wolf, Victor Sanh, et al. TransferTransfo: A Transfer Learning Approach for Neural Network Based Conversational Agents [11] https://github.com/huggingface/transfer-learning-conv-ai [12] https://jalammar.github.io/illustrated-transformer [13] Rafael MÃ¼ller, Simon Kornblith, st al. when does label smoothing help? [14] https://huggingface.co/transformers/model_doc/gpt2.html#gpt2doubleheadsmodel [15] https://huggingface.co/bert-base-chinese [16] https://github.com/qingkongzhiqian/ GPT2 -Summary [17] https://cloud.tsinghua.edu.cn/f/4dfb8c6c22ae47fbbe98 [18] Yida Wang, Pei Ke, et al. A Large-Scale Chinese Short-Text Conversation Dataset [19] Yizhe Zhang, Siqi Sun, et al. DialoGPT:Large-Scale Generative Pre-training for Conversational Response Generation","tags":"NLP","url":"articles/JDMDC2020.html","loc":"articles/JDMDC2020.html"},{"title":"Deploy model in production","text":"Install wsgi using code Install wsgi using pip Load wsgi module in Ubuntu How do I use a conda environment with mod_wsgi? Install wsgi using code git clone https://github.com/GrahamDumpleton/mod_wsgi apt-get install apache2-dev apt-get install python-dev cd mod_wsgi/ ./configure make make install Install wsgi using pip apt-get install libapache2-mod-wsgi-py3 instead of libapache2-mod-wsgi for python3 mod_wsgi install Load wsgi module in Ubuntu How do I use a conda environment with mod_wsgi? How do I use a conda environment with mod_wsgi? ubuntu+apache+mod_wsgi+flask mod_wsgi deploy https://github.com/ahkarami/Deep-Learning-in-Production https://pytorch.org/tutorials/intermediate/flask_rest_api_tutorial.html","tags":"Tools","url":"articles/Deploy-model-in-production.html","loc":"articles/Deploy-model-in-production.html"},{"title":"NLP Resources","text":"Paper Project Paper Effective Approaches to Attention-based Neural Machine Translation Attention is All You Need BART : Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension RASA : Dialogue Transformers Project Transformers Microsoft NLP best practices: Best practices and examples on NLP . RASA","tags":"NLP","url":"articles/NLP-Resources.html","loc":"articles/NLP-Resources.html"},{"title":"Pytorch Transformer","text":"pytorch transformer illustrated transformer import math import torch import torch.nn as nn from torch.nn import TransformerEncoder , TransformerEncoderLayer , TransformerDecoder , TransformerDecoderLayer from layers.encoder import CustomEmbedding import layers class PositionalEncoding ( nn . Module ): \"\"\" Args: d_model: the number of expected features in the input (required). dropout: the dropout value (default=0.1). \"\"\" def __init__ ( self , d_model , dropout = 0.1 , max_len = 512 ): super ( PositionalEncoding , self ) . __init__ () self . dropout = nn . Dropout ( p = dropout ) pe = torch . zeros ( max_len , d_model ) position = torch . arange ( 0 , max_len , dtype = torch . float ) . unsqueeze ( 1 ) div_term = torch . exp ( torch . arange ( 0 , d_model , 2 ) . float () * ( - math . log ( 10000.0 ) / d_model )) pe [:, 0 :: 2 ] = torch . sin ( position * div_term ) pe [:, 1 :: 2 ] = torch . cos ( position * div_term ) pe = pe . unsqueeze ( 0 ) . transpose ( 0 , 1 ) self . register_buffer ( 'pe' , pe ) def forward ( self , x ): x = x + self . pe [: x . size ( 0 ), :] return self . dropout ( x ) class TransformerModel ( nn . Module ): \"\"\" Args: vocab_size: # the size of vocabulary. embed_size: embedding dimension, the number of expected features in the input nhead: the number of heads in the multiheadattention models. dim_feedforward: the dimension of the feedforward network model in nn.TransformerEncoder. nlayers: the number of sub-decoder-layers in the decoder (default=6). dropout: the dropout value (default=0.1). \"\"\" def __init__ ( self , config ): super ( TransformerModel , self ) . __init__ () self . config = config self . pos_encoder = PositionalEncoding ( config . embed_size , config . dropout , config . max_len ) self . pos_decoder = PositionalEncoding ( config . embed_size , config . dropout , config . max_len ) self . src_embedding = CustomEmbedding ( config . vocab_size , config . embed_size ) self . tgt_embedding = nn . Embedding ( config . vocab_size , config . embed_size ) # encode images self . image_encoder = layers . ImageEncoder ( config . embedding_size ) # encoder encoder_layers = TransformerEncoderLayer ( config . embed_size , config . nhead , config . dim_feedforward , config . dropout ) self . transformer_encoder = TransformerEncoder ( encoder_layers , config . nlayers ) # decoder decoder_layers = TransformerDecoderLayer ( config . embed_size , config . nhead , config . dim_feedforward , config . dropout ) self . transformer_decoder = TransformerDecoder ( decoder_layers , config . nlayers ) self . linear = nn . Linear ( config . embed_size , config . vocab_size ) self . init_weights () def _attn_padding_mask ( self , seq ): \"\"\" seq_q: [batch_size, seq_len] seq_k: [batch_size, seq_len] seq_len could be src_len or it could be tgt_len seq_len in seq_q and seq_len in seq_k maybe not equal \"\"\" # eq(zero) is PAD token return seq . data . eq ( 0 ) # [batch_size, 1, len_k], True is masked #return pad_attn_mask.expand(batch_size, len_q, len_k) # [batch_size, len_q, len_k] def _sequence_mask ( self , seq ): \"\"\" Along with the input sequence, a square attention mask is required because the self-attention layers in nn. TransformerEncoder are only allowed to attend the earlier positions in the sequence. For the language modeling task, any tokens on the future positions should be masked. To have the actual words, the output of nn. TransformerEncoder model is sent to the final Linear layer, which is followed by a log-Softmax function. \"\"\" batch_size , seq_len = seq . size () mask = ( torch . triu ( torch . ones ( seq_len , seq_len )) == 1 ) . transpose ( 0 , 1 ) . to ( seq . device ) mask = mask . float () . masked_fill ( mask == 0 , float ( '-inf' )) . masked_fill ( mask == 1 , float ( 0.0 )) return mask def init_weights ( self ): initrange = 0.1 self . src_embedding . embedding . weight . data . uniform_ ( - initrange , initrange ) self . tgt_embedding . weight . data . uniform_ ( - initrange , initrange ) def forward ( self , src , input_sentence_length , input_conversation_length , tgt , input_images , input_images_length , input_image_indexes ): # encode images img_encoder_outputs = self . image_encoder ( input_images ) # encoder src_padding_mask = self . _attn_padding_mask ( src ) src_embed = self . src_embedding ( src , img_encoder_outputs , input_images_length , input_image_indexes ) * math . sqrt ( self . config . embed_size ) src_embed = self . pos_encoder ( src_embed ) . transpose ( 0 , 1 ) # Shape must be [Len, Batch, Embed] for nn.TransformerEncoderLayer. memory = self . transformer_encoder ( src = src_embed , src_key_padding_mask = src_padding_mask ) # decoder tgt_padding_mask = self . _attn_padding_mask ( tgt ) tgt_sequence_mask = self . _sequence_mask ( tgt ) tgt_embed = self . tgt_embedding ( tgt ) * math . sqrt ( self . config . embed_size ) tgt_embed = self . pos_decoder ( tgt_embed ) . transpose ( 0 , 1 ) output = self . transformer_decoder ( tgt = tgt_embed , memory = memory , tgt_mask = tgt_sequence_mask , tgt_key_padding_mask = tgt_padding_mask , memory_key_padding_mask = src_padding_mask ) output = self . linear ( output ) return output . transpose ( 0 , 1 ) . contiguous ()","tags":"Programming","url":"articles/Pytorch-Transformer.html","loc":"articles/Pytorch-Transformer.html"},{"title":"Pytorch contiguous","text":"Pytorch contiguous","tags":"Programming","url":"articles/Pytorch-contiguous.html","loc":"articles/Pytorch-contiguous.html"},{"title":"ã€ NLP ã€‘Teacher Forcing","text":"Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks Teacher-Forcing æŠ€æœ¯åœ¨è®­ç»ƒå‰æœŸçš„ç¡®æ˜¯èƒ½å¤Ÿå¾ˆå¤§çš„åŠ é€Ÿæ¨¡å‹æ”¶æ•›çš„ï¼š æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¯ä¸€ä¸ªæ—¶é—´æ­¥stepsï¼Œæœ‰pçš„æ¦‚ç‡é€‰æ‹©ä½¿ç”¨targetï¼Œæœ‰1-pçš„æ¦‚ç‡é€‰æ‹©ä½¿ç”¨predictã€‚ æ¨¡å‹åœ¨è®­ç»ƒå‰æœŸï¼Œpåº”è¯¥å°½å¯èƒ½çš„å¤§ï¼Œè¿™æ ·èƒ½å¤ŸåŠ é€Ÿæ”¶æ•›ï¼›è€Œåœ¨å¿«è¦ç»“æŸè®­ç»ƒçš„æ—¶å€™ï¼Œpå°½å¯èƒ½çš„å°ï¼Œè®©æ¨¡å‹åœ¨ Autoregressive çš„æ–¹æ¡ˆä¸­å°½å¯èƒ½çš„ä¿®å¤è‡ªèº«ç”Ÿæˆçš„é”™è¯¯ã€‚ æ›´ç¡®åˆ‡çš„ï¼Œè¿™ä¸ªpæ¦‚ç‡å¯ä»¥éšç€è®­ç»ƒçš„Steps or Epoch è¿›è¡Œè¡°å‡ï¼Œè€Œè¡°å‡çš„æ–¹å¼ä¹Ÿå¯ä»¥åˆ†ä¸ºï¼šExponential Decay, Inverse Sigmoid decay å’Œ Linear decay ä¸‰ç§æ–¹å¼ã€‚ åŸºäºpytorchå®ç°Linear decayï¼š parser . add_argument ( '--ss_used' , type = str2bool , default = True ) parser . add_argument ( '--ss_start' , type = float , default = 1.0 ) parser . add_argument ( '--ss_decay' , type = float , default = 0.005 ) parser . add_argument ( '--ss_min' , type = float , default = 0.9 ) # train for epoch_i in range ( self . epoch_i , self . config . n_epoch ): if self . config . ss_used and self . config . ss_start > self . config . ss_min : self . config . ss_start = self . config . ss_start - self . config . ss_decay * epoch_i # decode def decode ( self , out ): # Sample next word from multinomial word distribution if self . sample : x = torch . multinomial ( self . softmax ( out / self . temperature ), 1 ) . view ( - 1 ) # Greedy sampling else : _ , x = out . max ( dim = 1 ) return x for i in range ( seq_len ): out , h = self . forward_step ( x , h ) out_list . append ( out ) if config . ss_used and random . random () > config . ss_start : x = self . decode ( out ) # predict val else : x = inputs [:, i ] # ground true val","tags":"NLP","url":"articles/ã€NLPã€‘Teacher-Forcing.html","loc":"articles/ã€NLPã€‘Teacher-Forcing.html"},{"title":"Pytorch distributed train","text":"ä¸»å¡çº¿ç¨‹æš´æ¶¨ å…±äº«å†…å­˜é—®é¢˜ lamdaå¯¹è±¡ä¸èƒ½åºåˆ—åŒ–é—®é¢˜ åŠ è½½åˆ†å¸ƒå¼æ¨¡å‹åˆ°å•å¡ ä¸»å¡çº¿ç¨‹æš´æ¶¨ å¼‚å¸¸ï¼š æ­£å¸¸ï¼š def to_var ( x , on_cpu = False , gpu_id = None ): \"\"\"Tensor => Variable\"\"\" if torch . cuda . is_available () and not on_cpu : x = x . cuda ( gpu_id , non_blocking = True ) # x = Variable(x) return x def normal_kl_div ( mu1 , var1 , mu2 = to_var ( torch . FloatTensor ([ 0.0 ])), var2 = to_var ( torch . FloatTensor ([ 1.0 ]))): one = to_var ( torch . FloatTensor ([ 1.0 ])) return torch . sum ( 0.5 * ( torch . log ( var2 ) - torch . log ( var1 ) å¤šçº¿ç¨‹è„šæœ¬å¯¼å…¥æ—¶ï¼Œå‡½æ•°å‚æ•°æ€»æ˜¯æ‰§è¡Œto_var()ã€‚å½“çº¿ç¨‹num_workersè¶Šå¤šï¼Œæ•°æ®æ— æ•ˆè£…å…¥cudaå°±è¶Šå¤šã€‚ ä¿®æ”¹ def normal_kl_div ( mu1 , var1 , mu2 , var2 ): mu2 = to_var ( torch . FloatTensor ([ 0.0 ])) var2 = to_var ( torch . FloatTensor ([ 1.0 ])) one = to_var ( torch . FloatTensor ([ 1.0 ])) return torch . sum ( 0.5 * ( torch . log ( var2 ) - torch . log ( var1 ) å…±äº«å†…å­˜é—®é¢˜ Training Start ! 0 %| | 0 / 40937 [ 00 : 00 <? , ? it / s ] ERROR : Unexpected bus error encountered in worker . This might be caused by insufficient shared memory ( shm ) . Traceback ( most recent call last ) : File \"/root/anaconda3/envs/torch/lib/python3.7/multiprocessing/queues.py\" , line 236 , in _feed obj = _ForkingPickler . dumps ( obj ) File \"/root/anaconda3/envs/torch/lib/python3.7/multiprocessing/reduction.py\" , line 51 , in dumps cls ( buf , protocol ) . dump ( obj ) fd , size = storage . _share_fd_ () RuntimeError : unable to write to file </ torch_3531_3962650647 > RuntimeError : DataLoader worker ( pid 3527 ) is killed by signal : Bus error . Please note that PyTorch uses shared memory to share data between processes , so if torch multiprocessing is used ( e . g . for multithreaded data loaders ) the default shared memory segment size that container runs with is not enough , and you should increase shared memory size either with -- ipc = host or -- shm - size command line options to nvidia - docker run . å¤šè¿›ç¨‹æ•°æ®åŠ è½½Dataloaderï¼ŒDockerå®¹å™¨çš„å…±äº«å†…å­˜/dev/shmä¸è¶³ ä¿®æ”¹å½“å‰Dockerçš„shm-sizeã€‚æŒ‚è½½ç‚¹/dev/shm - docker ps - a - docker inspect [ container id ] | grep Id - systemctl stop docker - cd [ container directory ] - ä¿®æ”¹hostconfig . jsonå’Œconfig . v2 . json - systemctl start docker - docker start [ container id ] num_workersè®¾ç½®0 dataloader = torch . utils . data . DataLoader ( dataset , batch_size = 16 , shuffle = True , num_workers = 0 , pin_memory = True , collate_fn = dataset . collate_fn ) lamdaå¯¹è±¡ä¸èƒ½åºåˆ—åŒ–é—®é¢˜ -- Process 0 terminated with the following error : Traceback ( most recent call last ): File \"/root/anaconda3/envs/torch/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\" , line 19 , in _wrap fn ( i , * args ) File \"/home/yckj2939/project/yckj_project/mhred/pytorch/train.py\" , line 107 , in main_worker model . train ( train_sampler , train_data_loader , eval_data_loader ) File \"/home/yckj2939/project/yckj_project/mhred/pytorch/utils/time_track.py\" , line 18 , in timed result = method ( * args , ** kwargs ) File \"/home/yckj2939/project/yckj_project/mhred/pytorch/solver.py\" , line 160 , in train for batch_i , ( conversations , conversation_length , sentence_length , images , images_length ) in enumerate ( tqdm ( train_data_loader , ncols = 80 )): File \"/root/anaconda3/envs/torch/lib/python3.7/site-packages/tqdm/_tqdm.py\" , line 979 , in __iter__ for obj in iterable : File \"/root/anaconda3/envs/torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\" , line 278 , in __iter__ return _MultiProcessingDataLoaderIter ( self ) File \"/root/anaconda3/envs/torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\" , line 682 , in __init__ w . start () File \"/root/anaconda3/envs/torch/lib/python3.7/multiprocessing/process.py\" , line 112 , in start self . _popen = self . _Popen ( self ) File \"/root/anaconda3/envs/torch/lib/python3.7/multiprocessing/context.py\" , line 223 , in _Popen return _default_context . get_context () . Process . _Popen ( process_obj ) File \"/root/anaconda3/envs/torch/lib/python3.7/multiprocessing/context.py\" , line 284 , in _Popen return Popen ( process_obj ) File \"/root/anaconda3/envs/torch/lib/python3.7/multiprocessing/popen_spawn_posix.py\" , line 32 , in __init__ super () . __init__ ( process_obj ) File \"/root/anaconda3/envs/torch/lib/python3.7/multiprocessing/popen_fork.py\" , line 20 , in __init__ self . _launch ( process_obj ) File \"/root/anaconda3/envs/torch/lib/python3.7/multiprocessing/popen_spawn_posix.py\" , line 47 , in _launch reduction . dump ( process_obj , fp ) File \"/root/anaconda3/envs/torch/lib/python3.7/multiprocessing/reduction.py\" , line 60 , in dump ForkingPickler ( file , protocol ) . dump ( obj ) AttributeError : Can 't pickle local object ' Vocab . load .< locals >.< lambda > ' def load ( self , word2id_path = None , id2word_path = None ): if word2id_path : with open ( word2id_path , 'rb' ) as f : word2id = pickle . load ( f ) # Can't pickle lambda function self . word2id = defaultdict ( lambda : UNK_ID ) self . word2id . update ( word2id ) self . vocab_size = len ( self . word2id ) pickleæ¨¡å—ä¸èƒ½åºåˆ—åŒ–lambdaï¼Œéœ€è¦è‡ªå®šä¹‰å‡½æ•° from collections import defaultdict UNK = 1 dic = defaultdict ( lambda : UNK ) print ( dic [ 'Jerry' ]) # res: 1 ---> UNK ################################################## class Test : def default_unk ( self ): return UNK def update ( self ): self . w2i = defaultdict ( self . default_unk ) return self . w2i test = Test () dic = test . update () print ( dic [ 'Annie' ]) # res: 1 ---> UNK luly.lamost.org/blog/python_multiprocessing åŠ è½½åˆ†å¸ƒå¼æ¨¡å‹åˆ°å•å¡ RuntimeError : Error ( s ) in loading state_dict for MHRED : Missing key ( s ) in state_dict : \"encoder.embedding.weight\" , ... Unexpected key ( s ) in state_dict : \"module.encoder.embedding.weight\" , ... DistributedåŒ…è£…çš„æ¨¡å‹åœ¨ä¿å­˜æ—¶ï¼Œæƒå€¼å‚æ•°å‰é¢ä¼šå¸¦æœ‰moduleå­—ç¬¦ï¼Œç„¶è€Œè‡ªå·±åœ¨å•å¡ç¯å¢ƒä¸‹ï¼Œæ²¡æœ‰ç”¨DistributedåŒ…è£…çš„æ¨¡å‹æƒå€¼å‚æ•°ä¸å¸¦moduleã€‚ æ–¹æ¡ˆä¸€ï¼šä¿å­˜æ¨¡å‹æ—¶æŠŠmoduleå»æ‰ if len ( gpu_ids ) > 1 : t . save ( net . module . state_dict (), \"model.pth\" ) else : t . save ( net . state_dict (), \"model.pth\" ) æ–¹æ¡ˆäºŒï¼š åˆ›å»ºæ–°çš„æ¨¡å‹OrderedDictä¸åŒ…å«module loc = 'cuda: {} ' . format ( self . config . gpu ) checkpoint = torch . load ( checkpoint_path , map_location = loc ) checkpoint_new = OrderedDict () for key , value in checkpoint . items (): key = key [ 7 :] # remove `module.` checkpoint_new [ key ] = value self . model . load_state_dict ( checkpoint_new ) when loading the module, you need to provide an appropriate map_location argument to prevent a process to step into others' devices. If map_location is missing, torch.load will first load the module to CPU and then copy each parameter to where it was saved, which would result in all processes on the same machine using the same set of devices https://pytorch.org/tutorials/intermediate/ddp_tutorial.html#save-and-load-checkpoints","tags":"Programming","url":"articles/Pytorch-distributed-train.html","loc":"articles/Pytorch-distributed-train.html"},{"title":"Iterator","text":"Iterator Generator Coroutine Iterator iter(): æ¥æ”¶çš„æ˜¯å¯è¿­ä»£å¯¹è±¡ï¼Œè¿”å›çš„æ˜¯è¿­ä»£å™¨ã€‚ next(): æ¥æ”¶çš„æ˜¯è¿­ä»£å™¨ï¼Œè°ƒç”¨çš„æ˜¯è¿­ä»£å™¨å¯¹è±¡ä¸­çš„nextå‡½æ•°ï¼Œè¿”å›æ•°æ®å…ƒç´ ã€‚ ç”±äºç”Ÿæˆå™¨æ˜¯ä¸€ç§ç‰¹æ®Šçš„è¿­ä»£å™¨ï¼Œæ•…è€Œç”¨next()è€Œä¸æ˜¯iter()ã€‚ class Classmate ( object ): def __init__ ( self ): self . names = list () def add ( self , name ): self . names . append ( name ) def __iter__ ( self ): # è¿”å›è¿­ä»£å™¨å¯¹è±¡ return ClassIterator ( self ) class ClassIterator ( object ): def __init__ ( self , obj ): self . obj = obj self . cur = 0 # åŒ…å«__iter__çš„æ–¹æ³•å¯¹è±¡æˆå¯è¿­ä»£iterable def __iter__ ( self ): pass # åŒ…å«__next__çš„æ–¹æ³•å¯¹è±¡æˆè¿­ä»£å™¨iterator def __next__ ( self ): if self . cur < len ( self . obj . names ): res = self . obj . names [ self . cur ] self . cur += 1 return res else : raise StopIteration ä¼˜åŒ–ï¼šå»é™¤è¿­ä»£å™¨ClassIteratorï¼Œå°†Classmateå†™æˆè¿­ä»£å™¨ï¼Œè¿”å›è‡ªèº«selfå³å¯ã€‚ from collections import Iterable import time class Classmate ( object ): def __init__ ( self ): self . names = list () self . cur = 0 def add ( self , name ): self . names . append ( name ) def __iter__ ( self ): return self def __next__ ( self ): if self . cur < len ( self . names ): res = self . names [ self . cur ] self . cur += 1 return res else : raise StopIteration if __name__ == '__main__' : classmate = Classmate () classmate . add ( 'Jerry' ) classmate . add ( 'Annie' ) classmate . add ( 'Sophie' ) print ( 'Iterable: {} ' . format ( isinstance ( classmate , Iterable ))) for temp in classmate : print ( temp ) time . sleep ( 1 ) Fibonacciæ•°åˆ—ï¼Œè¿­ä»£å™¨å®šä¹‰ç”Ÿæˆæ•°æ®çš„æ–¹æ³•ï¼Œåœ¨è®¿é—®çš„æ—¶å€™äº§ç”Ÿæ•°æ®ï¼ŒèŠ‚çœå†…å­˜ã€‚ class Fibonacci ( object ): def __init__ ( self , num ): self . num = num self . cur = 0 self . a = 0 self . b = 1 def __iter__ ( self ): return self def __next__ ( self ): if self . cur < self . num : res = self . a self . a , self . b = self . b , self . a + self . b self . cur += 1 return res else : raise StopIteration if __name__ == '__main__' : fibo = Fibonacci ( 10 ) for num in fibo : print ( num ) Generator ç”Ÿæˆå™¨æ˜¯ç‰¹æ®Šçš„è¿­ä»£å™¨ã€‚å«æœ‰yieldå…³é”®å­—çš„å‡½æ•°ï¼Œä¸å†æ˜¯å‡½æ•°è€Œæ˜¯ç”Ÿæˆå™¨ã€‚è°ƒç”¨æ—¶ä¸å†æ˜¯å‡½æ•°è°ƒç”¨è€Œæ˜¯åˆ›å»ºç”Ÿæˆå™¨å¯¹è±¡ã€‚ yieldå…³é”®å­—ï¼Œå°†å‡½æ•°æš‚åœï¼Œå½“ä¸‹æ¬¡è®¿é—®æ—¶ï¼Œæ¥ç€yieldåé¢ç»§ç»­æ‰§è¡Œã€‚ ç”Ÿæˆå™¨ä¸¤ç§å¯åŠ¨æ–¹å¼ï¼šnext(generator)å’Œgenerator.send()ï¼Œåè€…å¯ä»¥ä¼ å‚ã€‚ ç”Ÿæˆå™¨ä¼ å‚ï¼šgenerator.send(â€˜pass args') ç”Ÿæˆå™¨returnï¼šåœ¨è¿­ä»£ç»“æŸæŠ›å‡ºå¼‚å¸¸StopIteratoræ—¶ï¼Œè¿”å›returnçš„å†…å®¹ã€‚ def generator ( n ): cur = 0 a , b = 0 , 1 while cur < n : ret = yield a print ( 'ret>>>' , ret ) a , b = b , a + b cur += 1 # å¹¶éè°ƒç”¨å‡½æ•°ï¼Œè€Œæ˜¯åˆ›å»ºç”Ÿæˆå™¨å¯¹è±¡ï¼Œä½¿ç”¨next()å‡½æ•°æ‰§è¡Œç”Ÿæˆå™¨ä»£ç ã€‚ obj = generator ( 10 ) # next()å‡½æ•°ä¼ é€’çš„æ˜¯è¿­ä»£å™¨ï¼Œè€Œç”Ÿæˆå™¨æ˜¯ä¸€ç§ç‰¹æ®Šçš„è¿­ä»£å™¨ ret = next ( obj ) print ( ret ) # å¯åŠ¨ç”Ÿæˆå™¨æ—¶ï¼Œå‚æ•°ä¼ ç»™yieldå³è¾¹ret ret = obj . send ( 'pass arg' ) print ( ret ) ret = next ( obj ) print ( ret ) ç»“è®º ï¼šè¿­ä»£å™¨èƒ½èŠ‚çœå†…å­˜ç©ºé—´ï¼Œèƒ½å®ç°å¾ªç¯ï¼›ç”Ÿæˆå™¨èƒ½æš‚å®šç±»å‡½æ•°çš„è¿è¡Œï¼Œç”¨sendæˆ–è€…nextç»§ç»­æ‰§è¡Œã€‚ä»–ä»¬éƒ½æ˜¯ä¿å­˜ç”Ÿæˆæ•°æ®çš„ä»£ç ã€‚ ç”Ÿæˆå™¨çš„å¦ä¸€ä¸ªé‡è¦åº”ç”¨åç¨‹ï¼šå®ç°å¤šä»»åŠ¡ã€‚ import time def task1 (): while True : print ( '---1---' ) time . sleep ( 0.1 ) yield def task2 (): while True : print ( '---2---' ) time . sleep ( 0.1 ) yield def main (): t1 = task1 () t2 = task2 () while True : next ( t1 ) next ( t2 ) if __name__ == '__main__' : main () Coroutine é‡‡ç”¨åŒæ­¥çš„æ–¹å¼ç¼–å†™å¼‚æ­¥ä»£ç ï¼Œçº¿ç¨‹çš„åˆ‡æ¢æ˜¯æ“ä½œç³»ç»Ÿæ‰§è¡Œçš„ã€‚å•çº¿ç¨‹å†…çš„åç¨‹æ˜¯ç¨‹åºå‘˜è‡ªå·±è°ƒåº¦åˆ‡æ¢çš„ã€‚ä¸éœ€è¦é”çš„æœºåˆ¶ï¼Œå‡½æ•°çš„åˆ‡æ¢èµ„æºæ¶ˆè€—æ›´å°‘ï¼Œå¹¶å‘æ€§æ›´é«˜ã€‚ åç¨‹ï¼šå¯ä»¥æš‚åœçš„å‡½æ•°ï¼ˆç”Ÿæˆå™¨ï¼‰ï¼Œä¸”å¯ä»¥å‘æš‚åœå¤„ä¼ å‚ã€‚pythoné€šè¿‡ç”Ÿæˆå™¨å®ç°åç¨‹ã€‚","tags":"Programming","url":"articles/Iterator.html","loc":"articles/Iterator.html"},{"title":"ã€ RL ã€‘Reinforcement Learning","text":"é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ MDPç»„ä»¶ MDPç¬¦å·è¡¨ç¤º è½¬æ¢æ¦‚ç‡ æœŸæœ›å›æŠ¥ æœŸæœ›å¥–åŠ± æŠ˜æ‰£æœŸæœ›å¥–åŠ± ç­–ç•¥ä¸å€¼å‡½æ•° ç­–ç•¥ Qå€¼å‡½æ•° æœ€ä¼˜ç­–ç•¥ æœ€ä¼˜Qå€¼å‡½æ•° è´å°”æ›¼æœ€ä¼˜æ–¹ç¨‹ é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ æ„å»ºå¼ºåŒ–å­¦ä¹ é—®é¢˜ï¼šé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ Markov Decision Processes (MDPs) MDPç»„ä»¶ é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ç§å½¢å¼åŒ–é¡ºåºå†³ç­–çš„æ–¹æ³•ã€‚ è¿™ç§å½¢å¼åŒ–æ˜¯æ„å»ºé€šè¿‡å¼ºåŒ–å­¦ä¹ è§£å†³çš„é—®é¢˜çš„åŸºç¡€ã€‚ åœ¨é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ä¸­ï¼Œæ™ºèƒ½ä½“$Agent$ä¸å…¶æ‰€åœ¨çš„ç¯å¢ƒè¿›è¡Œäº¤äº’ã€‚è¿™äº›äº¤äº’éšç€æ—¶é—´çš„æµé€ä¾æ¬¡å‘ç”Ÿã€‚ åœ¨æ¯ä¸ªæ—¶é—´æ­¥$t$ä¸­ï¼Œ$Agent$éƒ½ä¼šè·å¾—ç¯å¢ƒçŠ¶æ€$s_t$çš„ç¼–ç ã€‚ç»™å®š$s_t$ï¼Œ$Agent$å°†é€‰æ‹©è¦é‡‡å–çš„è¡ŒåŠ¨$a_t$ã€‚ ç„¶åï¼Œç¯å¢ƒé€šè¿‡$a_t$å°†æ›´æ–°æ–°çš„çŠ¶æ€$s_{t+1}$ï¼Œå¹¶ä¸”ç”±äºå…ˆå‰çš„æ“ä½œï¼Œ$Agent$ä¼šè·å¾—å¥–åŠ±$r_{t+1}$ã€‚ ä¸€ä¸ªé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹çš„ç»„å»ºåŒ…æ‹¬ï¼š Agent Environment State Action Reward ä»ç»™å®šçŠ¶æ€$State$ä¸­é€‰æ‹©åŠ¨ä½œ$Action$ï¼Œè¿‡æ¸¡åˆ°æ–°çŠ¶æ€å¹¶è·å¾—å¥–åŠ±$Reward$çš„è¿‡ç¨‹æ˜¯ä¸€éåˆä¸€éåœ°ä¾æ¬¡è¿›è¡Œçš„ï¼Œè¿™åˆ›å»ºçš„ä¸€ç³»åˆ—æˆä¸ºè½¨è¿¹$Trajectory$ï¼Œè¯¥è½¨è¿¹æ˜¾ç¤ºçŠ¶æ€ï¼ŒåŠ¨ä½œå’Œå¥–åŠ±çš„é¡ºåºã€‚ åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œ$Agent$çš„ç›®æ ‡æ˜¯æœ€å¤§é™åº¦åœ°æé«˜åœ¨ç»™å®šè¿™äº›çŠ¶æ€ä¸‹é‡‡å–çš„è¿™äº›è¡ŒåŠ¨æ‰€è·å¾—çš„å¥–åŠ±æ€»é¢ã€‚ è¿™æ„å‘³ç€$Agent$ä¸ä»…å¸Œæœ›æœ€å¤§åŒ–å³æ—¶å¥–åŠ±ï¼Œè¿˜å¸Œæœ› æœ€å¤§åŒ–å…¶éšç€æ—¶é—´çš„æ¨ç§»æ‰€è·å¾—çš„ç´¯ç§¯å¥–åŠ± ã€‚ MDPç¬¦å·è¡¨ç¤º åœ¨ä¸€ä¸ªé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ä¸­ï¼Œæœ‰ä¸€ä¸ªçŠ¶æ€é›†åˆ$S$ï¼ŒåŠ¨ä½œé›†åˆ$A$ï¼Œå¥–åŠ±é›†åˆ$R$ï¼Œä¸”è¿™äº›é›†åˆçš„å…ƒç´ æ˜¯æœ‰é™çš„ã€‚ åœ¨æ¯ä¸€ä¸ªæ—¶é—´æ­¥$t = 0, 1, 2, â€¦$, $Agent$æ¥æ”¶ç¯å¢ƒçš„çŠ¶æ€$S_t \\in S$ï¼ŒåŸºäºå½“å‰çŠ¶æ€$S_t$ï¼Œ$Agent$é€‰æ‹©ä¸€ä¸ªåŠ¨ä½œ$A_t \\in A$ã€‚å½¢æˆä¸€ä¸ªstate-actionå¯¹($S_t, A_t$)ã€‚ æ—¶é—´æ¨ç§»åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥$t + 1$ï¼Œç¯å¢ƒå—åˆ°$Agent$é€‰æ‹©çš„åŠ¨ä½œ$A_t$å½±å“ï¼Œå°†çŠ¶æ€ä»$S_t$è½¬ä¸º$S_{t+1} \\in S$ï¼Œæ­¤æ—¶Agentè·å¾—ä¸€ä¸ªæ•°å€¼å¥–åŠ±$R_{t+1} \\in R$ï¼Œè¯¥å¥–åŠ±æ˜¯å…³äºAgentä»çŠ¶æ€$S_t$é€‰æ‹©åŠ¨ä½œ$A_t$çš„å¥–åŠ±ã€‚å³å¥–åŠ±å‡½æ•°ï¼š$f(S_t, A_t) = R_{t+1}$ $Trajectory: S_0, A_0, R_1, S_1, A_1, R_2, S_2, A_2, R_3, â€¦$ è½¬æ¢æ¦‚ç‡ å› ä¸ºé›†åˆ$S$å’Œ$R$æ˜¯æœ‰é™é›†ï¼Œéšæœºå˜é‡$S_t$å’Œ$R_t$å…·æœ‰æ˜ç¡®å®šä¹‰çš„æ¦‚ç‡åˆ†å¸ƒï¼Œå³ \\begin{equation } p\\left( s&#94;{\\prime },r\\mid s,a\\right) =\\Pr \\left{ S_{t}=s&#94;{\\prime },R_{t}=r\\mid S_{t-1}=s,A_{t-1}=a\\right} \\text{.} \\end{equation } æœŸæœ›å›æŠ¥ æœŸæœ›å¥–åŠ± åœ¨ä¸€ä¸ªMDPè¿‡ç¨‹ä¸­ï¼Œæ˜¯ä»€ä¹ˆé©±åŠ¨å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ï¼Ÿ æœŸæœ›å›æŠ¥ Expected Return åœ¨ä¸€ä¸ªMDPè¿‡ç¨‹ä¸­ï¼Œæ™ºèƒ½ä½“çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–å®ƒçš„æœŸæœ›å¥–åŠ±Reward ã€‚æ•°å­¦è¡¨ç¤ºæ–¹å¼ï¼š å®šä¹‰åœ¨åœ¨$t$æ—¶åˆ»æ‰€è·å¾—çš„æœŸæœ›å¥–åŠ±$G$æ˜¯ï¼š \\begin{equation } G_{t}=R_{t+1}+R_{t+2}+R_{t+3}+\\cdots +R_{T}\\text{,} \\end{equation } $T$æ˜¯æœ€åä¸€ä¸ªæ—¶é—´æ­¥ã€‚ æœŸæœ›å¥–åŠ±çš„æ¦‚å¿µéå¸¸é‡è¦ï¼Œå› ä¸ºè¿™æ˜¯æ™ºèƒ½ä½“çš„ç›®æ ‡å°±æ˜¯æœ€å¤§åŒ–æœŸæœ›å¥–åŠ±ã€‚æœŸæœ›å¥–åŠ±æ˜¯æ¨åŠ¨æ™ºèƒ½ä½“åšå‡ºå†³ç­–çš„åŠ¨åŠ›ã€‚ æŠ˜æ‰£æœŸæœ›å¥–åŠ± åœ¨ä¸€ä¸ªMDPè¿‡ç¨‹ä¸­ï¼Œæ™ºèƒ½ä½“çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–å®ƒçš„æœŸæœ›æŠ˜æ‰£å¥–åŠ±Reward æŠ˜æ‰£ç‡$\\gamma$ï¼Œå–å€¼0~1ä¹‹é—´ï¼Œæ˜¯æŠ˜æ‰£å°†æ¥å¥–åŠ±çš„æ¯”ç‡ã€‚ \\begin{eqnarray } G_{t} &=&R_{t+1}+\\gamma R_{t+2}+\\gamma &#94;{2}R_{t+3}+\\cdots \\ &=&\\sum_{k=0}&#94;{\\infty }\\gamma &#94;{k}R_{t+k+1}\\text{.} \\end{eqnarray } æŠ˜æ‰£å¥–åŠ±çš„å®šä¹‰ä½¿æ™ºèƒ½ä½“æ›´å…³å¿ƒå³æ—¶å¥–åŠ±è€Œä¸æ˜¯æœªæ¥å¥–åŠ±ï¼Œå› ä¸ºæœªæ¥å¥–åŠ±å°†å¾—åˆ°æ›´å¤§çš„æŠ˜æ‰£ã€‚å› æ­¤ï¼Œå°½ç®¡æ™ºèƒ½ä½“ç¡®å®è€ƒè™‘äº†é¢„æœŸåœ¨å°†æ¥è·å¾—çš„å¥–åŠ±ï¼Œä½†å½“æ™ºèƒ½ä½“åšå‡ºå…³äºé‡‡å–ç‰¹å®šåŠ¨ä½œçš„å†³å®šæ—¶ï¼Œè¶Šç›´æ¥çš„å¥–åŠ±å°±å…·æœ‰æ›´å¤§çš„å½±å“åŠ›ã€‚ \\begin{eqnarray } G_{t} &=&R_{t+1}+\\gamma R_{t+2}+\\gamma &#94;{2}R_{t+3}+\\gamma &#94;{3}R_{t+4}+\\cdots \\ &=&R_{t+1}+\\gamma \\left( R_{t+2}+\\gamma R_{t+3}+\\gamma &#94;{2}R_{t+4}+\\cdots \\right) \\ &=&R_{t+1}+\\gamma G_{t+1} \\end{eqnarray } ç­–ç•¥ä¸å€¼å‡½æ•° ç­–ç•¥ ç­–ç•¥ï¼šç»™å®šä¸€ä¸ªçŠ¶æ€ï¼Œæ™ºèƒ½ä½“é€‰æ‹©ä»»æ„ä¸€ä¸ªåŠ¨ä½œçš„æ¦‚ç‡æ˜¯å¤šå°‘ã€‚ ç­–ç•¥ç”¨ç¬¦å·$\\pi$è¡¨ç¤ºï¼Œ$\\pi(a|s)$ï¼šåœ¨$t$æ—¶åˆ»ï¼Œ$\\pi$ç­–ç•¥ä¸‹ï¼Œç»™å®šçŠ¶æ€$s$é€‰æ‹©åŠ¨ä½œ$a$çš„æ¦‚ç‡æ˜¯$\\pi(a|s)$ã€‚$\\pi$æ˜¯åŠ¨ä½œ$a$çš„æ¦‚ç‡åˆ†å¸ƒã€‚ Qå€¼å‡½æ•° Value Functions, which generally give us an idea of how good some given state-action pair is for an agent in terms of expected reward. å€¼å‡½æ•°ï¼šæ™ºèƒ½ä½“é€‰æ‹©æŸä¸€ä¸ªçŠ¶æ€æœ‰å¤šå¥½ã€‚ä»rewardçš„è§’åº¦çœ‹å°±æ˜¯ï¼Œåœ¨ç»™å®šä¸€ä¸ªçŠ¶æ€é€‰æ‹©ä¸€ä¸ªåŠ¨ä½œå¯èƒ½å¢åŠ æˆ–è€…å‡å°‘rewardã€‚ åŠ¨ä½œå€¼å‡½æ•°ï¼š$q_\\pi$è¡¨ç¤ºåŸºäºç­–ç•¥$\\pi$çš„åŠ¨ä½œå€¼å‡½æ•°ã€‚å³ åœ¨ç»™å®šä¸€ä¸ªçŠ¶æ€ï¼ŒåŸºäºç­–ç•¥$\\pi$é€‰æ‹©ä¸€ä¸ªåŠ¨ä½œåï¼Œç»™å®šçš„å€¼ï¼Œè¿™ä¸ªå€¼ç”¨æ¥è¯„ä»·é€‰æ‹©è¯¥åŠ¨ä½œæœ‰å¤šå¥½ã€‚å€¼ç”¨æœŸæœ›å¥–åŠ±å®šä¹‰ $q_\\pi$ç§°Qå€¼å‡½æ•°ï¼ŒQ: quality \\begin{eqnarray } q_{\\pi }\\left( s,a\\right) &=&E_{\\pi }\\left[ G_{t}\\mid S_{t}=s,A_{t}=a \\rule[-0.05in]{0in}{0.2in}\\right] \\ &=&E_{\\pi }\\left[ \\sum_{k=0}&#94;{\\infty }\\gamma &#94;{k}R_{t+k+1}\\mid S_{t}=s,A_{t}=a\\right] \\text{.} \\end{eqnarray } æœ€ä¼˜ç­–ç•¥ ä»€ä¹ˆæ˜¯æœ€ä¼˜ç­–ç•¥ï¼Ÿ \\begin{equation }\\pi \\geq \\pi&#94;\\prime \\text{ if and only if } q_{Ï€}(s, a) \\geq q_{Ï€&#94;\\prime}(s, a) \\text{ for all } s\\in\\boldsymbol{S}\\text{.} \\end{equation } å¯¹äºæ‰€æœ‰çŠ¶æ€$s$ï¼Œå½“ä¸”ä»…å½“åŸºäºç­–ç•¥$\\pi$çš„å€¼å‡½æ•°å‡å¤§äºå…¶ä»–æ‰€æœ‰ç­–ç•¥$\\pi&#94;\\prime$çš„å€¼å‡½æ•°æ—¶ï¼Œè¿™ä¸ªç­–ç•¥$\\pi$å°±æ˜¯æœ€ä¼˜æµ‹ç­–ç•¥ã€‚ æœ€ä¼˜Qå€¼å‡½æ•° ç›¸ä¼¼çš„ï¼Œ æœ€ä¼˜ç­–ç•¥æœ‰ä¸€ä¸ªæœ€ä¼˜åŠ¨ä½œå€¼å‡½æ•°ï¼Œå³æœ€ä¼˜Qå€¼å‡½æ•°ï¼Œ$q_*$è¡¨ç¤ºã€‚ \\begin{equation } q_{\\ast }\\left( s,a\\right) =\\max_{\\pi }q_{\\pi }\\left( s,a\\right) \\end{equation } $q_*$è¡¨ç¤ºå¯¹äºç»™å®šçŠ¶æ€åŠ¨ä½œå¯¹ï¼Œè¯¥ç­–ç•¥æ¯”ä»»ä½•å…¶ä»–ç­–ç•¥æ›´èƒ½è·å¾—æœ€å¤§æœŸæœ›å¥–åŠ±ã€‚ è´å°”æ›¼æœ€ä¼˜æ–¹ç¨‹ $q_*$æœ€ä¼˜Qå€¼å‡½æ•°çš„åŸºæœ¬å±æ€§ï¼Œæ»¡è¶³è´å°”æ›¼æœ€ä¼˜æ–¹ç¨‹ï¼š \\begin{eqnarray } q_{\\ast }\\left( s,a\\right) &=&E\\left[ R_{t+1}+\\gamma \\max_{a&#94;{\\prime }}q_{\\ast }\\left( s&#94;\\prime,a&#94;{\\prime }\\right)\\right] \\end{eqnarray }","tags":"NLP","url":"articles/reinforcement-learning.html","loc":"articles/reinforcement-learning.html"},{"title":"A* Heuristic Algorithm","text":"#include <algorithm> // for sort #include <fstream> #include <iostream> #include <sstream> #include <string> #include <vector> using std :: cout ; using std :: ifstream ; using std :: istringstream ; using std :: sort ; using std :: string ; using std :: vector ; using std :: abs ; // TODO: Add kStart and KFinish enumerators to the State enum. enum class State { kStart , kFinish , kEmpty , kObstacle , kClosed , kPath }; // directional deltas const int delta [ 4 ][ 2 ]{{ -1 , 0 }, { 0 , -1 }, { 1 , 0 }, { 0 , 1 }}; vector < State > ParseLine ( string line ) { istringstream sline ( line ); int n ; char c ; vector < State > row ; while ( sline >> n >> c && c == ',' ) { if ( n == 0 ) { row . push_back ( State :: kEmpty ); } else { row . push_back ( State :: kObstacle ); } } return row ; } vector < vector < State >> ReadBoardFile ( string path ) { ifstream myfile ( path ); vector < vector < State >> board {}; if ( myfile ) { string line ; while ( getline ( myfile , line )) { vector < State > row = ParseLine ( line ); board . push_back ( row ); } } return board ; } /** * Compare the F values of two cells. */ bool Compare ( const vector < int > a , const vector < int > b ) { int f1 = a [ 2 ] + a [ 3 ]; // f1 = g1 + h1 int f2 = b [ 2 ] + b [ 3 ]; // f2 = g2 + h2 return f1 > f2 ; } /** * Sort the two-dimensional vector of ints in descending order. */ void CellSort ( vector < vector < int >> * v ) { sort ( v -> begin (), v -> end (), Compare ); } // Calculate the manhattan distance int Heuristic ( int x1 , int y1 , int x2 , int y2 ) { return abs ( x2 - x1 ) + abs ( y2 - y1 ); } /** * Check that a cell is valid: on the grid, not an obstacle, and clear. */ bool CheckValidCell ( int x , int y , vector < vector < State >> & grid ) { bool on_grid_x = ( x >= 0 && x < grid . size ()); bool on_grid_y = ( y >= 0 && y < grid [ 0 ]. size ()); if ( on_grid_x && on_grid_y ) return grid [ x ][ y ] == State :: kEmpty ; return false ; } /** * Add a node to the open list and mark it as open. */ void AddToOpen ( int x , int y , int g , int h , vector < vector < int >> & openlist , vector < vector < State >> & grid ) { // Add node to open vector, and mark grid cell as closed. openlist . push_back ( vector < int > { x , y , g , h }); grid [ x ][ y ] = State :: kClosed ; } /** * Expand current nodes's neighbors and add them to the open list. */ void ExpandNeighbors ( const vector < int > & current , int goal [ 2 ], vector < vector < int >> & openlist , vector < vector < State >> & grid ) { // Get current node's data. int x = current [ 0 ]; int y = current [ 1 ]; int g = current [ 2 ]; // Loop through current node's potential neighbors. for ( int i = 0 ; i < 4 ; i ++ ) { int x2 = x + delta [ i ][ 0 ]; int y2 = y + delta [ i ][ 1 ]; // Check that the potential neighbor's x2 and y2 values are on the grid and not closed. if ( CheckValidCell ( x2 , y2 , grid )) { // Increment g value and add neighbor to open list. int g2 = g + 1 ; int h2 = Heuristic ( x2 , y2 , goal [ 0 ], goal [ 1 ]); AddToOpen ( x2 , y2 , g2 , h2 , openlist , grid ); } } } /** * Implementation of A* search algorithm */ vector < vector < State >> Search ( vector < vector < State >> grid , int init [ 2 ], int goal [ 2 ]) { // Create the vector of open nodes. vector < vector < int >> open {}; // Initialize the starting node. int x = init [ 0 ]; int y = init [ 1 ]; int g = 0 ; int h = Heuristic ( x , y , goal [ 0 ], goal [ 1 ]); AddToOpen ( x , y , g , h , open , grid ); while ( open . size () > 0 ) { // Get the next node CellSort ( & open ); auto current = open . back (); open . pop_back (); x = current [ 0 ]; y = current [ 1 ]; grid [ x ][ y ] = State :: kPath ; // Check if we're done. if ( x == goal [ 0 ] && y == goal [ 1 ]) { // TODO: Set the init grid cell to kStart, and // set the goal grid cell to kFinish before returning the grid. grid [ init [ 0 ]][ init [ 1 ]] = State :: kStart ; grid [ goal [ 0 ]][ goal [ 1 ]] = State :: kFinish ; return grid ; } // If we're not done, expand search to current node's neighbors. ExpandNeighbors ( current , goal , open , grid ); } // We've run out of new nodes to explore and haven't found a path. cout << \"No path found!\" << \" \\n \" ; return std :: vector < vector < State >> {}; } string CellString ( State cell ) { switch ( cell ) { case State :: kObstacle : return \"â›°ï¸ \" ; case State :: kPath : return \"ğŸš— \" ; case State :: kEmpty : return \"E \" ; case State :: kClosed : return \"C \" ; case State :: kStart : return \"ğŸš¦ \" ; case State :: kFinish : return \"ğŸ \" ; default : return \"? \" ; // TODO: Add cases to return \"ğŸš¦ \" for kStart // and \"ğŸ \" for kFinish. } } void PrintBoard ( const vector < vector < State >> board ) { for ( int i = 0 ; i < board . size (); i ++ ) { for ( int j = 0 ; j < board [ i ]. size (); j ++ ) { cout << CellString ( board [ i ][ j ]); } cout << \" \\n \" ; } } #include \"test.cpp\" int main () { int init [ 2 ]{ 0 , 0 }; int goal [ 2 ]{ 4 , 5 }; auto board = ReadBoardFile ( \"1.board\" ); auto solution = Search ( board , init , goal ); PrintBoard ( solution ); // Tests TestHeuristic (); TestAddToOpen (); TestCompare (); TestSearch (); TestCheckValidCell (); TestExpandNeighbors (); }","tags":"Algorithms","url":"articles/A_star_algorithm.html","loc":"articles/A_star_algorithm.html"},{"title":"Sort","text":"Quick Sort Merge Sort Heap Sort Topological Sort Quick Sort å¼•ä¾‹ï¼šè·å…°å›½æ——é—®é¢˜ Merge Sort class Solution { public : ListNode * sortList ( ListNode * head ) { if ( head == nullptr || head -> next == nullptr ) { return head ; } ListNode * fast = head ; ListNode * slow = head ; while ( fast -> next && fast -> next -> next ) { slow = slow -> next ; fast = fast -> next -> next ; } fast = slow -> next ; slow -> next = nullptr ; return mergeTwoLists ( sortList ( head ), sortList ( fast )); } ListNode * mergeTwoLists ( ListNode * l1 , ListNode * l2 ) { if ( l1 == nullptr && l1 == nullptr ) { return nullptr ; } if ( l1 == nullptr || l2 == nullptr ) { return l1 == nullptr ? l2 : l1 ;} ListNode dummy ( -1 ), * current ; current = & dummy ; while ( l1 && l2 ) { if ( l1 -> val < l2 -> val ) { current -> next = l1 ; l1 = l1 -> next ; } else { current -> next = l2 ; l2 = l2 -> next ; } current = current -> next ; } current -> next = l1 == nullptr ? l2 : l1 ; return dummy . next ; } }; Heap Sort https://docs.python.org/3/library/heapq.html#heapq.heapify æ—¶é—´å¤æ‚åº¦O(N*logN)ï¼Œé¢å¤–ç©ºé—´å¤æ‚åº¦O(1)ã€‚ å †ç»“æ„éå¸¸é‡è¦ å †ç»“æ„çš„ heapInsert å’Œ heapify å †ç»“æ„çš„å¢å¤§å’Œå‡å°‘ å¦‚æœåªæ˜¯å»ºå †çš„è¿‡ç¨‹ï¼Œæ—¶é—´å¤æ‚åº¦ä¸ºO(N) ä¼˜å…ˆçº§é˜Ÿåˆ—ç»“æ„ï¼Œå°±æ˜¯å †ç»“æ„ å †çš„å®šä¹‰ï¼š å †ç»“æ„ å°±æ˜¯ä¸€ä¸ª å®Œå…¨äºŒå‰æ ‘ ï¼Œæ•°ç»„çš„ç»“æ„å®ç°ï¼Œé€šè¿‡çº¦å®šä¸‹æ ‡è§„åˆ™ã€‚ å¯¹äºä»»æ„ä¸‹æ ‡ä¸º i çš„ç»“ç‚¹ï¼Œ å·¦å­©å­ï¼š 2*i + 1 å³å­©å­ï¼š 2*i + 2 çˆ¶èŠ‚ç‚¹ï¼š (i-1) // 2 å¤§æ ¹å † ï¼šåœ¨ä¸€æ£µå®Œå…¨äºŒå‰æ ‘ä¸­ï¼Œä»»ä½•ä¸€æ£µå­æ ‘çš„æœ€å¤§å€¼éƒ½æ˜¯è¿™æ£µå­æ ‘çš„æ ¹ï¼Œæ‰€å½¢æˆçš„ç»“æ„å«å¤§æ ¹å †ã€‚å°æ ¹å †ç±»ä¼¼ã€‚ å †çš„ç‰¹ç‚¹ä¸ä¼˜åŠ¿ï¼š å¤§/å°æ ¹å †æœ‰ä¸€ä¸ªå¾ˆé‡è¦çš„å±æ€§ï¼šå®ƒçš„æœ€å¤§/å°å…ƒç´ å§‹ç»ˆæ˜¯æ ¹èŠ‚ç‚¹ heap[0] ã€‚ å †çš„è°ƒæ•´ä»£ä»·åªå’Œ å±‚æ•° æœ‰å…³ï¼Œæ‰€ä»¥ å…¥å † å’Œ å‡ºå † çš„ä»£ä»·åªæœ‰ O(lgN) ã€‚ å¤§æ ¹å †çš„å®ç°ï¼š This implementation uses arrays for which heap[i] > heap[2*i+1] and heap[i] > heap[2*i+2] for all i , counting elements from zero. ç»™å®šæ•°ç»„ï¼Œéƒ½å¯æ ¹æ®çº¦å®š è§†å…¶ä¸ºå † ï¼Œä½†å…¶ä¸æ˜¯å¤§æ ¹å †ï¼Œ å¦‚ä½•å°†æ•°ç»„è°ƒæ•´ä¸ºå¤§æ ¹å † ï¼Ÿ å»ºç«‹å¤§æ ¹å †ï¼š heapInsert : ç»å†ä¸€ä¸ªæ–°ç»“ç‚¹åŠ å…¥ä¸€ä¸ªå·²ç»è°ƒæ•´å¥½çš„å †ä¸­ï¼ŒåŒæ—¶å¾€ä¸Šè°ƒæ•´çš„è¿‡ç¨‹ã€‚è°ƒæ•´åœæ­¢æ¡ä»¶ï¼šå½“åŠ å…¥ç»“ç‚¹å€¼ä¸å¤§äºå…¶çˆ¶èŠ‚ç‚¹æ—¶ï¼Œ è°ƒæ•´åœæ­¢ã€‚ å †åœ¨æ•°ç»„ä¸Šå¯ä¼¸ç¼© def insertHeap ( arr , index ) : par_i = ( index - 1 ) // 2 while par_i >= 0 and arr [ index ] > arr [ par_i ] : # æ’å…¥ç»“ç‚¹å€¼æ¯”çˆ¶ç»“ç‚¹å¤§æ—¶ ï¼Œ å¾€ä¸Šè°ƒæ•´ arr [ index ] , arr [ par_i ] = arr [ par_i ] , arr [ index ] # ä¸çˆ¶ç»“ç‚¹äº¤æ¢ index = par_i # æ’å…¥ç»“ç‚¹æ¥åˆ°çˆ¶èŠ‚ç‚¹çš„ä½ç½® par_i = ( index - 1 ) // 2 def createHeap ( arr ) : if arr == None or len ( arr ) < 2 : return arr for i in range ( len ( arr )) : # ä¾æ¬¡å°†ç»“ç‚¹åŠ å…¥å †ä¸­ ï¼Œ æœ€ç»ˆå°†æ•°ç»„ ï¼ˆ å † ï¼‰ è°ƒæ•´ä¸ºå¤§æ ¹å † insertHeap ( arr , i ) return arr æ—¶é—´å¤æ‚åº¦åˆ†æï¼š O(N) å½“ç¬¬ i ä¸ªç»“ç‚¹åŠ å…¥å †ä¸­æ—¶ï¼Œ 0 ~ i-1 å·²ç»è°ƒæ•´ä¸ºå¤§æ ¹å †ï¼Œå…¶é«˜åº¦ä¸º O(log(i-1)) ï¼Œå³è°ƒæ•´ä»£ä»·ä¸º O(log(i-1)) ã€‚(æ²¿å…¶çˆ¶ç»“ç‚¹ä¾æ¬¡å‘ä¸Š> æ¯”è¾ƒè°ƒæ•´) æ‰€ä»¥, N ä¸ªç»“ç‚¹çš„è°ƒæ•´ä»£ä»·ä¸ºï¼š O(lg1) + O(lg2) + ... + O(lgN) æ”¶æ•›äº O(N) å †åŒ–ï¼š def heapify ( arr , index , heapSize ) : left = 2 * index + 1 # å·¦å­©å­æœªè¶Šç•Œ ï¼Œ åœ¨å †ä¸Š ï¼Œ ç»§ç»­å¾ªç¯åˆ¤æ–­æ˜¯å¦ä¸‹æ²‰ while left < heapSize : # 1. æ±‚å·¦å³å­©å­æœ€å¤§çš„ä¸‹æ ‡ largest = left + 1 if ( left + 1 ) < heapSize and arr [ left+1 ] > arr [ left ] else left # 2. æœ€å¤§å­©å­å’Œæœ¬ç»“ç‚¹æœ€å¤§çš„ä¸‹æ ‡ largest = index if arr [ index ] >= arr [ largest ] else largest # 3. å¦‚æœæœ€å¤§çš„ç»“ç‚¹å°±æ˜¯è‡ªèº« ï¼Œ heapifyå®Œæˆè·³å‡º if largest == index : break # 4. å¦åˆ™ ï¼Œ äº¤æ¢ä¸‹æ²‰ arr [ largest ] , arr [ index ] = arr [ index ] , arr [ largest ] index = largest left = 2 * index + 1 å †æ’åºï¼š å †å¤§å°ï¼šheapSize = len(arr) æ•°ç»„æœ€åä¸€ä¸ªæ•°ä¸‹æ ‡ï¼šheapSize -= 1 æŠŠæ•°ç»„ arr åˆ›å»ºä¸ºå¤§æ ¹å † å †é¡¶ arr[0] ä¸æ•°ç»„æœ€åä¸€ä¸ªæ•° arr[heapSize] äº¤æ¢ å°†å †çš„å¤§å°ç¼©å° heapSize -= 1 0~heapSize åš heapify è‡³ 2 å¾ªç¯ï¼Œç›´åˆ°å †å¤§å°å‡åˆ°0ï¼Œæ•°ç»„æœ‰åº def heapSort ( arr ) : createHeap ( arr ) heapSize = len ( arr ) while heapSize > 1 : heapSize -= 1 arr [ 0 ] , arr [ heapSize ] = arr [ heapSize ] , arr [ 0 ] heapify ( arr , 0 , heapSize ) Topological Sort # Definition for a Directed graph node class DirectedGraphNode : def __init__ ( self , x ): self . label = x self . neighbors = [] class Solution : \"\"\" @param graph: A list of Directed graph node @return: A list of integer \"\"\" def topSort ( self , graph ): # 1. ç»Ÿè®¡ç»“ç‚¹å…¥åº¦ indegree = self . get_indegree ( graph ) # 2. BFS order = [] start_nodes = [ n for n in graph if indegree [ n ] == 0 ] # å…¥åº¦ä¸º0çš„æ‰€æœ‰ç»“ç‚¹ queue = collections . deque ( start_nodes ) # é˜Ÿåˆ—ä¸­å­˜å‚¨çš„æ˜¯å…¥åº¦ä¸º0çš„ç‚¹ while queue : node = queue . popleft () order . append ( node ) for neighbor in node . neighbors : # éå†è¯¥èŠ‚ç‚¹çš„æ‰€æœ‰é‚»å±…èŠ‚ç‚¹ï¼Œç¬¬ä¸€å±‚éå†ã€‚ indegree [ neighbor ] -= 1 # å°†é˜Ÿåˆ—ä¸­è¾“å‡ºçš„ç‚¹çš„æ‰€ä»¥ä¸´ç•Œç‚¹å…¥åº¦å‡1 if indegree [ neighbor ] == 0 : # å°†å…¥åº¦ä¸º0çš„ç»“ç‚¹æ”¾å…¥é˜Ÿåˆ— queue . append ( neighbor ) return order def get_indegree ( self , graph ): \"\"\" è®¡ç®—æ¯ä¸€ä¸ªç»“ç‚¹çš„å…¥åº¦æ•° \"\"\" indegree = { x : 0 for x in graph } # åˆå§‹åŒ–æ¯ä¸€ä¸ªç»“ç‚¹çš„å…¥åº¦æ•°ä¸º0 for node in graph : for neighbor in node . neighbors : indegree [ neighbor ] += 1 return indegree","tags":"Algorithms","url":"articles/Sort.html","loc":"articles/Sort.html"},{"title":"C++","text":"1. åŸºäºå¯¹è±¡çš„ç¨‹åºè®¾è®¡ 1.1 ä¸å«æŒ‡é’ˆæˆå‘˜çš„ç±» 1.2 å«æœ‰æŒ‡é’ˆæˆå‘˜çš„ç±» 1.3 new 1.4 delete 1.5 this 1.6 static 1.7 å•ä¾‹æ¨¡å¼ 1.8 class template 1.9 function template 2. é¢å‘å¯¹è±¡çš„ç¨‹åºè®¾è®¡ 2.1 ç»„åˆ å®šä¹‰ æ„é€ ä¸ææ„ å†…å­˜è§’åº¦ é€‚é…å™¨æ¨¡å¼ 2.2 å§”æ‰˜ å®šä¹‰ Handle & Body 2.2 ç»§æ‰¿ å®šä¹‰ æ„é€ ä¸ææ„ å«æœ‰è™šå‡½æ•°çš„ç»§æ‰¿ æ¨¡æ¿æ–¹æ³•æ¨¡å¼ 1. åŸºäºå¯¹è±¡çš„ç¨‹åºè®¾è®¡ åªåŒ…å«å•ä¸€ç±»çš„ç¨‹åºè®¾è®¡ï¼Œå­˜åœ¨ä¸¤ç§ç±»å‹çš„ç±»çš„è®¾è®¡æ€æƒ³ï¼šæ˜¯å¦å«æœ‰æŒ‡é’ˆæˆå‘˜ã€‚ ç¼–å†™ç±» class çš„è‰¯å¥½ä¹ æƒ¯ï¼š æ•°æ®ç§æœ‰åŒ– private æ„é€ å‡½æ•°å°½é‡ä½¿ç”¨åˆå§‹åŒ–åˆ—è¡¨ initialization list ï¼Œæ•ˆç‡é«˜ã€‚ å‚æ•°ä¸è¿”å›å€¼å°½é‡å¼•ç”¨ä¼ é€’ by reference ï¼Œè¿”å›çš„å€¼åªè¦ä¸æ˜¯local objectï¼Œå°½é‡ä½¿ç”¨å¼•ç”¨è¿”å›ã€‚ åœ¨ç±»ä½“ä¸­çš„å‡½æ•°éœ€è¦åŠ  const çš„å°½é‡åŠ ï¼Œä¸ä¼šä¿®æ”¹æˆå‘˜å˜é‡ã€‚ 1.1 ä¸å«æŒ‡é’ˆæˆå‘˜çš„ç±» Complex class #ifndef __COMPLEX__ #define __COMPLEX__ class Complex { public : Complex ( double r = 0 , double i = 0 ) : re ( r ), im ( i ) { } Complex & operator += ( const Complex & ); double real () const { return re ; } double imag () const { return im ; } private : double re , im ; friend Complex & __doapl ( Complex & , const Complex & ); }; inline Complex & __doapl ( Complex * ths , const Complex & r ){ ths -> re += r . re ; ths -> im += r . im ; return * ths ; } // class member function inline Complex & Complex :: operator += ( const Complex & r ){ return __doapl ( this , r ); } // class non-member function, global function inline Complex operator + ( const Complex & x , const Complex & y ){ // temporary object, return by value return Complex ( real ( x ) + real ( y ), imag ( x ) + imag ( y )); } inline Complex operator + ( double x , const Complex & y ){ return Complex ( x + real ( y ), imag ( y )); } inline Complex operator + ( const Complex & x , double y ){ return Complex ( real ( x ) + y , imag ( x )); } // class non-member function, global function inline ostream & operator << ( ostream & os , const Complex & r ){ // return by referance due to the example of `cout << c1 << c2 << endl` return std :: cout << '(' << real ( r ) << ' , ' << ' imag ( r ) ' << ')' ; } #endif 1.2 å«æœ‰æŒ‡é’ˆæˆå‘˜çš„ç±» String class #ifndef __MYSTRING__ #define __MYSTRING__ #include <cstring> class String { public : // Big Three String ( const char * cstr ); // constructor func String ( const String & str ); // copy constructor func String & operator = ( const String & str ); // copy asignment func ~ String (); // destructor func char * get_c_str () const { return m_data ; } private : char * m_data ; }; inline String :: String ( const char * cstr = 0 ){ if ( cstr ){ m_data = new char [ strlen ( cstr ) + 1 ]; strcpy ( m_data , cstr ); } else { m_data = new char [ 1 ]; * m_data = '\\0' ; } } inline String :: String ( const String & str ){ m_data = new char [ strlen ( str . m_data ) + 1 ]; strcpy ( m_data , str . m_data ); // deep copy } inline String & String :: operator = ( const String & str ){ // checking self-assignment if ( this == & str ){ return * this ; } delete [] m_data ; // preventing memory leak m_data = new char [ strlen ( str . m_data ) + 1 ]; strcpy ( m_data , str . m_data ); return * this ; } inline String ::~ String (){ delete [] m_data ; } #include <iostream> using namespace std ; ostream & operator << ( ostream & os , const String & str ){ os << str . get_c_str (); return os ; } #endif 1.3 new å…ˆåˆ†é…å†…å­˜ï¼Œå†è°ƒç”¨æ„é€ å‡½æ•°ã€‚ newæ˜¯è¿ç®—ç¬¦ï¼Œå†…éƒ¨è°ƒç”¨Cè¯­è¨€çš„mallocå‡½æ•°ã€‚ Complex* pc = new Complex(1, 2); ç¼–è¯‘å™¨è½¬åŒ–ä¸ºï¼š Complex * pc ; // operator newæ˜¯å‡½æ•°åï¼Œå†…éƒ¨è°ƒç”¨malloc(n) void * mem = operator new ( sizeof ( Complex ) ); // 1. åˆ†é…å†…å­˜ pc = static_cast < Complex *> ( mem ); // 2. ç±»å‹è½¬æ¢ pc -> Complex :: Complex ( 1 , 2 ) // 3. æ„é€ å‡½æ•° // 3ç­‰ä»·äºComplex::Complex(pc, 1, 2); pcå³this 1.4 delete å…ˆè°ƒç”¨ææ„å‡½æ•°ï¼Œå†é‡Šæ”¾å†…å­˜ã€‚ deleteæ˜¯è¿ç®—ç¬¦ï¼Œå†…éƒ¨è°ƒç”¨Cè¯­è¨€çš„freeå‡½æ•°ã€‚ æ³¨æ„ï¼š deleteå­˜åœ¨ä¸¤ä¸ªåˆ é™¤åŠ¨ä½œã€‚1.å…ˆè°ƒç”¨ææ„å‡½æ•°ï¼ŒæŠŠç±»ä¸­åŠ¨æ€åˆ†é…çš„å†…å­˜ç©ºé—´ \"Hello\" åˆ é™¤ï¼›2.å†å°†æŒ‡å‘å­—ç¬¦ä¸²çš„æŒ‡é’ˆ ps åˆ é™¤ã€‚ String * ps = new String ( \"Hello\" ); ... delete ps ; ç¼–è¯‘å™¨è½¬åŒ–ä¸ºï¼š String ::~ String ( ps ); // ææ„å‡½æ•° // operator deleteæ˜¯å‡½æ•°åï¼Œå†…éƒ¨è°ƒç”¨free(ps) operator delete ( ps ); // é‡Šæ”¾å†…å­˜ array new ä¸ array delete æ­é…ä½¿ç”¨ï¼Œå¦åˆ™å­˜åœ¨å†…å­˜æ³„æ¼ã€‚ 1.5 this ç±»çš„æˆå‘˜å‡½æ•°åœ¨å†…å­˜ä¸­åªæœ‰ä¸€ä»½ï¼Œé»˜è®¤å­˜åœ¨thisæŒ‡é’ˆï¼ŒæŒ‡å‘å®ä¾‹åŒ–çš„å¯¹è±¡ï¼Œç±»çš„æˆå‘˜å‡½æ•°æ˜¯é€šè¿‡thisæŒ‡é’ˆæ¥å¤„ç†æ¯ä¸ªå¯¹è±¡å¯¹åº”çš„æ•°æ®ã€‚éšå¼å°†thisæŒ‡é’ˆå³&c1å¯¹è±¡åœ°å€ä½œä¸ºå‚æ•°ä¼ é€’ä¼ é€’ç»™ç±»æˆå‘˜å‡½æ•°ã€‚ Complex c1 , c2 ; c1 . real (); --- > Complex :: real (& c1 ); c2 . real (); --- > Complex :: real (& c2 ); 1.6 static static data members // é™æ€æ•°æ®ï¼Œä¸ç±»çš„å¯¹è±¡è„±ç¦» static member func // é™æ€å‡½æ•°ï¼Œä¸ç±»çš„æˆå‘˜å‡½æ•°ç›¸åŒï¼Œå†…å­˜ä¸­åªå­˜åœ¨ä¸€ä»½ é™æ€å‡½æ•°ä¸ç±»æˆå‘˜å‡½æ•°æœ€å¤§åŒºåˆ«åœ¨äºï¼šæ²¡æœ‰thisæŒ‡é’ˆ class Account { public : static double m_rate ; static void set_rate ( const double & x ) { m_rate = x ; } }; double Account :: m_rate = 8.0 ; // é™æ€æ•°æ®æˆå‘˜ä¸€å®šè¦åœ¨ç±»ä½“å¤–å®šä¹‰ int main () { // é™æ€å‡½æ•°çš„è°ƒç”¨ä¸¤ç§æ–¹æ³• // ç±»åè°ƒç”¨ Account :: set_rate ( 5.0 ); // å¯¹è±¡è°ƒç”¨ Account a ; a . set_rate ( 5.0 ); } 1.7 å•ä¾‹æ¨¡å¼ ä¸€ä¸ªç±»åªå­˜åœ¨ä¸€ä¸ªå¯¹è±¡ï¼Œå®ç°æ–¹æ³•æ˜¯å°†ç±»çš„æ„é€ å™¨ç§æœ‰åŒ–privateä¸staticçš„ç»¼åˆåº”ç”¨ã€‚ class Singleton { public : static Singleton & getInstance () { return a ; } // è·å–å•ä¾‹å¯¹è±¡ã€‚ void setup () { ... } private : Singleton (); // æ„é€ å™¨ç§æœ‰åŒ–ï¼Œå¤–ç•Œç¦æ­¢åˆ›å»ºå¯¹è±¡ã€‚ Signleton ( const Singleton & rhs ); static Singleton a ; // å®šä¹‰å”¯ä¸€ä¸€ä¸ªé™æ€å•åˆ—å¯¹è±¡ã€‚ ... }; Singleton :: getInstance . setup (); // è·å–å•ä¾‹å¯¹è±¡å¹¶è°ƒç”¨å¯¹è±¡çš„ç±»æˆå‘˜å‡½æ•°setup()ã€‚ ä¸Šè¿°å•ä¾‹æ¨¡å¼å¹¶éæœ€ä½³å†™æ³•ï¼Œå¾…ä¼˜åŒ–çš„é—®é¢˜æ˜¯ï¼šå¯¹è±¡aå·²ç»åœ¨å†…å­˜ä¸­æ„å»ºï¼Œå³ä½¿ä¸ä½¿ç”¨ã€‚æœ€ä½³å†™æ³•å¦‚ä¸‹ï¼š class Singleton { public : static Singleton & getInstance (); void setup () { ... } private : Singleton (); Signleton ( const Singleton & rhs ); ... }; // å•ä¾‹å¯¹è±¡aåœ¨ä½¿ç”¨æ—¶å†…å­˜æ„å»ºï¼ŒgetInstanceå‡½æ•°é€€å‡ºæ—¶ï¼Œstaticå˜é‡ä¾ç„¶å­˜åœ¨ã€‚ Single :: getInstance () { static Singleton a ; return a ; } Singleton :: getInstance . setup (); 1.8 class template template template < typename T > class Complex { public : Complex ( T r = 0 , T i = 0 ) : re ( r ), im ( i ) { } Complex & operator += ( const Complex & ); T real () const { return re ; } T imag () const { return im ; } private : T re , im ; friend Complex & __doapl ( Complex & , const Complex & ); }; int main () { // ä»£ç è†¨èƒ€ Complex < double > c1 ( 1.2 , 2.3 ); Complex < int > c1 ( 2 , 3 ); return 0 ; } 1.9 function template template ï¼šç¼–è¯‘å™¨ä¼šå¯¹æ¨¡æ¿å‡½æ•°åšå‚æ•°ç±»å‹æ¨å¯¼ã€‚C++æ ‡å‡†åº“ä¸­ç®—æ³•å‡é‡‡ç”¨å‡½æ•°æ¨¡æ¿ã€‚ template < class T > inline const T & min ( const T & a , const T & b ) { return b < a ? b : a ; } class Stone { public : Stone ( int w , int h , int weight ) : _w ( w ), _h ( h ), _weight ( w ) { } bool operator < ( const Stone & rhs ) const { return _weight < rhs . _weight ; } private : int _w , _h , _weight ; }; int main () { Stone r1 ( 2 , 3 ), r2 ( 3 , 3 ), r3 ; r3 = min ( r1 , r2 ); return 0 ; } ä½¿ç”¨æ—¶ï¼Œ min å‡½æ•°ä¸éœ€è¦åƒç±»æ¨¡æ¿ min<double>(r1, r2) æŒ‡å®šå‚æ•°ï¼Œé€šè¿‡å‚æ•°æ¨å¯¼ã€‚é€šè¿‡æ¨å¯¼ T ä¸º Stone ç±»å‹ï¼Œ b < a è°ƒç”¨å¯¹è±¡ b çš„ç±»å‹ T ä¸­çš„ Stone::operator< ï¼Œå³åœ¨ Stone ç±»ä¸­ã€‚ 2. é¢å‘å¯¹è±¡çš„ç¨‹åºè®¾è®¡ é¢å‘å¤šä¸ªç±»çš„ç¨‹åºè®¾è®¡ï¼Œç±»ä¸ç±»ä¹‹é—´å­˜åœ¨å…³ç³» 2.1 ç»„åˆ å®šä¹‰ ä¸€ä¸ªç±»åŒ…å«å¦ä¸€ä¸ªç±»ï¼Œhas-aå…³ç³»ã€‚å®ç°æ–¹å¼ï¼šä¸€ä¸ªç±»çš„æˆå‘˜å˜é‡ä¸ºå¦ä¸€ä¸ªç±»çš„ç±»å¯¹è±¡ã€‚ æ„é€ ä¸ææ„ ç»„åˆçš„æ„é€ ä¸ææ„ï¼šæ„é€  ç”±å†…è€Œå¤– ï¼Œææ„ ç”±å¤–è€Œå†… å†…å­˜è§’åº¦ ç»„åˆçš„å†…å­˜è§’åº¦ï¼š é€‚é…å™¨æ¨¡å¼ é€‚é…å™¨æ¨¡å¼(Adapter Pattern) æ˜¯ä¸€ç§ç»“æ„å‹è®¾è®¡æ¨¡å¼ï¼Œ å®ƒèƒ½ä½¿æ¥å£ä¸å…¼å®¹çš„å¯¹è±¡èƒ½å¤Ÿç›¸äº’åˆä½œã€‚é€‚é…å™¨æ¨¡å¼å°†ä¸€ä¸ªæ¥å£è½¬æ¢æˆå®¢æˆ·å¸Œæœ›çš„å¦ä¸€ä¸ªæ¥å£ï¼Œé€‚é…å™¨æ¨¡å¼ä½¿æ¥å£ä¸å…¼å®¹çš„é‚£äº›ç±»å¯ä»¥ä¸€èµ·å·¥ä½œï¼Œå…¶åˆ«åä¸ºåŒ…è£…å™¨(Wrapper)ã€‚ queue -> deque ï¼Œè®¾è®¡æ¨¡å¼ï¼šAdapteræ˜¯é€‚é…å™¨æ¨¡å¼ã€‚ é€‚é…å™¨æ¨¡å¼ï¼šç°æœ‰ç±»dequeçš„åŠŸèƒ½å·²ç»æ»¡è¶³å®¢æˆ·éœ€æ±‚ï¼Œä½†æ˜¯dequeç±»çš„åç§°å’Œæ¥å£æ— æ³•æ»¡è¶³å®¢æˆ·ã€‚éœ€è¦ä¸€ä¸ªæ–°çš„queueç±»åŒ…è£…ç°æœ‰çš„dequeç±»ï¼Œé€‚é…æ»¡è¶³å®¢æˆ·çš„æ¥å£å’Œåç§°ã€‚ 2.2 å§”æ‰˜ å®šä¹‰ å§”æ‰˜åˆç§°é€šè¿‡å¼•ç”¨çš„ç»„åˆã€‚ä¸€ä¸ªç±»Stringé€šè¿‡å¼•ç”¨åŒ…å«å¦ä¸€ä¸ªç±»StrigRefçš„æŒ‡é’ˆï¼Œå¹¶éçœŸæ­£æ„ä¹‰ä¸Šçš„åŒ…å«ã€‚ Handle & Body æ€æƒ³ï¼šç§°ä¸ºHandle and Body æˆ– pimplæŒ‡é’ˆå®ç°ã€‚Handleç±»é€šè¿‡æŒ‡é’ˆæŒ‡å‘å®ç°ç±»Bodyã€‚ ä¼˜ç‚¹ï¼šè§£è€¦ã€‚Bodyå®ç°ç±»ä»»æ„å˜åŠ¨ä¸ä¼šå½±å“Handleç«¯ï¼ŒHandleç«¯è¿›è€Œä¹Ÿä¸ä¼šå½±å“å®¢æˆ·ç«¯ã€‚ class String { public : String (); String ( const char * s ); String ( const String & s ); String & Operator = ( const String & s ); ~ String (); private : StringRef * rep ; // pimplè¯¥æ–¹æ³•ç§°ä¸ºæŒ‡é’ˆå®ç° }; namespace { class StringRef { friend class String ; StringRep ( const char * s ); ~ StringRep (); int count ; char * ref ; }; } 2.2 ç»§æ‰¿ å®šä¹‰ å­ç±»å¯¹è±¡åŒ…å«çˆ¶ç±»æˆåˆ†ï¼Œis-aå…³ç³» æ„é€ ä¸ææ„ ç»§æ‰¿ä¸ç»„åˆä¸€æ ·ï¼šæ„é€  ç”±å†…è€Œå¤– ï¼Œææ„ ç”±å¤–è€Œå†… ã€‚å­ç±»æ„é€ å‡½æ•°å…ˆè°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°ï¼Œå†æ‰§è¡Œè‡ªå·±ï¼›å­ç±»çš„ææ„å‡½æ•°å…ˆæ‰§è¡Œè‡ªå·±ï¼Œå†è°ƒç”¨çˆ¶ç±»çš„ææ„å‡½æ•°ã€‚ çˆ¶ç±»çš„ææ„å‡½æ•°ä¸ºä»€ä¹ˆå¿…é¡»æ˜¯è™šå‡½æ•°virtualï¼Ÿ åŸå› ï¼šå½“åŸºç±»æŒ‡é’ˆæŒ‡å‘æ´¾ç”Ÿç±»çš„æ—¶å€™ï¼Œè‹¥åŸºç±»ææ„å‡½æ•°ä¸å£°æ˜ä¸ºè™šå‡½æ•°ï¼Œåœ¨ææ„æ—¶ï¼Œåªä¼šè°ƒç”¨åŸºç±»è€Œä¸ä¼šè°ƒç”¨æ´¾ç”Ÿç±»çš„ææ„å‡½æ•°ï¼Œä»è€Œå¯¼è‡´å†…å­˜æ³„éœ²ã€‚ å«æœ‰è™šå‡½æ•°çš„ç»§æ‰¿ ç»§æ‰¿æœ€é‡è¦çš„æ˜¯éœ€è¦ä¸è™šå‡½æ•°ç»“åˆæ‰èƒ½è¾¾åˆ°å¼ºæœ‰åŠ›çš„æ•ˆæœã€‚ ç±»çš„æˆå‘˜å‡½æ•°åˆ†ä¸ºï¼šéè™šå‡½æ•°ï¼Œè™šå‡½æ•°ï¼Œçº¯è™šå‡½æ•°ã€‚ éè™šå‡½æ•°ï¼šå­ç±»æ˜¯ä¸å¯è¦†ç›–overrideçš„ã€‚ è™šå‡½æ•°ï¼šå­˜åœ¨é»˜è®¤å®šä¹‰ï¼ŒæœŸæœ›å­ç±»è¦†ç›–overrideã€‚ çº¯è™šå‡½æ•°ï¼šä¸å­˜åœ¨é»˜è®¤å®šä¹‰ï¼Œå­ç±»ä¸€å®šéœ€è¦è¦†ç›–overrideã€‚ class Shape { public : virtual draw () const = 0 ; // pure virtual virtual error ( const std :: string & msg ); // impure virtual int objectID () const ; // non-virtual }; class Rectangle : public Shape { ... }; æ¨¡æ¿æ–¹æ³•æ¨¡å¼ æ¨¡æ¿æ–¹æ³•æ¨¡å¼(Template Method Pattern) æ˜¯ä¸€ç§è¡Œä¸ºè®¾è®¡æ¨¡å¼ï¼Œå®ƒåœ¨çˆ¶ç±»ä¸­å®šä¹‰äº†ä¸€ä¸ªç®—æ³•çš„æ¡†æ¶ï¼Œå…è®¸å­ç±»åœ¨ä¸ä¿®æ”¹ç»“æ„çš„æƒ…å†µä¸‹é‡å†™ç®—æ³•çš„ç‰¹å®šæ­¥éª¤ã€‚æ¨¡æ¿æ–¹æ³•æ¨¡å¼ï¼Œå®šä¹‰ä¸€ä¸ªæ“ä½œä¸­çš„ç®—æ³•éª¨æ¶ï¼Œè€Œå°†ä¸€äº›æ­¥éª¤å»¶è¿Ÿåˆ°å­ç±»ä¸­ã€‚æ¨¡æ¿æ–¹æ³•ä½¿å¾—å­ç±»å¯ä»¥ä¸æ”¹å˜ä¸€ä¸ªç®—æ³•çš„ç»“æ„å³å¯é‡æ–°å®šä¹‰è¯¥ç®—æ³•çš„æŸäº›ç‰¹å®šæ­¥éª¤ã€‚ ç»å…¸åœºæ™¯ï¼š åº”ç”¨ç¨‹åºæ¡†æ¶ ä¸­å¤§é‡ä½¿ç”¨æ¨¡æ¿æ–¹æ³•ï¼Œä¸èƒ½ç¡®å®šçš„åŠŸèƒ½è®¾ç½®ä¸ºè™šå‡½æ•°æ¨è¿Ÿåˆ°å­ç±»å®ç°ã€‚ æ¨¡æ¿æ–¹æ³•å°±æ˜¯å›¾ä¸­çš„ OnFileOpen() æ–¹æ³•ï¼Œæ–¹æ³•ä½“å†…çš„ Serialize æ˜¯è™šå‡½æ•°ï¼Œæ¨è¿Ÿåˆ°å­ç±» CMyDoc ä¸­å®ç°ã€‚ å­ç±»çš„å®ç°çš„è™šå‡½æ•°æ˜¯å¦‚ä½•è°ƒç”¨çš„ï¼Ÿ å³å­ç±»å¯¹è±¡è°ƒç”¨çˆ¶ç±»æ–¹æ³•çš„è¿‡ç¨‹ã€‚ å­ç±»å¯¹è±¡ myDoc åœ¨è°ƒç”¨çˆ¶ç±»æ–¹æ³• OnFileOpen æ—¶ï¼Œç¼–è¯‘å™¨ä¼šéšå¼çš„å°†å­ç±»å¯¹è±¡ &myDoc çš„åœ°å€ä¼ é€’ç»™çˆ¶ç±» OnFileOpen(&myDoc) æ–¹æ³•ï¼Œå³ this = &myDoc æŒ‡é’ˆã€‚ çˆ¶ç±» OnFileOpen æ–¹æ³•åœ¨æ‰§è¡Œæ—¶ï¼Œé‡åˆ°è™šå‡½æ•° Serialize å®é™…æ—¶æ‰§è¡Œ this->Serialize() å­ç±»çš„ Serialize() æ–¹æ³•ã€‚ #include <iostream> using namespace std ; class CDocument { public : void OnFileOpen () { // æ¨¡æ¿æ–¹æ³•ï¼Œå­˜åœ¨å°šæœªå®ç°çš„è™šå‡½æ•° // åº”ç”¨ç¨‹åºæ¡†æ¶ï¼Œæ¯ä¸€ä¸ªcoutè¡¨ç¤ºä¸€ä¸ªå®é™…çš„æ“ä½œ cout << \"dialogue ...\" << endl ; cout << \"check file status ...\" << endl ; cout << \"open file ...\" << endl ; Serialize (); cout << \"close file ...\" << endl ; } virtual void Serialize () { }; // æ¨è¿Ÿåˆ°å­ç±»å®ç° }; class CMyDoc : public CDocument { public : virtual void Serialize () { cout << CMyDoc :: Serialize () << endl ; } }; int main () { CMyDoc myDoc ; myDoc . OnFileOpen (); }","tags":"Programming","url":"articles/C++.html","loc":"articles/C++.html"},{"title":"LinkedList","text":"é“¾è¡¨ç»“ç‚¹å®šä¹‰ é“¾è¡¨åŸºæœ¬æ“ä½œ Remove Duplicates from Sorted List Reverse Linked List Merge Two Sorted Lists Merge k Sorted Lists Sort List æ“…ç”¨DummyèŠ‚ç‚¹ Remove Duplicates from Sorted List II Partition List å¿«æ…¢æŒ‡é’ˆ ç»¼åˆè®¾è®¡ LRU Cache GitHub LinkedList é“¾è¡¨ç»“ç‚¹å®šä¹‰ class ListNode { public : int val ; ListNode * next ; ListNode () : val ( 0 ), next ( nullptr ) {} ListNode ( int x ) : val ( x ), next ( nullptr ) {} ListNode ( int x , ListNode * next ) : val ( x ), next ( next ) {} }; é“¾è¡¨åŸºæœ¬æ“ä½œ é“¾è¡¨çš„åŸºæœ¬æ“ä½œä¸æŠ€å·§ï¼Œéœ€è¦ç†Ÿè®°äºå¿ƒï¼Œä¿¡æ‰‹æ‹ˆæ¥ æ’å…¥ã€åˆ é™¤ã€ç¿»è½¬ï¼ˆåŸºç¡€ï¼‰ åˆå¹¶ä¸ä¸­åˆ†ï¼ˆè¿›é˜¶ï¼‰ Remove Duplicates from Sorted List ç”±äºé‡å¤èŠ‚ç‚¹è¦ä¿ç•™ä¸€ä¸ªï¼Œåˆ™ä¸éœ€è¦è€ƒè™‘åˆ é™¤å¤´èŠ‚ç‚¹çš„ç‰¹æ®Šæƒ…å†µã€‚ class Solution : def deleteDuplicates ( self , head : ListNode ) -> ListNode : if not head or not head . next : return head cur = head while cur . next : if cur . val == cur . next . val : cur . next = cur . next . next else : cur = cur . next return head Reverse Linked List Python class Solution : if not head or not head . next : return head pre , cur = None , head while cur : pos = cur . next cur . next = pre pre = cur cur = pos return pre C ++ class Solution { public : ListNode * reverseList ( ListNode * head ){ if ( ! head ) return nullptr ; ListNode * pre , * cur , * post ; cur = head ; pre = nullptr ; while ( cur ){ post = cur -> next ; cur -> next = pre ; pre = cur ; cur = post ; } return pre ; } }; Merge Two Sorted Lists Python class Solution : def mergeTwoLists ( self , l1 , l2 ): dummy = cur = ListNode ( - 1 ) while l1 and l2 : if l1 . val < l2 . val : cur . next = l1 l1 = l1 . next else : cur . next = l2 l2 = l2 . next cur = cur . next cur . next = l1 or l2 return dummy . next C ++ class Solution { public : ListNode * mergeTwoLists ( ListNode * l1 , ListNode * l2 ){ if ( ! l1 && ! l2 ) return nullptr ; if ( ! l1 || ! l2 ) return ! l1 ? l2 : l1 ; ListNode dummy ( -1 ), * current ; current = & dummy ; while ( l1 && l2 ){ if ( l1 -> val < l2 -> val ){ current -> next = l1 ; l1 = l1 -> next ; } else { current -> next = l2 ; l2 = l2 -> next ; } current = current -> next ; } current -> next = l1 == nullptr ? l2 : l1 ; return dummy . next ; } }; Merge k Sorted Lists #include <iostream> #include <vector> using namespace std ; class ListNode { int val ; ListNode * next ; ListNode () : val ( 0 ), next ( nullptr ) { } ListNode ( int val ) : val ( val ), next ( nullptr ) { } ListNode ( int val , ListNode * next ) : val ( val ), next ( next ) { } }; class Solution { public : ListNode * mergeKLists ( vector < ListNode *>& lists ) { /*O(K*N)*/ if ( lists . size () == 0 ) { return nullptr ; } if ( lists . size () == 1 ) { return lists [ 0 ]; } ListNode * res = lists [ 0 ]; int n = lists . size (); for ( int i = 1 ; i < n ; ++ i ) { res = mergeLists ( res , lists [ i ]); } return res ; } ListNode * mergeKLists ( vector < ListNode *>& lists ) { /* æ—¶é—´å¤æ‚åº¦åˆ†æï¼šK æ¡é“¾è¡¨çš„æ€»ç»“ç‚¹æ•°æ˜¯ Nï¼Œå¹³å‡æ¯æ¡é“¾è¡¨æœ‰ N/K ä¸ª * èŠ‚ç‚¹ï¼Œå› æ­¤åˆå¹¶ä¸¤æ¡é“¾è¡¨çš„æ—¶é—´å¤æ‚åº¦æ˜¯ O(N/K)ã€‚ä» K æ¡é“¾è¡¨å¼€å§‹ * ä¸¤ä¸¤åˆå¹¶æˆ 1 æ¡é“¾è¡¨ï¼Œå› æ­¤æ¯æ¡é“¾è¡¨éƒ½ä¼šè¢«åˆå¹¶ logK æ¬¡ï¼Œå› æ­¤ K * æ¡é“¾è¡¨ä¼šè¢«åˆå¹¶ K * logK æ¬¡ï¼Œå› æ­¤æ€»å…±çš„æ—¶é—´å¤æ‚åº¦æ˜¯ K*logK*N/K * å³ Oï¼ˆNlogKï¼‰ã€‚*/ return partition ( lists , 0 , lists . size () - 1 ); } ListNode * partition ( vector < ListNode *>& lists , int start , int end ) { if ( start > end ) {{ return nullptr ; } if ( start == end ) { return lists [ start ]; } if ( start < end ) { int mid = start + (( end - start ) >> 1 ); ListNode * l = partition ( lists , start , mid ); ListNode * r = partition ( lists , mid + 1 , end ); return mergeTwoLists ( l , r ); } return nullptr ; } ListNode * mergeTwoLists ( ListNode * l1 , ListNode * l2 ){ if ( l1 == nullptr && l2 == nullptr ) { return nullptr ; } if ( l1 == nullptr ) { return l2 ; } if ( l2 == nullptr ) { return l1 ; } ListNode dummy ( -1 ), * cur ; cur = & dummy ; while ( l1 && l2 ) { if ( l1 -> val < l2 -> val ) { cur -> next = l1 ; l1 = l1 -> next ; } else { cur -> next = l2 ; l2 = l2 -> next ; } cur = cur -> next ; } cur -> next = l1 == nullptr ? l2 : l1 ; return dummy . next ; } }; Sort List class Solution { public : ListNode * sortList ( ListNode * head ) { if ( head == nullptr || head -> next == nullptr ) { return head ; } ListNode * fast = head ; ListNode * slow = head ; while ( fast -> next && fast -> next -> next ) { slow = slow -> next ; fast = fast -> next -> next ; } fast = slow -> next ; slow -> next = nullptr ; return mergeTwoLists ( sortList ( head ), sortList ( fast )); } ListNode * mergeTwoLists ( ListNode * l1 , ListNode * l2 ) { if ( l1 == nullptr && l1 == nullptr ) { return nullptr ; } if ( l1 == nullptr || l2 == nullptr ) { return l1 == nullptr ? l2 : l1 ;} ListNode dummy ( -1 ), * current ; current = & dummy ; while ( l1 && l2 ) { if ( l1 -> val < l2 -> val ) { current -> next = l1 ; l1 = l1 -> next ; } else { current -> next = l2 ; l2 = l2 -> next ; } current = current -> next ; } current -> next = l1 == nullptr ? l2 : l1 ; return dummy . next ; } }; æ“…ç”¨DummyèŠ‚ç‚¹ ä»¥ä¸‹ä¸¤ç§æƒ…å†µä¸‹éœ€è¦ä½¿ç”¨ Dummy Node ï¼š å½“é“¾è¡¨çš„ç»“æ„å‘ç”Ÿå˜åŒ–æ—¶ å½“éœ€è¦è¿”å›çš„é“¾è¡¨å¤´ä¸ç¡®å®šæ—¶ Remove Duplicates from Sorted List II é‡è¦!!! ç”±äºè¦åˆ æ‰æ‰€æœ‰çš„é‡å¤é¡¹ï¼Œå¤´èŠ‚ç‚¹ä¹Ÿå¯èƒ½è¢«åˆ é™¤ï¼Œè€Œæœ€ç»ˆå´è¿˜éœ€è¦è¿”å›é“¾è¡¨çš„å¤´èŠ‚ç‚¹ï¼Œæ‰€ä»¥å®šä¹‰ä¸€ä¸ªæ–°çš„èŠ‚ç‚¹dummyé“¾ä¸ŠåŸé“¾è¡¨æ¥ç®€åŒ–ã€‚ dummy = p = ListNode(-1) p = p.next dummy.next class Solution : def deleteDuplicates ( self , head : ListNode ) -> ListNode : if not head or not head . next : return head dummy = p = ListNode ( - 1 ) # dummyå’Œpæ˜¯è¿™ä¸ªèŠ‚ç‚¹çš„å¼•ç”¨ dummy . next = head # dummyä¸på¼•ç”¨çš„èŠ‚ç‚¹nextæŒ‡é’ˆå‡æŒ‡å‘äº†headèŠ‚ç‚¹ while p . next and p . next . next : if p . next . val == p . next . next . val : sameVal = p . next . val while p . next and p . next . val == sameVal : p . next = p . next . next # åœ¨dummyä¸pä¾æ—§å¼•ç”¨åŒä¸€ä¸ªèŠ‚ç‚¹çš„æƒ…å†µä¸‹ï¼Œdummyä¸påŒæ—¶ä¿®æ”¹nextæŒ‡é’ˆ else : p = p . next # på¼•ç”¨é‡æ–°æŒ‡å‘ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ï¼Œdummyä¸å˜ return dummy . next # æ‰€ä»¥dummy.nextèƒ½å¤Ÿä¿æŒæ€»æ˜¯æŒ‡å‘ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ Partition List more.next = None ï¼šååŠæ®µçš„é“¾è¡¨ï¼Œå°¾èŠ‚ç‚¹çš„ next æŒ‡é’ˆè¦è®¾ç½®ä¸º None ï¼ class Solution : def partition ( self , head : ListNode , x : int ) -> ListNode : if not head and not head . next : return head dummy1 = less = ListNode ( - 1 ) dummy2 = more = ListNode ( - 1 ) while head : if head . val < x : less . next = head less = head else : more . next = head more = head head = head . next more . next = None # Note!!! less . next = dummy2 . next return dummy1 . next Error : dummy1 = dummy2 = ListNode ( - 1 ) # å¼•ç”¨åŒä¸€ä¸ªå¯¹è±¡ï¼ less = dummy1 more = dummy2 Right : dummy1 = less = ListNode ( - 1 ) dummy2 = more = ListNode ( - 1 ) å¿«æ…¢æŒ‡é’ˆ ç»¼åˆè®¾è®¡ LRU Cache åˆ†æï¼šä¸ºäº†ä¿æŒcacheçš„æ€§èƒ½ï¼Œä½¿æŸ¥æ‰¾ï¼Œæ’å…¥ï¼Œåˆ é™¤éƒ½æœ‰è¾ƒé«˜çš„æ€§èƒ½ï¼Œæˆ‘ä»¬ä½¿ç”¨ åŒå‘é“¾è¡¨ å’Œ å“ˆå¸Œè¡¨ ä½œä¸ºcacheçš„æ•°æ®ç»“æ„ï¼Œå› ä¸ºï¼š åŒå‘é“¾è¡¨ æ’å…¥ å’Œ åˆ é™¤ æ•ˆç‡é«˜ å“ˆå¸Œè¡¨ä¿å­˜æ¯ä¸ªèŠ‚ç‚¹çš„åœ°å€ï¼Œå¯ä»¥åŸºæœ¬ä¿è¯åœ¨O(1)æ—¶é—´å†… æŸ¥æ‰¾ èŠ‚ç‚¹ å…·ä½“å®ç°ç»†èŠ‚ï¼š è¶Šé è¿‘é“¾è¡¨å¤´éƒ¨ï¼Œè¡¨ç¤ºèŠ‚ç‚¹ä¸Šæ¬¡è®¿é—®è·ç¦»ç°åœ¨æ—¶é—´æœ€çŸ­ï¼Œå°¾éƒ¨çš„èŠ‚ç‚¹è¡¨ç¤ºæœ€è¿‘è®¿é—®æœ€å°‘ æŸ¥è¯¢æˆ–è€…è®¿é—®èŠ‚ç‚¹æ—¶ï¼Œå¦‚æœèŠ‚ç‚¹å­˜åœ¨ï¼ŒæŠŠè¯¥èŠ‚ç‚¹äº¤æ¢åˆ°é“¾è¡¨å¤´éƒ¨ï¼ŒåŒæ—¶æ›´æ–°hashè¡¨ä¸­è¯¥èŠ‚ç‚¹çš„åœ°å€ æ’å…¥èŠ‚ç‚¹æ—¶ï¼Œå¦‚æœcacheçš„sizeè¾¾åˆ°äº†ä¸Šé™ï¼Œåˆ™åˆ é™¤å°¾éƒ¨èŠ‚ç‚¹ï¼ŒåŒæ—¶è¦åœ¨hashè¡¨ä¸­åˆ é™¤å¯¹åº”çš„é¡¹ã€‚æ–°èŠ‚ç‚¹éƒ½æ’å…¥é“¾è¡¨å¤´éƒ¨ã€‚ æ³¨æ„ï¼š è¿™é¢˜æ›´å¤šçš„æ˜¯è€ƒå¯Ÿç”¨æ•°æ®ç»“æ„è¿›è¡Œè®¾è®¡çš„èƒ½åŠ›ï¼Œåœ¨å†™ä»£ç æ—¶å°½é‡å°†å­å‡½æ•°æ‹†åˆ†å‡ºæ¥ï¼Œå…ˆå†™ä¸ªæ•´ä½“çš„æ¡†æ¶ã€‚ ç§»å‡ºé“¾è¡¨æœ€åä¸€ä¸ªèŠ‚ç‚¹æ—¶ï¼Œè¦è®°å¾—åœ¨é“¾è¡¨å’Œå“ˆå¸Œè¡¨ä¸­éƒ½ç§»å‡ºè¯¥å…ƒç´ ï¼Œæ‰€ä»¥èŠ‚ç‚¹ä¸­ä¹Ÿè¦è®°å½•Keyçš„ä¿¡æ¯ï¼Œæ–¹ä¾¿åœ¨å“ˆå¸Œè¡¨ä¸­ç§»é™¤ å¤´å°¾èŠ‚ç‚¹é‡‡ç”¨dummyçš„æŠ€å·§ï¼Œæå¤§ç®€åŒ–ç¨‹åºã€‚ class ListNode (): def __init__ ( self , key , val ): self . key = key # è®°å½•Keyçš„ä¿¡æ¯ï¼Œæ–¹ä¾¿åœ¨å“ˆå¸Œè¡¨ä¸­ç§»é™¤ self . val = val self . pre = None self . next = None class DoubleLinkedList (): def __init__ ( self ): self . head = ListNode ( - 1 , - 1 ) # dummy head node æå¤§ç®€åŒ–äº†ç¨‹åºå¤´å°¾çš„å¤„ç† self . tail = ListNode ( - 1 , - 1 ) # dummy tail node self . head . next = self . tail self . tail . pre = self . head def insertHead ( self , node ): '''å¤´æ’æ³• ''' node . next = self . head . next node . pre = self . head self . head . next . pre = node self . head . next = node def removeNode ( self , node ): '''åˆ é™¤ä»»æ„ä¸€ä¸ªæŒ‡å®šèŠ‚ç‚¹ ''' node . pre . next = node . next node . next . pre = node . pre def removeTailNode ( self ): '''åˆ é™¤å°¾èŠ‚ç‚¹ï¼Œå°¾èŠ‚ç‚¹æ˜¯æœ€ä¹…æœªä½¿ç”¨çš„ ''' removeNode = self . tail . pre self . removeNode ( removeNode ) class LRUCache : def __init__ ( self , capacity : int ): self . cache = DoubleLinkedList () self . map = {} # åŠ å¿«æœç´¢é€Ÿåº¦ï¼š{keyï¼šå¯¹åº”èŠ‚ç‚¹çš„åœ°å€} self . cap = capacity # LRU Cacheçš„å®¹é‡å¤§å° def get ( self , key : int ) -> int : '''æŸ¥è¯¢æ“ä½œ ''' if key not in self . map : return - 1 node = self . map [ key ] # keyåœ¨å­—å…¸ä¸­ self . cache . removeNode ( node ) # å°†keyå¯¹åº”çš„èŠ‚ç‚¹åˆ é™¤ self . cache . insertHead ( node ) # ç„¶åå°†è¿™ä¸ªèŠ‚ç‚¹æ·»åŠ åˆ°åŒå‘é“¾è¡¨å¤´éƒ¨ return node . val # å¹¶è¿”å›èŠ‚ç‚¹çš„value def put ( self , key : int , value : int ) -> None : ''' 1. è®¾ç½®valueã€‚ 2. å¦‚æœkeyä¸å­˜åœ¨åˆ™æ’å…¥valueï¼Œéœ€æ³¨æ„cacheå®¹é‡ã€‚ ''' if key in self . map : # å¦‚æœkeyåœ¨å­—å…¸ä¸­ node = self . map [ key ] self . cache . removeNode ( node ) #å…ˆåœ¨é“¾è¡¨cacheä¸­åˆ æ‰keyå¯¹åº”çš„èŠ‚ç‚¹ self . cache . insertHead ( node ) # ç„¶åå°†è¿™ä¸ªèŠ‚ç‚¹æ’å…¥åˆ°é“¾è¡¨çš„å¤´éƒ¨ node . val = value # å°†è¿™ä¸ªèŠ‚ç‚¹çš„å€¼valæ”¹å†™ä¸ºvalue else : node = ListNode ( key , value ) # æ–°å»ºä¸€ä¸ªNodeèŠ‚ç‚¹ï¼Œvalå€¼ä¸ºvalue self . map [ key ] = node # å°†keyå’Œnodeçš„å¯¹åº”å…³ç³»æ·»åŠ åˆ°å­—å…¸ä¸­ self . cache . insertHead ( node ) # å°†è¿™ä¸ªèŠ‚ç‚¹æ·»åŠ åˆ°é“¾è¡¨è¡¨å¤´ if len ( self . map ) > self . cap : del self . map [ self . cache . tail . pre . key ] self . cache . removeTailNode ()","tags":"Algorithms","url":"articles/LinkedList.html","loc":"articles/LinkedList.html"},{"title":"ã€ RL ã€‘Q Learning","text":"Training Inference import numpy as np import gym import random import time from IPython.display import clear_output \"\"\"Creating the Environment\"\"\" env = gym . make ( \"FrozenLake-v0\" ) \"\"\"Creating the Q-Table and initializing all the Q-Values to zero for each state-action pair.\"\"\" action_space_size = env . action_space . n state_space_size = env . observation_space . n q_table = np . zeros (( state_space_size , action_space_size )) q_table array([[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]]) \"\"\"Initializing the parametres for Q-Learning algorithm\"\"\" num_episodes = 10000 max_steps_per_episode = 100 learning_rate = 0.1 discount_rate = 0.99 # for exploration-exploitation trade-off: epsilon-greedy policy exploration_rate = 1 max_exploration_rate = 1 min_exploration_rate = 0.01 exploration_decay_rate = 0.001 Training rewards_all_episodes = [] # Q-Learning algorithm for episode in range ( num_episodes ): # initialize new episode parameter state = env . reset () done = False rewards_current_episode = 0 for step in range ( max_steps_per_episode ): # exploration-exploitation trade-off: agent explores or # exploits the environment in this time-step. exploration_rate_threshold = random . uniform ( 0 , 1 ) if exploration_rate_threshold > exploration_rate : action = np . argmax ( q_table [ state , :]) # print(\"policy action: {}\".format(action)) else : action = env . action_space . sample () # print(\"random action: {}\".format(action)) # taking action new_state , reward , done , info = env . step ( action ) # Update Q-Table for Q(s, a) q_table [ state , action ] = ( 1 - learning_rate ) * q_table [ state , action ] \\ + learning_rate * ( reward + discount_rate * np . max ( q_table [ new_state , :])) # transition to the next state state = new_state rewards_current_episode += reward if done is True : break # exploration rate decay exploration_rate = min_exploration_rate + ( max_exploration_rate - min_exploration_rate ) \\ * np . exp ( - exploration_decay_rate * episode ) rewards_all_episodes . append ( rewards_current_episode ) # Calculate and print the average reward per thousand episodes rewards_per_thosand_episodes = np . split ( np . array ( rewards_all_episodes ), num_episodes / 1000 ) count = 1000 for r in rewards_per_thosand_episodes : print ( count , \": \" , str ( sum ( r / 1000 ))) count += 1000 ********Average reward per thousand episodes******** 1000 : 0.057000000000000044 2000 : 0.21100000000000016 3000 : 0.3760000000000003 4000 : 0.5990000000000004 5000 : 0.6180000000000004 6000 : 0.6640000000000005 7000 : 0.6830000000000005 8000 : 0.6610000000000005 9000 : 0.6620000000000005 10000 : 0.6840000000000005 q_table array([[0.57489904, 0.52079771, 0.51748556, 0.48793235], [0.42212101, 0.26917985, 0.34271382, 0.5203443 ], [0.41164658, 0.4280145 , 0.40879341, 0.48422459], [0.32569816, 0.37293149, 0.36049325, 0.46078178], [0.59779375, 0.39344761, 0.32263887, 0.28641992], [0. , 0. , 0. , 0. ], [0.29567781, 0.13502175, 0.22982768, 0.21277447], [0. , 0. , 0. , 0. ], [0.35598767, 0.48995879, 0.42166608, 0.62406041], [0.45348018, 0.70820025, 0.49994856, 0.49117507], [0.58119802, 0.44345026, 0.26892586, 0.38122787], [0. , 0. , 0. , 0. ], [0. , 0. , 0. , 0. ], [0.33119261, 0.66936184, 0.77995132, 0.48286706], [0.72566318, 0.8968122 , 0.70399676, 0.7334053 ], [0. , 0. , 0. , 0. ]]) Inference # The Q-Table is the konwledge we gained by training. # agent choose the best action from each state according to the Q-Table. for episode in range ( 3 ): state = env . reset () done = False print ( \"EPISODE {} \" . format ( episode + 1 )) time . sleep ( 1 ) for step in range ( max_steps_per_episode ): # show the current state of environment on screen. env . render () time . sleep ( 0.3 ) clear_output ( wait = True ) # choose action with highest Q-Value for current state. action = np . argmax ( q_table [ state , :]) # update the state, reward, done for the action. new_state , reward , done , info = env . step ( action ) if done : clear_output ( wait = True ) env . render () if reward == 1 : print ( \"Reached the goal!\" ) time . sleep ( 3 ) clear_output ( wait = True ) else : print ( \"Fell the hole!\" ) time . sleep ( 3 ) clear_output ( wait = True ) break state = new_state env . close () (Down) SFFF FHFH FFFH HFF\u001b[41mG\u001b[0m Reached the goal!","tags":"NLP","url":"articles/ã€RLã€‘Q-Learning.html","loc":"articles/ã€RLã€‘Q-Learning.html"},{"title":"Algorithms","text":"Linked List 206. Reverse Linked List 21. Merge Two Sorted Lists 234. Palindrome Linked List 19. Remove Nth Node From End of List Search DFS 695. Max Area of Island 547. Number of Provinces 417. Pacific Atlantic Water Flow Backtracking 46. Permutations 77. Combinations 79. Word Search Linked List 206. Reverse Linked List class ListNode : def __init__ ( self , val ): self . val = val self . next = None class Solution : def reverseLinkedList ( self , head : ListNode ) -> ListNode : if not head or not head . next : return head pre , cur , post = None , head , head . next while cur : post = cur . next cur . next = pre pre = cur cur = post return pre 21. Merge Two Sorted Lists class ListNode : def __init__ ( self , val : int ): self . val = val self . next = None class Solution : def mergeTwoLists ( self , l1 : ListNode , l2 : ListNode ) -> ListNode : if not l1 and not l2 : return None if not l1 : return l2 if not l2 : return l1 dummpy = cur = ListNode ( - 1 ) while l1 and l2 : if l1 . val < l2 . val : cur . next = l1 l1 = l1 . next else : cur . next = l2 l2 = l2 . next cur = cur . next cur . next = l1 or l2 return dummpy . next 234. Palindrome Linked List class Solution : def isPalindrome ( self , head : ListNode ) -> bool : slow = fast = head while fast and fast . next : slow = slow . next fast = fast . next . next fast = head slow = self . reverseLinkedList ( slow ) while slow : if fast . val != slow . val : return False fast = fast . next slow = slow . next return True def reverseLinkedList ( self , head : ListNode ) -> ListNode : pre , cur = None , head while cur : post = cur . next cur . next = pre pre = cur cur = post return pre 19. Remove Nth Node From End of List class Solution : def removeNthFromEnd ( self , head : ListNode , n : int ) -> ListNode : dummpy = slow = fast = ListNode ( - 1 ) fast . next = head for _ in range ( n + 1 ): fast = fast . next while fast : fast = fast . next slow = slow . next slow . next = slow . next . next return dummpy . next Search DFS 695. Max Area of Island class Solution : \"\"\"O(M*N)ï¼šæ‰€æœ‰èŠ‚ç‚¹åªéå†ä¸€æ¬¡ã€‚ M*Nä¸ªèŠ‚ç‚¹ï¼›æ¯ä¸ªèŠ‚ç‚¹æœ‰4æ¡è¾¹ã€‚ \"\"\" def maxAreaOfIsland ( self , grid : List [ List [ int ]]) -> int : if not grid : return 0 row , col = len ( grid ), len ( grid [ 0 ]) max_area = 0 for i in range ( row ): for j in range ( col ): max_area = max ( max_area , self . dfs ( grid , i , j )) return max_area def dfs ( self , grid , i , j ): if i < 0 or i >= len ( grid ) or j < 0 or j >= len ( grid [ 0 ]) or grid [ i ][ j ] == 0 : return 0 grid [ i ][ j ] = 0 # do choice, mark visited return 1 + self . dfs ( grid , i - 1 , j ) + self . dfs ( grid , i + 1 , j ) + self . dfs ( grid , i , j - 1 ) + self . dfs ( grid , i , j + 1 ) 547. Number of Provinces class Solution : \"\"\"O(N*N) Nä¸ªèŠ‚ç‚¹ï¼›æ¯ä¸ªèŠ‚ç‚¹è‡³å°‘1æ¡è¾¹ï¼ˆåªä¸è‡ªå·±ç›¸è¿ï¼‰ï¼Œæœ€å¤šNæ¡è¾¹ï¼ˆä¸æ‰€æœ‰èŠ‚ç‚¹ç›¸è¿ï¼‰ã€‚ \"\"\" def findCircleNum ( self , isConnected : List [ List [ int ]]) -> int : node = len ( isConnected ) visited = [ False ] * node count = 0 for i in range ( node ): if visited [ i ] == False : self . dfs ( isConnected , i , visited ) count += 1 return count def dfs ( self , isConnected , i , visited ): visited [ i ] = True for j in range ( len ( isConnected )): if isConnected [ i ][ j ] == 1 and visited [ j ] == False : self . dfs ( isConnected , j , visited ) 417. Pacific Atlantic Water Flow class Solution : directions = [[ - 1 , 0 ], [ 1 , 0 ], [ 0 , - 1 ], [ 0 , 1 ]] def pacificAtlantic ( self , heights : List [ List [ int ]]) -> List [ List [ int ]]: row , col = len ( heights ), len ( heights [ 0 ]) pa_status = [[ False for _ in range ( col )] for _ in range ( row )] al_status = [[ False for _ in range ( col )] for _ in range ( row )] for r in range ( row ): self . dfs ( heights , r , 0 , pa_status ) self . dfs ( heights , r , col - 1 , al_status ) for c in range ( col ): self . dfs ( heights , 0 , c , pa_status ) self . dfs ( heights , row - 1 , c , al_status ) results = [] for i in range ( row ): for j in range ( col ): if pa_status [ i ][ j ] == True and al_status [ i ][ j ] == True : results . append ([ i , j ]) return results def dfs ( self , heights , r , c , status ): if status [ r ][ c ] == True : return status [ r ][ c ] = True for direction in self . directions : r_new , c_new = r + direction [ 0 ], c + direction [ 1 ] if r_new >= 0 and r_new < len ( heights ) and c_new >= 0 and c_new < len ( heights [ 0 ]) and heights [ r_new ][ c_new ] >= heights [ r ][ c ]: self . dfs ( heights , r_new , c_new , status ) Backtracking 46. Permutations class Solution : def permute ( self , nums : List [ int ]) -> List [ List [ int ]]: results , track = [], [] self . backtrack ( nums , track , results ) return results def backtrack ( self , nums , track , results ): if len ( track ) == len ( nums ): results . append ( track . copy ()) return for num in nums : if num in track : continue track . append ( num ) self . backtrack ( nums , track , results ) track . remove ( num ) 77. Combinations 79. Word Search class Solution : \"\"\" Time: O(M*N) Space: O(M*N) \"\"\" def exist ( self , board : List [ List [ int ]], word : str ) -> bool : row , col = len ( board ), len ( board [ 0 ]) visited = [[ False for _ in range ( col )] for _ in range ( row )] for i in range ( row ): for j in range ( col ): if self . backtrack ( board , i , j , word , 0 , visited ): return True return False def backtrack ( self , board , i , j , word , index , visited ): if i < 0 or i >= len ( board ) or j < 0 or j >= len ( board [ 0 ]) or visited [ i ][ j ] == True or board [ i ][ j ] != word [ index ]: return False if index == len ( word ) - 1 and board [ i ][ j ] == word [ index ]: return True visited [ i ][ j ] = True # avoid visit agian res = self . backtrack ( board , i - 1 , j , word , index + 1 , visited ) \\ or self . backtrack ( board , i + 1 , j , word , index + 1 , visited ) \\ or self . backtrack ( board , i , j - 1 , word , index + 1 , visited ) \\ or self . backtrack ( board , i , j + 1 , word , index + 1 , visited ) visited [ i ][ j ] = False return res class Solution : \"\"\" Time: O(M*N) Space: O(1) \"\"\" def exist ( self , board : List [ List [ int ]], word : str ) -> bool : row , col = len ( board ), len ( board [ 0 ]) for i in range ( row ): for j in range ( col ): if self . backtrack ( board , i , j , word , 0 ): return True return False def backtrack ( self , board , i , j , word , index ): if i < 0 or i >= len ( board ) or j < 0 or j >= len ( board [ 0 ]): return False if board [ i ][ j ] == \"#\" or board [ i ][ j ] != word [ index ]: return False if index == len ( word ) - 1 and board [ i ][ j ] == word [ index ]: return True temp = board [ i ][ j ] board [ i ][ j ] = \"#\" # avoid visit agian res = self . backtrack ( board , i - 1 , j , word , index + 1 ) \\ or self . backtrack ( board , i + 1 , j , word , index + 1 ) \\ or self . backtrack ( board , i , j - 1 , word , index + 1 ) \\ or self . backtrack ( board , i , j + 1 , word , index + 1 ) board [ i ][ j ] = temp return res","tags":"Algorithms","url":"articles/Algorithms.html","loc":"articles/Algorithms.html"},{"title":"ã€ RL ã€‘User Simulator","text":"User Simulator BackGround Rule-Based Simulator Design User Simulator BackGround ä¸ºä»€ä¹ˆéœ€è¦ç”¨æˆ·æ¨¡æ‹Ÿå™¨ï¼Ÿ ç›‘ç£å­¦ä¹ æ–¹æ³•ç¼ºé™·ï¼š éœ€è¦æ”¶é›†å¤§é‡å®é™…çš„äººæœºä¸äººäººçš„è®­ç»ƒæ ‡æ³¨æ•°æ®ï¼Œæ˜‚è´µä¸”è€—æ—¶ã€‚ æ­¤å¤–ï¼Œå³ä½¿æœ‰å¤§é‡çš„è®­ç»ƒæ•°æ®ï¼Œä¹Ÿæœ‰å¯èƒ½åœ¨è®­ç»ƒæ•°æ®ä¸­æœªå……åˆ†æ¢ç©¶æŸäº›å¯¹è¯çŠ¶æ€ç©ºé—´ï¼Œä»è€Œé˜»æ­¢äº†å—ç›‘ç£çš„å­¦ä¹ è€…æ‰¾åˆ°å¥½çš„ç­–ç•¥ã€‚ å¼ºåŒ–å­¦ä¹ ä¼˜åŠ¿ï¼š ä¸éœ€è¦å¤§é‡è®­ç»ƒæ•°æ®ï¼Œä»…ç»™å‡ºå¥–åŠ±ä¿¡å·ï¼Œæ™ºèƒ½ä½“å³å¯é€šè¿‡ä¸ç”¨æˆ·äº¤äº’æ¥ä¼˜åŒ–å¯¹è¯ç­–ç•¥ã€‚ å¼ºåŒ–å­¦ä¹ åœ¨å¯¹è¯é¢†åŸŸå­˜åœ¨çš„é—®é¢˜ï¼š å¼ºåŒ–å­¦ä¹ æ¨¡å‹éœ€è¦ä»ç¯å¢ƒä¸­è·å–å¾ˆå¤šæ ·æœ¬ï¼Œä½†æ˜¯ä»é›¶å¼€å§‹ä¸çœŸå®ç”¨æˆ·äº¤äº’æ˜¯ä¸åˆ‡å®é™…çš„ã€‚æ‰€ä»¥éœ€è¦ç”¨æˆ·æ¨¡æ‹Ÿå™¨æ¨¡æ‹ŸçœŸå®ä¸–ç•Œçš„ç¯å¢ƒã€‚ ç”¨æˆ·æ¨¡æ‹Ÿå™¨ï¼š ç”¨æˆ·æ¨¡æ‹Ÿçš„ç›®æ ‡æ˜¯äº§ç”Ÿè‡ªç„¶è€Œåˆç†çš„å¯¹è¯ï¼Œä»è€Œä½¿å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“èƒ½å¤Ÿæ¢ç´¢ç­–ç•¥ç©ºé—´ã€‚ åŸºäºæ¨¡æ‹Ÿçš„æ–¹æ³•å…è®¸ä»£ç†æ¢ç´¢å…ˆå‰è§‚å¯Ÿåˆ°çš„æ•°æ®ä¸­å¯èƒ½ä¸å­˜åœ¨çš„trajectoryï¼Œå…‹æœäº†åŸºäºæ¨¡æ‹Ÿçš„æ–¹æ³•çš„ä¸»è¦å±€é™æ€§ã€‚ åœ¨ç”¨æˆ·æ¨¡æ‹Ÿå™¨ä¸Šè®­ç»ƒçš„æ™ºèƒ½ä½“å¯ä»¥ä½œä¸ºæœ‰æ•ˆçš„èµ·ç‚¹ï¼Œä¹‹åéƒ¨ç½²åœ¨çœŸå®ä¸–ç•Œä¸äººäº’åŠ¨ï¼Œä»è€Œé€šè¿‡å¼ºåŒ–å­¦ä¹ æ¥è¿›ä¸€æ­¥æ”¹è¿›ã€‚ NLU ï¼šè‡ªç„¶è¯­è¨€ â€”-> å­—å…¸è¯­ä¹‰æ ‡ç­¾ DST ï¼šå¯¹è¯å†å²è¿½è¸ª DP ï¼šé€‰æ‹©å¯¹è¯åŠ¨ä½œ NLG ï¼šå¯¹è¯åŠ¨ä½œ â€”-> è‡ªç„¶è¯­è¨€ å¯¹è¯ç³»ç»Ÿå›å¤ï¼ˆactionï¼‰â€”-> ç”¨æˆ·æ¨¡æ‹Ÿå™¨ ç”¨æˆ·æ¨¡æ‹Ÿå™¨ä¸å¯¹è¯ç³»ç»Ÿç»“æ„ç›¸ä¼¼ã€‚ User goalï¼šç”¨æˆ·æ¨¡æ‹Ÿå™¨ç¬¬ä¸€æ­¥é¦–å…ˆç”Ÿæˆå¯¹è¯ç›®æ ‡ã€‚å¯¹è¯ç³»ç»ŸAgentå¯¹æ­¤ç›®æ ‡ä¸å¯çŸ¥ï¼Œä½†æ˜¯éœ€è¦é€šè¿‡å¤šè½®å¯¹è¯å®Œæˆç”¨æˆ·æ¨¡æ‹Ÿå™¨çš„ç›®æ ‡ã€‚ e.g. user goal = inform_slots + request_slotsï¼š { \" request_slots \" : { \" ticket \" : \" UNK \" }, \" inform_slots \" : { \" city \" : \" seattle \" , \" numberofpeople \" : \" 2 \" , \" theater \" : \" regal meridian 16 \" , \" starttime \" : \" 9 : 25 pm \" , \" date \" : \" tomorrow \" , \" moviename \" : \" zoolander 2 \" } } ä¿¡æ¯æ§½ï¼šslot=valueã€‚è‹¥å¹²æ§½å€¼å¯¹ï¼Œæ˜¯ç”¨æˆ·ç”¨äºæŸ¥è¯¢çš„çº¦æŸã€‚ è¯·æ±‚æ§½ï¼šslotã€‚è‹¥å¹²æ§½ï¼Œæ²¡æœ‰ä¿¡æ¯å€¼ï¼Œç”¨æˆ·æœŸæœ›é€šè¿‡å¯¹è¯ä»å¯¹è¯ç³»ç»Ÿæ–¹è·å–çš„ä¿¡æ¯å€¼ã€‚ User modelï¼šç”¨æˆ·æ¨¡å‹å¯¹åº”å¯¹è¯ç³»ç»Ÿçš„å¯¹è¯ç®¡ç†æ¨¡å—ã€‚å®ƒçš„ä»»åŠ¡æ˜¯æ ¹æ®å¯¹è¯å†å²ç”Ÿæˆå½“å‰çš„ç”¨æˆ·åŠ¨ä½œï¼Œç”¨æˆ·åŠ¨ä½œæ˜¯é¢„å…ˆå®šä¹‰å¥½çš„è¯­ä¹‰æ ‡ç­¾ï¼Œä¾‹å¦‚\"inform, request, greet, bye\"ã€‚ Paper: End-to-End Task-Completion Neural Dialogue Systems Rule-Based Simulator Agenda-Based Simulator: Plato Paper: Statistical User Simulation with a Hidden Agenda åœ¨å¯¹è¯è¿‡ç¨‹ä¸­ï¼Œç”¨æˆ·æ¨¡æ‹Ÿå™¨ç»´æŠ¤ç€ä¸€ä¸ªç´§å‡‘çš„ï¼Œç±»ä¼¼å †æ ˆçš„è¡¨ç¤ºå½¢å¼ï¼Œç§°ä¸ºç”¨æˆ·è®®ç¨‹Agendaï¼Œå…¶ä¸­ç”¨æˆ·çŠ¶æ€è¢«åˆ†è§£ä¸ºè®®ç¨‹Aå’Œç›®æ ‡Gã€‚è¯¥ç›®æ ‡Gç”±çº¦æŸCå’Œè¯·æ±‚Rç»„æˆã€‚åœ¨æ¯ä¸ªæ—¶é—´æ­¥tå¤„ï¼Œç”¨æˆ·æ¨¡æ‹Ÿå™¨éƒ½ä¼šåŸºäºå½“å‰çŠ¶æ€å’Œä¸Šä¸€ä¸ªä»£ç†åŠ¨ä½œç”Ÿæˆä¸‹ä¸€ä¸ªç”¨æˆ·åŠ¨ä½œï¼Œç„¶åæ›´æ–°å½“å‰çŠ¶æ€ã€‚ å½“ç”¨æˆ·æ¨¡æ‹Ÿå™¨æ”¶åˆ°è¾“å…¥æ—¶ï¼Œå®ƒä¼šå‚è€ƒPolicy/ Ruleä»¥æŸ¥çœ‹å°†å“ªäº›å†…å®¹æ¨é€åˆ°è®®ç¨‹Agendaä¸­ï¼Œä½œä¸ºå¯¹è¾“å…¥çš„å“åº”ã€‚ ç»è¿‡ä¸€äº›æ•´ç†åï¼ˆä¾‹å¦‚ï¼Œåˆ é™¤é‡å¤çš„å†…å®¹æˆ–ä¸å†æœ‰æ•ˆçš„å†…å®¹ï¼‰ï¼Œç”¨æˆ·æ¨¡æ‹Ÿå™¨ä¼šå°†ä¸€ä¸ªæˆ–å¤šä¸ªé¡¹ç›®ä»è®®ç¨‹Agendaä¸­å¼¹å‡ºä½œä¸ºå›å¤ã€‚ Design ç”¨æˆ·æ¨¡æ‹Ÿå™¨ç»´æŠ¤æ¯ä¸€è½®çš„çŠ¶æ€self.stateï¼Œself.stateå…·æœ‰å­—æ®µrequest_slots, inform_slots, rest_slots, history_slots, turn, diaact Response for Request (System Actionï¼šrequest_slots) case1: åœ¨ç›®æ ‡ä¿¡æ¯æ§½ä¸­ system_action in goal.inform_slots ç³»ç»Ÿagentçš„é—®é¢˜æ§½åœ¨ç”¨æˆ·æ¨¡æ‹Ÿå™¨ç›®æ ‡çš„ä¿¡æ¯æ§½ä¸­ï¼Œ1. ç”¨ç›®æ ‡ä¿¡æ¯æ§½å€¼ç›´æ¥å¡«self.state.inform_slotsä½œä¸ºå›å¤ï¼Œ2. åŒæ—¶ä»çŠ¶æ€self.stateçš„å‰©ä½™æ§½æ ˆself.state.rest_slotsä¸­åˆ é™¤ï¼Œ3. å¹¶æ¸…ç©ºself.state.request_slotsçŠ¶æ€çš„è¯·æ±‚æ§½ï¼Œå› ä¸ºå·²ç»ç¡®å®šä¸ºç”¨æˆ·æ¨¡æ‹Ÿå™¨å›ç­”çš„é™ˆè¿°å¥ã€‚ case2: åœ¨ç›®æ ‡è¯·æ±‚æ§½ä¸­ï¼Œä¸”åœ¨çŠ¶æ€å†å²æ§½ä¸­ï¼Œä¸åœ¨å‰©ä½™æ§½ä¸­ã€‚ é—®é¢˜å·²ç»å›ç­”system_action in goal.request_slots and not in self.state.rest_slots and in self.history_slots ç³»ç»Ÿagentçš„é—®é¢˜æ§½åœ¨ç”¨æˆ·æ¨¡æ‹Ÿå™¨ç›®æ ‡çš„è¯·æ±‚æ§½ä¸­ï¼Œå¹¶ä¸”åœ¨ç”¨æˆ·å¯¹è¯çŠ¶æ€çš„å†å²æ§½ä¸­ï¼Œä¸åœ¨å‰©ä½™æ ˆæ§½ä¸­ã€‚è¡¨ç¤ºè¯¥é—®é¢˜å·²ç»å›ç­”ï¼Œ1. ä»å†å²æ§½ä¸­å–å€¼æ„é€ å›å¤å³å¯ã€‚2. æ¸…ç©ºself.state.request_slotsçŠ¶æ€çš„è¯·æ±‚æ§½ case3: åœ¨ç›®æ ‡è¯·æ±‚æ§½ä¸­ï¼Œä¸”åœ¨çŠ¶æ€å‰©ä½™æ§½ä¸­ã€‚ é—®é¢˜æœªæ›¾å›ç­”system_action in goal.request_slots and not in self.state.rest_slots åœ¨ç›®æ ‡çš„è¯·æ±‚æ§½ä¸­ï¼Œå¹¶ä¸”åœ¨çŠ¶æ€çš„å‰©ä½™æ§½ä¸­ï¼Œ case4: ä¸åœ¨ç›®æ ‡çš„è¯·æ±‚æ§½å’Œä¿¡æ¯æ§½ä¸­ ï¼Œå³ä¸åœ¨ç”¨æˆ·æ¨¡æ‹Ÿå™¨goalä¸­ã€‚ å°†å½“å‰å¯¹è¯çŠ¶æ€çš„ä¿¡æ¯æ§½å¡«å€¼ä¸ºï¼šself.state.inform_slots.slots=dialog_config.I_DO_NOT_CAREå¹¶å›å¤ã€‚å¹¶æ£€æŸ¥self.stateçš„è¯·æ±‚æ§½å’Œå‰©ä½™æ§½æ ˆæ˜¯å¦ä¸ºç©ºï¼Œè®¾ç½®å¯¹è¯çŠ¶æ€ã€‚","tags":"NLP","url":"articles/ã€RLã€‘User-Simulator.html","loc":"articles/ã€RLã€‘User-Simulator.html"},{"title":"BackTracking","text":"BackTracking Permutation I/ II Subset Combination N Queens Word Search Ref. Backtracking BackTracking å›æº¯ç®—æ³•ï¼šæœ¬è´¨æ˜¯Nå‰æ ‘çš„éå†é—®é¢˜ ï¼Œå…³é”®å°±æ˜¯åœ¨å‰åºéå†å’Œååºéå†çš„ä½ç½®åšä¸€äº›æ“ä½œã€‚å›æº¯ç®—æ³•æ¡†æ¶ï¼š è·¯å¾„ï¼šä¹Ÿå°±æ˜¯å·²ç»åšå‡ºçš„é€‰æ‹©ã€‚ é€‰æ‹©åˆ—è¡¨ï¼šä¹Ÿå°±æ˜¯ä½ å½“å‰å¯ä»¥åšçš„é€‰æ‹©ã€‚ï¼ˆä¸€èˆ¬ä¼šå®šä¹‰ä¸€ä¸ªvisitedå¸ƒå°”æ•°ç»„ï¼Œç”¨äºå‰ªæï¼‰ ç»“æŸæ¡ä»¶ï¼šä¹Ÿå°±æ˜¯åˆ°è¾¾å†³ç­–æ ‘åº•å±‚ï¼Œæ— æ³•å†åšé€‰æ‹©çš„æ¡ä»¶ã€‚ result = [] def dfs ( è·¯å¾„, é€‰æ‹©åˆ—è¡¨ ) : if æ»¡è¶³ç»“æŸæ¡ä»¶: result . append ( è·¯å¾„ ) return for é€‰æ‹© in é€‰æ‹©åˆ—è¡¨: åšé€‰æ‹© dfs ( è·¯å¾„, é€‰æ‹©åˆ—è¡¨ ) æ’¤é”€é€‰æ‹© å†™dfså‡½æ•°æ—¶ï¼Œéœ€è¦ç»´æŠ¤èµ°è¿‡çš„ è·¯å¾„ å’Œå½“å‰å¯ä»¥åšçš„ é€‰æ‹©åˆ—è¡¨ ï¼Œå½“è§¦å‘ ç»“æŸæ¡ä»¶ æ—¶ï¼Œå°† è·¯å¾„ è®°å…¥ç»“æœé›†ã€‚ Permutation I/ II #include <string> #include <vector> #include <algorithm> #include <iostream> class Solution { private : std :: vector < std :: string > res ; std :: string track ; public : std :: vector < std :: string > permutation ( std :: string s ) { if ( s . empty ()){ return res ; } std :: vector < bool > visited ( s . size (), false ); std :: sort ( s . begin (), s . end ()); dfs ( res , track , s , visited ); return res ; } void dfs ( std :: vector < std :: string >& res , \\ std :: string & track , \\ std :: string & s , \\ std :: vector < bool >& visited ){ if ( track . size () == s . size ()){ res . push_back ( track ); } for ( int i = 0 ; i < s . size (); i ++ ){ if ( visited [ i ]){ continue ; } if ( i > 0 && visited [ i -1 ] && s [ i -1 ] == s [ i ]){ continue ; } visited [ i ] = true ; track . push_back ( s [ i ]); dfs ( res , track , s , visited ); track . pop_back (); visited [ i ] = false ; } } }; Subset Combination N Queens class Solution { /* In this problem, we can go row by row, and in each position, we need to check * if the column, the 45Â° diagonal and the 135Â° diagonal had a queen before. * Solution: Directly check the validity of each position using nQueens. */ public : vector < vector < string > > solveNQueens ( int n ) { vector < vector < string > > res ; vector < string > nQueens ( n , string ( n , '.' )); solveNQueens ( res , nQueens , 0 , n ); return res ; } private : void solveNQueens ( vector < vector < string > >& res , \\ vector < string >& nQueens , \\ int row , int & n ) { if ( row == n ) { res . push_back ( nQueens ); return ; } for ( int col = 0 ; col != n ; ++ col ) if ( isValid ( nQueens , row , col , n )) { nQueens [ row ][ col ] = 'Q' ; solveNQueens ( res , nQueens , row + 1 , n ); nQueens [ row ][ col ] = '.' ; } } bool isValid ( vector < string >& nQueens , int row , int col , int & n ) { //check if the column had a queen before. for ( int i = 0 ; i != row ; ++ i ) if ( nQueens [ i ][ col ] == 'Q' ) return false ; //check if the 45Â° diagonal had a queen before. for ( int i = row - 1 , j = col - 1 ; i >= 0 && j >= 0 ; -- i , -- j ) if ( nQueens [ i ][ j ] == 'Q' ) return false ; //check if the 135Â° diagonal had a queen before. for ( int i = row - 1 , j = col + 1 ; i >= 0 && j < n ; -- i , ++ j ) if ( nQueens [ i ][ j ] == 'Q' ) return false ; return true ; } }; Word Search #include <vector> #include <iostream> using std :: vector ; using std :: string ; class Solution { private : int row , col ; const int delta [ 4 ][ 2 ]{{ -1 , 0 }, { 1 , 0 }, { 0 , -1 }, { 0 , 1 }}; public : bool exist ( vector < vector < char >>& board , string word ) { if ( board . empty () || word . empty ()){ return false ; } row = board . size (); col = board [ 0 ]. size (); vector < vector < bool >> visted ( row , vector < bool > ( col , false )); for ( int i = 0 ; i < row ; i ++ ){ for ( int j = 0 ; j < col ; j ++ ){ // å¦‚æœæœåˆ°ç›´æ¥è¿”å›ï¼Œå¦åˆ™ç»§ç»­æœç´¢ if ( dfs ( i , j , board , word , visted , 0 )){ return true ; } } } return false ; } bool dfs ( int x , \\ int y , \\ vector < vector < char >>& board , \\ string word , \\ vector < vector < bool >>& visted , \\ int index ){ if ( index == word . size () -1 ){ return board [ x ][ y ] == word . at ( index ); } if ( board [ x ][ y ] == word . at ( index )){ visted [ x ][ y ] = true ; // åˆ†åˆ«ä»å››ä¸ªæ–¹å‘è¿›è¡Œæœç´¢ for ( int i = 0 ; i < 4 ; i ++ ){ int newRow = x + delta [ i ][ 0 ]; int newCol = y + delta [ i ][ 1 ]; if ( checkValid ( newRow , newCol , visted ) && \\ dfs ( newRow , newCol , board , word , visted , index + 1 )){ return true ; } } // å½“å‰ç‚¹(x, y)çš„å››ä¸ªæ–¹å‘éƒ½æ²¡æœåˆ°ï¼Œ // å›æº¯éœ€è¦é‡ç½®visted[x][y]ä¸ºfalseï¼Œç”¨äºå…¶ä»–ä½ç½®å¼€å§‹æŸ¥è¯¢ã€‚ visted [ x ][ y ] = false ; } return false ; } bool checkValid ( int x , int y , vector < vector < bool >>& visted ){ if ( x >= 0 && x < row && y >= 0 && y < col ){ return visted [ x ][ y ] == false ; } return false ; } };","tags":"Algorithms","url":"articles/BackTracking.html","loc":"articles/BackTracking.html"},{"title":"NLP Attention","text":"Context attention - LSTM Self attention Masked self attention Self Attention Cross Attention - Transformer http://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention Context attention - LSTM Encoder and Decoder class Attention ( nn . Module ): def __init__ ( self , method , hidden_size ): super ( Attention , self ) . __init__ () self . method = method self . hidden_size = hidden_size if self . method == 'general' : self . attention = nn . Linear ( self . hidden_size , self . hidden_size ) elif self . method == 'concat' : self . attention = nn . Linear ( self . hidden_size * 3 , self . hidden_size ) self . v = nn . Parameter ( nn . init . normal_ ( torch . empty ( self . hidden_size ))) def forward ( self , hidden , encoder_outputs ): attention_energies = self . score ( hidden , encoder_outputs ) attention_energies = attention_energies . t () return F . softmax ( attention_energies , dim = 1 ) . unsqueeze ( 1 ) def score ( self , hidden , encoder_output ): if self . method == 'dot' : energy = hidden . dot ( encoder_output ) return energy elif self . method == 'general' : energy = self . attention ( encoder_output ) energy = hidden . dot ( energy ) return energy elif self . method == 'concat' : encoder_output = encoder_output . transpose ( 0 , 1 ) energy = self . attention ( torch . cat (( hidden . expand ( encoder_output . size ( 0 ), - 1 , - 1 ), encoder_output ), 2 )) . tanh () return torch . sum ( self . v * energy , dim = 2 ) # attention by jerry self . attention = Attention ( attn_model , hidden_size ) # Calculate attention weights from the current RNN last hidden output attn_weights = self . attention ( last_hidden . unsqueeze ( 0 ), encoder_outputs ) # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector context = attn_weights . bmm ( encoder_outputs ) # Concatenate weighted context vector and GRU output using Luong eq. 5 last_hidden = last_hidden . squeeze ( 0 ) context = context . squeeze ( 1 ) concat_input = torch . cat (( last_hidden , context ), 1 ) concat_output = torch . tanh ( self . concat ( concat_input )) Self attention Encoder or Decoder Masked self attention Decoder padding masked & sequence masked Self Attention Cross Attention - Transformer from torch import nn , Tensor from typing import Dict , List , Optional , Tuple class Attention ( nn . Module ): \"\"\"Multi-headed attention from 'Attention Is All You Need' paper\"\"\" def __init__ ( self , embed_dim , num_heads , dropout = 0.0 , bias = True , encoder_decoder_attention = False , # otherwise self_attention ): super () . __init__ () self . embed_dim = embed_dim self . num_heads = num_heads self . dropout = dropout self . head_dim = embed_dim // num_heads assert self . head_dim * num_heads == self . embed_dim , \"embed_dim must be divisible by num_heads\" self . scaling = self . head_dim ** - 0.5 self . encoder_decoder_attention = encoder_decoder_attention self . k_proj = nn . Linear ( embed_dim , embed_dim , bias = bias ) self . v_proj = nn . Linear ( embed_dim , embed_dim , bias = bias ) self . q_proj = nn . Linear ( embed_dim , embed_dim , bias = bias ) self . out_proj = nn . Linear ( embed_dim , embed_dim , bias = bias ) self . cache_key = \"encoder_decoder\" if self . encoder_decoder_attention else \"self\" def _shape ( self , tensor , seq_len , bsz ): \"\"\"å¤šå¤´æ³¨æ„åŠ›ï¼Œéšå±‚ç»´åº¦reshap \"\"\" return tensor . contiguous () . view ( seq_len , bsz * self . num_heads , self . head_dim ) . transpose ( 0 , 1 ) def forward ( self , query , key : Tensor , key_padding_mask : Optional [ Tensor ] = None , layer_state : Optional [ Dict [ str , Tensor ]] = None , attn_mask : Optional [ Tensor ] = None , output_attentions = False , ) -> Tuple [ Tensor , Optional [ Tensor ]]: \"\"\"Input shape: Time(SeqLen) x Batch x Channel\"\"\" static_kv : bool = self . encoder_decoder_attention tgt_len , bsz , embed_dim = query . size () # get here for encoder decoder cause of static_kv if layer_state is not None : # reuse k,v and encoder_padding_mask saved_state = layer_state . get ( self . cache_key , {}) if \"prev_key\" in saved_state and static_kv : # previous time steps are cached - no need to recompute key and value if they are static key = None else : # this branch is hit by encoder saved_state = None # Scale q to prevent the dot product between q and k from growing too large. q = self . q_proj ( query ) * self . scaling if static_kv and key is None : # cross-attention with cache k = v = None elif static_kv and key is not None : # cross-attention no prev_key found in cache k = self . k_proj ( key ) v = self . v_proj ( key ) else : # self-attention k = self . k_proj ( query ) v = self . v_proj ( query ) q = self . _shape ( q , tgt_len , bsz ) if k is not None : k = self . _shape ( k , - 1 , bsz ) if v is not None : v = self . _shape ( v , - 1 , bsz ) if saved_state : k , v = self . _concat_saved_state ( k , v , saved_state , static_kv , bsz ) # Update cache if isinstance ( layer_state , dict ): cached_shape = ( bsz , self . num_heads , - 1 , self . head_dim ) # bsz must be first for reorder_cache layer_state [ self . cache_key ] = dict ( prev_key = k . view ( * cached_shape ), prev_value = v . view ( * cached_shape )) src_len = k . size ( 1 ) assert key_padding_mask is None or key_padding_mask . shape == ( bsz , src_len ) # æ³¨æ„åŠ›çŸ©é˜µï¼Œå³queryä¸keyçš„æ±‚å‡ºçš„çŸ©é˜µç³»æ•° attn_weights = torch . bmm ( q , k . transpose ( 1 , 2 )) assert attn_weights . size () == ( bsz * self . num_heads , tgt_len , src_len ) if attn_mask is not None : attn_weights = attn_weights . view ( bsz , self . num_heads , tgt_len , src_len ) + attn_mask attn_weights = attn_weights . view ( bsz * self . num_heads , tgt_len , src_len ) # Note: deleted workaround to get around fork/join parallelism not supporting Optional types. on 2020/10/15 if key_padding_mask is not None : # don't attend to padding symbols attn_weights = attn_weights . view ( bsz , self . num_heads , tgt_len , src_len ) reshaped = key_padding_mask . unsqueeze ( 1 ) . unsqueeze ( 2 ) attn_weights = attn_weights . masked_fill ( reshaped , float ( \"-inf\" )) attn_weights = attn_weights . view ( bsz * self . num_heads , tgt_len , src_len ) attn_weights = F . softmax ( attn_weights , dim =- 1 ) attn_probs = F . dropout ( attn_weights , p = self . dropout , training = self . training ) assert v is not None attn_output = torch . bmm ( attn_probs , v ) assert attn_output . size () == ( bsz * self . num_heads , tgt_len , self . head_dim ) attn_output = attn_output . transpose ( 0 , 1 ) . contiguous () . view ( tgt_len , bsz , embed_dim ) attn_output = self . out_proj ( attn_output ) if output_attentions : attn_weights = attn_weights . view ( bsz , self . num_heads , tgt_len , src_len ) else : attn_weights = None return attn_output , attn_weights","tags":"NLP","url":"articles/NLP-Attention.html","loc":"articles/NLP-Attention.html"},{"title":"ã€ NLP ã€‘ BERT","text":"http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time","tags":"NLP","url":"articles/ã€NLPã€‘BERT.html","loc":"articles/ã€NLPã€‘BERT.html"},{"title":"ã€ NLP ã€‘ELMo","text":"ELMo: Embeddings from Language models, BiLSTM vector concatï¼Œweighed hidden layers stacked ä¸GloVe embeddingæœ€å¤§åŒºåˆ«ï¼Œå¼•å…¥äº†ä¸Šä¸‹æ–‡ï¼Œcontextualized word-embeddings ( BERT , ELMo) ELMoä¸ä¼šä¸ºæ¯ä¸ªå•è¯ä½¿ç”¨å›ºå®šçš„embeddingå‘é‡ï¼Œè€Œæ˜¯ä¼šåœ¨ä¸ºæ¯ä¸ªå•è¯åˆ†é…embeddingä¹‹å‰å…ˆæŸ¥çœ‹æ•´ä¸ªå¥å­(ä¸Šä¸‹æ–‡)ã€‚ http://jalammar.github.io/illustrated-bert","tags":"NLP","url":"articles/ã€NLPã€‘ELMo.html","loc":"articles/ã€NLPã€‘ELMo.html"},{"title":"ã€ RL ã€‘Policy Gradient","text":"1. Reinforcement Learning 2. Deep Learning 1. Reinforcement Learning Actor(Policy) Neural Network as Actor (Deep). vs lookup Table(Q Learning). ä½¿ç”¨ç¥ç»ç½‘ç»œä½œä¸ºActoræ¯”æŸ¥è¡¨çš„ä¼˜åŠ¿ï¼Ÿ æŸ¥è¡¨æ— æ³•ç©·ä¸¾è¾“å…¥ï¼Œe.g.å›¾åƒç”»é¢æˆ–è€…è¯­è¨€è¾“å…¥ã€‚NNæ³›åŒ–æ€§æ¯”è¾ƒå¼ºï¼Œå¯¹äºæœªçœ‹è¿‡çš„Observationï¼Œä¸¾ä¸€åä¸‰ï¼Œåˆç†çš„è¾“å‡ºã€‚ Environment Reward 2. Deep Learning å¦‚ä½•é€‰å–Actorï¼Ÿ Neural Network as Actor (Deep) å¦‚ä½•è¡¡é‡Actorçš„å¥½åï¼Ÿ Maxmize Reward çš„æœŸæœ›ã€‚Rewardæ˜¯ä¸€ä¸ªå›åˆ episode ï¼Œæ¯è½®Rewardçš„æ€»å’Œã€‚ç”±äºActoræ˜¯stochasticéšæœºçš„ï¼Œæ¯ä¸ªå›åˆçš„Rewardä¸åŒã€‚æ‰€ä»¥maxmize sampling Nå›åˆRewardçš„æœŸæœ›ã€‚ æœŸæœ›å°±è¡¡é‡äº†Actor","tags":"NLP","url":"articles/ã€RLã€‘Policy-Gradient.html","loc":"articles/ã€RLã€‘Policy-Gradient.html"},{"title":"ã€ NLP ã€‘ RASA Issues","text":"1. Conversation Design 2. Stories 3. Data Augmentation 4. Policy 1. Conversation Design Dialogue Elements intent and goal are easily confused. 2. Stories rasa-stories rasa-core-understanding-stories 3. Data Augmentation rasa-data-augmentation data-augmentation 4. Policy Transformer Embedding Dialogue ( TED ) Policy Paper: Dialogue Transformers","tags":"NLP","url":"articles/ã€NLPã€‘RASA-Issues.html","loc":"articles/ã€NLPã€‘RASA-Issues.html"},{"title":"CNN","text":"(batch_size, height, width, channel) = (200, 32, 32, 256) å·ç§¯æ ¸ï¼Œç”¨äºæå–ç‰¹å®šç‰¹å¾ï¼Œç”±å·ç§¯æ ¸å†³å®šã€‚ç½‘ç»œå­¦ä¹ çš„å‚æ•°ä¹Ÿå°±æ˜¯å·ç§¯æ ¸çš„å‚æ•°ï¼Œæ‰€ä»¥ç›¸æ¯”äºå…¨è¿æ¥ç½‘ç»œå¤§å¤§å‡å°‘äº†å‚æ•°ã€‚æ»‘åŠ¨å·ç§¯æ ¸åœ¨å›¾ç‰‡ä¸Šæå–ç›¸åº”ç‰¹å¾ã€‚ é€šé“æ•°ç­‰äºå·ç§¯æ ¸æ•°ï¼Œæ¯ä¸ªé€šé“å‚æ•°å…±äº«ï¼Œè´Ÿè´£ç‰¹å®šç‰¹å¾æå–ã€‚ä¸RGBé¢œè‰²ä¸‰é€šé“åŒºåˆ«å¼€æ¥ã€‚ å°å¤§æå®æ¯… Why convolution ? Andrew Ng CNN &TextCNN","tags":"ML","url":"articles/CNN.html","loc":"articles/CNN.html"},{"title":"Deploy my blog quickly","text":"1. Clone Blog 2. Create virtual environment 3. Install themes & plugins download and install theme elegant download pelican plugins 4. Deploy Blog 1. Clone Blog $ git clone git@github.com:jerrylsu/blog.git 2. Create virtual environment $ conda create -n blog python = 3 .6.8 $ conda activate blog $ pip install pelican -i https://pypi.doubanio.com/simple $ pip install bs4 markdown webassets cssmin -i https://pypi.doubanio.com/simple 3. Install themes & plugins The directory of themes and plugins can be pulled by pelican site. download and install theme elegant github.com/getpelican/pelican-themes $ cd /blog/themes $ git clone git@github.com:Pelican-Elegant/elegant.git $ pelican-themes --install themes/elegant --verbose download pelican plugins github.com/getpelican/pelican-plugins $ cd blog $ git clone git@github.com:getpelican/pelican-plugins.git $ mv peliacn-plugins plugins 4. Deploy Blog $ mkdir output # Binding domain name. $ touch output/CNAME $ echo 'www.jerrulsu.com' >> output/CNAME # Generate automatically deployment files into output directory # and deploy blog to github.com:jerrylsu/jerrylsu.github.io.git. # if use windows conda environment on cygwin, you must use command # python -i ./cmder p $ ./cmder p","tags":"Tools","url":"articles/Deploy-my-blog-quickly.html","loc":"articles/Deploy-my-blog-quickly.html"},{"title":"ã€ NLP ã€‘ RASA Dialogue Transformers","text":"Dialogue Transformers åŸºäºtransformeræ¶æ„çš„dialogue levelçš„å¯¹è¯ç­–ç•¥ï¼Œå…¶ä¸­è‡ªæ³¨æ„åŠ›æœºåˆ¶å…³æ³¨å¤šè½®å¯¹è¯åºåˆ—ã€‚RNNç½‘ç»œç»“æ„æ˜¯åœ¨å¯¹æ•´ä¸ªå¯¹è¯åºåˆ—è¿›è¡Œç¼–ç ï¼Œæ•…è€Œè®¤ä¸ºå†å²åºåˆ—çš„æ¯ä¸€è½®å¯¹è¯turnå‡æ˜¯ç›¸å…³çš„ã€‚å°½ç®¡å¤æ‚LSTMç»“æ„å¯¹RNNè¿›è¡Œäº†æ”¹è¿›ï¼Œå¯ä»¥å¯¹å†å²ä¿¡æ¯é€‰æ‹©æ€§é—å¿˜ï¼Œç„¶åè¿™éœ€è¦æœ‰è¶³å¤Ÿçš„è®­ç»ƒæ•°æ®ã€‚åŸºäºè¿™äº›ï¼Œåœ¨è®­ç»ƒæ•°æ®æœ‰é™å’Œå¤šä¸»é¢˜å¯¹è¯çš„åœºæ™¯ï¼ˆä¸€ç»„å¯¹è¯ä¸­ä¼šäº¤å å¤šç§å¯¹è¯ç‰‡æ®µï¼‰ä¸‹ï¼Œç½‘ç»œæ— æ³•è§£å†³è¿™äº›é—®é¢˜ã€‚è€Œtransformerç»“æ„ä¼šé€‰å–å“ªäº›è½®å‚ä¸å½“å‰è½®å¯¹è¯çŠ¶æ€çš„ç¼–ç ï¼Œè‡ªç„¶è€Œç„¶çš„å¿½ç•¥æ— å…³å’Œé€‰å–ç›¸å…³å†å²å¯¹è¯è½®ï¼Œæœ‰æ•ˆå…‹æœäº†RNNç»“æ„çš„é™åˆ¶ä»¥LSTMå¯¹å¤§è®­ç»ƒæ•°æ®çš„ä¾èµ–ã€‚ åŸºäºè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„transformerç»“æ„ï¼Œå¯¹å¼€æ”¾åŸŸå¤šä¸»é¢˜çš„å¯¹è¯æœ‰æ˜æ˜¾çš„ä¼˜åŠ¿ã€‚åœ¨å¯¹ç¼–ç çš„levelä¸Šï¼ŒNLPé€šå¸¸æ˜¯åŸºäºå•è½®çš„tokenåºåˆ—è¿›è¡Œç¼–ç ï¼Œè€Œrasaçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶æ˜¯å¯¹æ•´ä¸ªå¯¹è¯åºåˆ—ç¼–ç ã€‚ e.g. ## Generated Story case-0-568983 * inform_face_name{\"e_face_name_2\": \"Jerry\"} - action_set_face_name - slot{\"s_face_name_1\": \"Jerry\"} å¯¹äºTransformer encodeç½‘ç»œçš„bertæ¨¡å‹æ¥è¯´ï¼Œä¸Šä¾‹ä½œä¸ºä¸€æ¡è®­ç»ƒæ ·æœ¬çš„storyï¼Œå…±æœ‰ä¸‰è½®å¯¹è¯ä¸”å…·æœ‰æ—¶åºå…³ç³»ï¼Œå³3 time stepsã€‚æ¯ä¸€ä¸ªtime stepçš„vectoræœ‰ç”¨æˆ·è¾“å…¥ï¼ˆæ„å›¾å’Œå®ä½“ï¼‰ + æ§½ + ä¸Šä¸€è½®çš„Actionï¼Œæ¯ä¸€ä¸ªtime stepåŒæ—¶å¯¹åº”ä¸€ä¸ªactionçš„é¢„æµ‹vectorã€‚åŒºåˆ«ä¸åŸå§‹çš„bertåŒå‘è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œè¯¥ç­–ç•¥ä¸­ä½¿ç”¨å•å‘æ³¨æ„åŠ›ï¼Œå³å…³æ³¨å½“å‰è½®ä¹‹å‰çš„å¯¹è¯å†å²ä¿¡æ¯ã€‚ Transformer embeddingç­–ç•¥ä½“ç³»ç»“æ„ï¼ŒåŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤ï¼š å°†ç”¨æˆ·è¾“å…¥ï¼ˆç”¨æˆ·æ„å›¾å’Œå®ä½“ï¼‰ï¼Œæ¯ä¸ªæ—¶é—´æ­¥éª¤çš„å…ˆå‰ç³»ç»ŸåŠ¨ä½œï¼Œæ§½concatenateä¸ºè¾“å…¥å‘é‡è¾“å…¥embeddingå±‚ï¼› é€å…¥transformerï¼› å¯¹transformerçš„è¾“å‡ºåº”ç”¨ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼Œè·å¾—è¿™ä¸ªæ—¶é—´æ­¥å¯¹è¯embeddingå‘é‡ï¼› åœ¨æ¯ä¸ªæ—¶é—´æ­¥ä¸Šå¯¹å…¨éƒ¨çš„ç³»ç»Ÿactionsåˆ›å»ºembeddingå‘é‡ï¼› è®¡ç®—å¯¹è¯embeddingå‘é‡å’Œç³»ç»Ÿactions embeddingå‘é‡ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œå³lossã€‚å‚è§StarSpaceçš„è®ºæ–‡ã€‚ Dialogue_featuresä½œä¸ºè¾“å…¥ç‰¹å¾ï¼Œæ€»å…±0ï¼Œ1ï¼Œ2ä¸‰è½®å¯¹è¯ã€‚FullDialoguePolicyé»˜è®¤å‚ç…§æœ€é•¿storyè¿›è¡Œ-1 paddingï¼Œå³è¾“å…¥4çš„ä½œç”¨ã€‚ Bot_featuresä½œä¸ºæ¯ä¸€è½®é¢„æµ‹çš„è¾“å‡ºç‰¹å¾ï¼ŒåŒæ ·-1 paddingå¹¶æœ€ç»ˆé»˜è®¤è½¬æ¢ä¸ºaction_listenå‘é‡ã€‚ å¯¹äºå¤šä¸»é¢˜è‡ªæ³¨æ„åŠ›æœºåˆ¶çŸ©é˜µçš„æµ‹è¯•ç»“æœï¼š å¦‚ä¸Šå›¾è‡ªæ³¨æ„åŠ›çŸ©é˜µæ‰€ç¤ºï¼Œçºµè½´ä¸ºè¢«é¢„æµ‹çš„å¯¹è¯è½®ï¼Œæ¨ªè½´ä¸ºpolicyæ‰€å…³æ³¨çš„å¯¹è¯å†å²ã€‚ç”±äºä½¿ç”¨å•å‘transformerç»“æ„ï¼ŒçŸ©é˜µçš„ä¸Šä¸‰è§’0æ©ç ï¼Œä»¥ç¡®ä¿ä¸ä¼šå»å…³æ³¨æœªæ¥çš„å¯¹è¯è½®ã€‚å›¾ç¤ºå¯ä»¥è¯æ˜å­¦ä¹ çš„æ³¨æ„åŠ›æƒé‡å¾ˆå®¹æ˜“è§£é‡Šå¹¶åæ˜ å¯¹è¯é€»è¾‘ï¼Œåœ¨æ¯ä¸€è½®çš„å¯¹è¯ä¸­ï¼Œä¸å½“å‰é¢„æµ‹ç›¸å…³çš„å¯¹è¯å†å²æœ‰è¾ƒé«˜çš„æ³¨æ„åŠ›æƒé‡ã€‚ References: https://arxiv.org/abs/1910.00486 https://github.com/jerrylsu/learning/tree/master/nlp/rasa/featurizers","tags":"NLP","url":"articles/ã€NLPã€‘RASA-Dialogue-Transformers.html","loc":"articles/ã€NLPã€‘RASA-Dialogue-Transformers.html"},{"title":"ã€ NLP ã€‘ RASA Featurizer","text":"è®­ç»ƒé›†storieså¦‚ä½•æ„å»ºçŠ¶æ€stateä½œä¸ºè®­ç»ƒè¾“å…¥æ•°æ®ï¼Ÿ æ„å»ºçš„çŠ¶æ€stateä½œä¸ºè¾“å…¥Xå¦‚ä½•ç¼–ç ï¼Ÿ è¾“å‡ºyæ˜¯ä»€ä¹ˆï¼Ÿå¦‚ä½•ç¼–ç ï¼Ÿ https://rasa.com/docs/rasa/api/core-featurization/ Dialogue Transformers Transformer policyæ˜¯å¯¹dialogue turn levelç¼–ç ï¼Œè€Œä¸æ˜¯token levelç¼–ç ã€‚ 1.1 è¾“å…¥ç‰¹å¾Xç¼–ç  1.1.1 ç”¨æˆ·è¾“å…¥å’Œç³»ç»ŸåŠ¨ä½œè¯å…¸æ„å»º 1.1.2 encodeâ€”â€”è¯è¢‹æ¨¡å‹ 1.2 è¾“å‡ºYç¼–ç  FullDialogueTrackerFeaturizer è®­ç»ƒé›†storieså¦‚ä½•æ„å»ºçŠ¶æ€stateä½œä¸ºè®­ç»ƒè¾“å…¥æ•°æ®ï¼Ÿ æ„å»ºçš„çŠ¶æ€stateä½œä¸ºè¾“å…¥Xå¦‚ä½•ç¼–ç ï¼Ÿ è¾“å‡ºyæ˜¯ä»€ä¹ˆï¼Ÿå¦‚ä½•ç¼–ç ï¼Ÿ https://rasa.com/docs/rasa/api/core-featurization/ Dialogue Transformers LabelTokenizerSingleStateFeaturizer creates a vector based on the feature label: All active feature labels (e.g. prev_action_listen) are split into tokens and represented as a bag-of-words. For example, actions utter_explain_details_hotel and utter_explain_details_restaurant will have 3 features in common, and differ by a single feature indicating a domain. Labels for user inputs (intents, entities) and bot actions are featurized separately. Each label in the two categories is tokenized on a special character split_symbol (e.g. action_search_restaurant = {action, search, restaurant}), creating two vocabularies. A bag-of-words representation is then created for each label using the appropriate vocabulary. The slots are featurized as binary vectors, indicating their presence or absence at each step of the dialogue. Transformer policyæ˜¯å¯¹dialogue turn levelç¼–ç ï¼Œè€Œä¸æ˜¯token levelç¼–ç ã€‚ we apply self-attention at the discourse level, attending over the sequence of dialogue turns rather than the sequence of tokens in a single turn. ä¸€æ¡è®­ç»ƒæ•°æ®æ˜¯ï¼ŒXä¸ªdialogue turnså’ŒYä¸ªaction_namesã€‚ 1.1 è¾“å…¥ç‰¹å¾Xç¼–ç  1.1.1 ç”¨æˆ·è¾“å…¥å’Œç³»ç»ŸåŠ¨ä½œè¯å…¸æ„å»º prepare_from_domain Creates internal vocabularies for user intents and bot actions to use for featurization user_labels = [] slot_labels = [] bot_labels = [] bot_vocab = None user_vocab = None åªæœ‰slot_labelsæ²¡æœ‰ç”Ÿæˆå­—å…¸ï¼Œä½¿ç”¨åˆ—è¡¨[â€˜slot_s_answer_error_0'â€¦]ï¼Œä¹Ÿæ²¡æœ‰split(â€˜_') bot_labels = [ 'action_listen' , 'action_restart' , 'utter_ask_is_staff' , 'utter_ask_visitor_reserve' ] distinct_tokens = set ([ token for label in bot_labels for token in label . split ( '_' )]) bot_vocab = { token : idx for idx , token in enumerate ( sorted ( distinct_tokens ))} bot_vocab {'action': 0, 'ask': 1, 'is': 2, 'listen': 3, 'reserve': 4, 'restart': 5, 'staff': 6, 'utter': 7, 'visitor': 8} user_labels = [ 'intent_ask_human_service' , 'intent_bye' , 'intent_chitchat' , 'intent_confirm' ] distinct_tokens = set ([ token for label in user_labels for token in label . split ( '_' )]) user_vocab = { token : idx for idx , token in enumerate ( sorted ( distinct_tokens ))} user_vocab {'ask': 0, 'bye': 1, 'chitchat': 2, 'confirm': 3, 'human': 4, 'intent': 5, 'service': 6} slot_labels = [ 'slot_s_answer_error_0' , 'slot_s_chitchat_turn_0' , 'slot_s_digits_key_0' , 'slot_s_host_name_0' , 'slot_s_is_call_human_0' , 'slot_s_is_call_human_1' , 'slot_s_is_chitchat_0' , 'slot_s_is_chitchat_1' , 'slot_s_is_reserve_visitor_0' , 'slot_s_is_reserve_visitor_1' , 'slot_s_is_same_name_0' , 'slot_s_is_same_name_1' , 'slot_s_is_staff_0' , 'slot_s_is_staff_1' , 'slot_s_is_valid_info_0' , 'slot_s_is_valid_info_1' , 'slot_s_is_valid_reserve_0' , 'slot_s_is_valid_reserve_1' , 'slot_s_is_valid_staff_0' , 'slot_s_is_valid_staff_1' , 'slot_s_is_visitor_0' , 'slot_s_is_visitor_1' , 'slot_s_phone_number_0' , 'slot_s_self_name_0' , 'slot_s_staff_homophonic_name_0' , 'slot_s_title_name_0' , 'slot_s_visitor_homophonic_name_0' ] 1.1.2 encodeâ€”â€”è¯è¢‹æ¨¡å‹ æ€»ç‰¹å¾å‘é‡ç»´åº¦ï¼šnum_features = ç”¨æˆ·è¾“å…¥ï¼ˆæ„å›¾å’Œå®ä½“ï¼‰å­—å…¸ç»´åº¦ + æ§½ç»´åº¦ + ç³»ç»Ÿactionå­—å…¸ç»´åº¦ user_feature_len = len ( user_vocab ) print ( \"user feature len: {} \" . format ( user_feature_len )) slot_feature_len = len ( slot_labels ) print ( \"slot feature len: {} \" . format ( slot_feature_len )) bot_feature_len = len ( bot_vocab ) print ( \"bot feature len: {} \" . format ( bot_feature_len )) num_features = len ( user_vocab ) + len ( slot_labels ) + len ( bot_vocab ) print ( \"num_feature = user vocab + slot labels + bot vocab: {} \" . format ( num_features )) user feature len: 7 slot feature len: 27 bot feature len: 9 num_feature = user vocab + slot labels + bot vocab: 43 # ç‰¹å¾åŒ–å‘é‡ï¼Œå›ºå®šé•¿åº¦ã€‚ import numpy as np used_features = np . zeros ( num_features , dtype = float ) used_features array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) # é€šè¿‡ifåˆ¤æ–­çŠ¶æ€å±äºç”¨æˆ·ã€æ§½ã€è¿˜æ˜¯ç³»ç»ŸåŠ¨ä½œï¼Œä»¥ç¡®å®šåœ¨å‘é‡num_featuresä¸­çš„åç§»é‡offsetã€‚ # ç”¨æˆ·çš„æ„å›¾å®ä½“ + æ§½ + ç³»ç»ŸåŠ¨ä½œ # è¾“å…¥çš„çŠ¶æ€stateï¼ˆåŒ…æ‹¬ç”¨æˆ·è¾“å…¥çš„æ„å›¾å®ä½“ã€æ§½ã€ç³»ç»ŸåŠ¨ä½œï¼‰ state = { 'entity_e_phone_number' : 1.0 , 'intent_deny+inform_name_self+inform_phone_number_self' : 1.0 , 'prev_action_listen' : 1.0 , 'entity_e_name' : 1.0 , 'entity_e_four_digits' : 1.0 } def split_state_name ( state_name : str ): \"\"\"Split multiple intents with '+' and '_'. Add the string of 'intent'. e.g. \"intent_deny+inform_name_self+inform_phone_number_self\" -> ['intent', 'deny', 'inform', 'name', 'self', 'inform', 'phone', 'number', 'self', 'intent', 'intent'] \"\"\" intents = state_name . split ( '+' ) intents_num , res = len ( intents ), [] for words in intents : res . extend ( words . split ( '_' )) for _ in range ( intents_num - 1 ): res . append ( 'intent' ) return res used_features = np . zeros ( num_features , dtype = float ) idx = 0 PREV_PREFIX = \"prev_\" for state_name , prob in state . items (): idx += 1 print () print ( 'state name {} : {} ' . format ( idx , state_name )) if state_name in user_labels : # ç”¨æˆ·è¾“å…¥ç¼–ç å…¥å‘é‡used_features #for t in [word for words in state_name.split('+') for word in words.split('_')]: # Bingo!!! for t in split_state_name ( state_name ): #for t in state_name.split('_'): idx = user_vocab [ t ] used_features [ idx ] += prob print ( t ) print ( used_features ) elif state_name in slot_labels : # æ§½ç¼–ç å…¥å‘é‡used_features offset = len ( user_vocab ) idx = slot_labels . index ( state_name ) used_features [ offset + idx ] += prob elif state_name [ len ( PREV_PREFIX ) : ] in bot_labels : # ç³»ç»ŸåŠ¨ä½œç¼–ç å…¥å‘é‡used_features action_name = state_name [ len ( PREV_PREFIX ) :] for t in action_name . split ( '_' ): offset = len ( user_vocab ) + len ( slot_labels ) idx = bot_vocab [ t ] used_features [ offset + idx ] += prob print ( t ) print ( used_features ) state name 1: entity_e_phone_number entity [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] e [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] phone [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] number [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] state name 30: intent_deny+inform_name_self+inform_phone_number_self intent [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] deny [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] inform [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] name [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] self [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] inform [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 2. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] phone [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 2. 1. 0. 0. 1. 1. 0. 0. 2. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] number [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 2. 1. 0. 0. 1. 2. 0. 0. 2. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] self [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 2. 1. 0. 0. 1. 2. 0. 0. 2. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] intent [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 2. 2. 0. 0. 1. 2. 0. 0. 2. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] intent [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 2. 3. 0. 0. 1. 2. 0. 0. 2. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] state name 26: prev_action_listen action [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 2. 3. 0. 0. 1. 2. 0. 0. 2. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] listen [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 2. 3. 0. 0. 1. 2. 0. 0. 2. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] state name 33: entity_e_name entity [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 2. 0. 0. 0. 0. 0. 2. 3. 0. 0. 1. 2. 0. 0. 2. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] e [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 2. 3. 0. 0. 1. 2. 0. 0. 2. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] name [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 2. 3. 0. 0. 2. 2. 0. 0. 2. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] state name 29: entity_e_four_digits entity [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 2. 3. 0. 0. 0. 0. 0. 2. 3. 0. 0. 2. 2. 0. 0. 2. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] e [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 0. 0. 0. 0. 2. 3. 0. 0. 2. 2. 0. 0. 2. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] four [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 3. 3. 1. 0. 0. 0. 0. 2. 3. 0. 0. 2. 2. 0. 0. 2. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] digits [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 3. 3. 1. 0. 0. 0. 0. 2. 3. 0. 0. 2. 2. 0. 0. 2. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] state_nam = 'intent_deny+inform_name_self' def split_state_name ( state_name : str ): intents = state_name . split ( '+' ) intents_num = len ( intents ) res = [] for words in intents : res . extend ( words . split ( '_' )) for _ in range ( intents_num - 1 ): res . append ( 'intent' ) return res split_state_name ( state_nam ) ['intent', 'deny', 'inform', 'name', 'self', 'intent'] [ word for words in state_name . split ( '+' ) for word in words . split ( '_' )] ['entity', 'e', 'four', 'digits'] if PREV_PREFIX + ACTION_LISTEN_NAME in state: å‰ä¸€è½®æ˜¯action_listen,æ‰å¯¹ç”¨æˆ·çš„è¾“å…¥ï¼ˆå³ï¼Œæ„å›¾å’Œå®ä½“ï¼‰ç¼–ç ã€‚è€Œåï¼Œå‡ è½®è™½ç„¶åŒ…å«å‰å‡ è½®ä¿¡æ¯ï¼Œä½†å¯¹ä¿¡æ¯ä¸­çš„ç”¨æˆ·è¾“å…¥ä¸å†ç¼–ç  X çš„shape=ï¼ˆ1ï¼Œ4ï¼Œ153ï¼‰1thç»´æ˜¯storyæ•°ï¼Œ2ç»´æ˜¯å¯¹è¯è½®æ•°ï¼Œ3ç»´æ˜¯æ¯è½®çš„ç¼–ç vectoré•¿åº¦ã€‚å›ºå®šé•¿åº¦ï¼Œæœ‰padding 1.2 è¾“å‡ºYç¼–ç  å¯¹actionè¿›è¡Œone-hotç¼–ç ã€‚ â€˜action_listen' â€”-> â€˜1,0,0,â€¦,0,0,0' (62,)ç»´å‘é‡ æ„é€ bot_actionå­—å…¸ï¼Œ\" \"æ‹†åˆ†ã€‚ â€˜action_listen' â€”-> â€˜1, 0, 0, .., 1, â€¦, 0, 0' (62, 72)ç»´çŸ©é˜µã€‚62ä¸ªactionsï¼Œæ¯ä¸ªactionç”¨72ç»´è¡¨ç¤ºï¼Œ72æ˜¯' â€˜æ‹†åˆ†æ‰€æœ‰action_namesåæ„æˆçš„å­—å…¸æ•°ã€‚ one-hotå‘é‡è½¬bot_actionå­—å…¸å‘é‡ã€‚np.argmax(onehot vector)è·å–ç´¢å¼•, æŸ¥(62, 72)çŸ©é˜µã€‚ Y æœ€ç»ˆçš„è¾“å‡ºç»´åº¦æ˜¯(1dim, 2dim, 3dim) = (1, 4, 72): 1 story, 4 turns dialogue, 72 vector of action dictã€‚å¯¹äºFullDialogueTrackerFeaturizer,ç¬¬2ä¸ªç»´åº¦æ˜¯å¯¹è¯è½®æ•°å¤§å°ï¼ŒæŒ‰ç…§æœ€é•¿storyé•¿åº¦padding -1, ç”¨-1è¡¥é½çš„è½®å¯¹åº”çš„æ ‡ç­¾æ˜¯action_listenã€‚ FullDialogueTrackerFeaturizer å’Œ MaxHistoryTrackerFeaturizer çš„åŒºåˆ«å°±æ˜¯å†å¯¹2ndç»´åº¦ä¸Šçš„æ§åˆ¶ï¼Œ if y . ndim == 3 and isinstance ( self , MaxHistoryTrackerFeaturizer ) : # if it is MaxHistoryFeaturizer , remove time axis y = y [:, 0 , :] ## Generated Story case-0-56898 * inform_face_name{\"e_face_name_1\": \"å¼ æ˜¥æ¢…\"} - action_set_face_name - slot{\"s_face_name_1\": \"å¼ æ˜¥æ¢…\"} - utter_goodbye # domain action_names = [ 'action_listen' , 'action_restart' , 'action_session_start' , 'action_default_fallback' , 'action_deactivate_form' , 'action_revert_fallback_events' , 'action_default_ask_affirmation' , 'action_default_ask_rephrase' , 'action_back' , 'action_confirm_homophonic_name' , 'action_judge_same_name_order_or_department_validity' , 'action_match_answer_info' , 'action_match_reserve_visitor_name' , 'action_match_staff_name' , 'action_set_face_name' , 'action_set_full_name' , 'action_set_host_name' , 'action_set_reality_name_by_face' , 'action_set_reality_name_by_joint' , 'action_set_same_name_order_or_department' , 'action_set_self_name' , 'action_set_user_domain' , 'action_set_user_info' , 'utter_ask_is_staff' , 'utter_ask_staff_digits_key' , 'utter_ask_staff_digits_key_again' , 'utter_ask_staff_name' , 'utter_ask_staff_name_and_digits_key' , 'utter_ask_user_is_staff' , 'utter_ask_visitor_host' , 'utter_ask_visitor_host_full_name' , 'utter_ask_visitor_name' , 'utter_ask_visitor_name_and_phone' , 'utter_ask_visitor_phone' , 'utter_ask_visitor_phone_again' , 'utter_ask_visitor_phone_error' , 'utter_ask_visitor_phone_error_again' , 'utter_ask_visitor_phone_no_pass' , 'utter_ask_visitor_reserve' , 'utter_call_human_service' , 'utter_chitchat' , 'utter_chitchat_again' , 'utter_chitchat_once_again' , 'utter_confirm_host_name' , 'utter_confirm_staff_name' , 'utter_confirm_visitor_name' , 'utter_correct_answer' , 'utter_default' , 'utter_error_authentication' , 'utter_error_catch' , 'utter_goodbye' , 'utter_greet_short' , 'utter_help_find_people' , 'utter_staff_digits_key_error' , 'utter_staff_digits_key_error_again' , 'utter_staff_inform_no_collection' , 'utter_staff_invalid_name' , 'utter_staff_welcome' , 'utter_visitor_lack_host_information' , 'utter_visitor_lack_reserve_name' , 'utter_visitor_wait' , 'utter_wrong_answer' ] bot_vocab = { 'action' : 0 , 'affirmation' : 1 , 'again' : 2 , 'and' : 3 , 'answer' : 4 , 'ask' : 5 , 'authentication' : 6 , 'back' : 7 , 'by' : 8 , 'call' : 9 , 'catch' : 10 , 'chitchat' : 11 , 'collection' : 12 , 'confirm' : 13 , 'correct' : 14 , 'deactivate' : 15 , 'default' : 16 , 'department' : 17 , 'digits' : 18 , 'domain' : 19 , 'error' : 20 , 'events' : 21 , 'face' : 22 , 'fallback' : 23 , 'find' : 24 , 'form' : 25 , 'full' : 26 , 'goodbye' : 27 , 'greet' : 28 , 'help' : 29 , 'homophonic' : 30 , 'host' : 31 , 'human' : 32 , 'info' : 33 , 'inform' : 34 , 'information' : 35 , 'invalid' : 36 , 'is' : 37 , 'joint' : 38 , 'judge' : 39 , 'key' : 40 , 'lack' : 41 , 'listen' : 42 , 'match' : 43 , 'name' : 44 , 'no' : 45 , 'once' : 46 , 'or' : 47 , 'order' : 48 , 'pass' : 49 , 'people' : 50 , 'phone' : 51 , 'reality' : 52 , 'rephrase' : 53 , 'reserve' : 54 , 'restart' : 55 , 'revert' : 56 , 'same' : 57 , 'self' : 58 , 'service' : 59 , 'session' : 60 , 'set' : 61 , 'short' : 62 , 'staff' : 63 , 'start' : 64 , 'user' : 65 , 'utter' : 66 , 'validity' : 67 , 'visitor' : 68 , 'wait' : 69 , 'welcome' : 70 , 'wrong' : 71 } num_actions = len ( action_names ) num_actions 62 trackers_as_actions = [ 'action_listen' , 'action_set_face_name' , 'utter_goodbye' , 'action_listen' ] ['action_listen', 'action_set_face_name', 'utter_goodbye', 'action_listen'] # Encode system action as one-hot vector. labels = [] # Multi_story def action_as_one_hot ( action ): y = np . zeros ( num_actions , dtype = int ) index_for_action = action_names . index ( action ) #print(f'Index for action: {index_for_action}') y [ index_for_action ] = 1 return y #print(f'One-hot of y: {y}\\n y shape: {y.shape}') story_labels = [ action_as_one_hot ( action ) for action in trackers_as_actions ] # one story and multi_turns labels . append ( story_labels ) y = np . array ( labels ) y . shape # (1dim, 2dim, 3dim) = (1, 4, 62) 1 story, 4 turns dialogue, 62 one-hot vector of action (1, 4, 62) # Create matrix with all actions from domain encoded in rows as bag of words def create_encoded_all_actions () -> np . ndarray : encoded_all_actions = np . zeros (( num_actions , len ( bot_vocab )), dtype = np . int32 ) for idx , name in enumerate ( action_names ): for t in name . split ( '_' ): encoded_all_actions [ idx , bot_vocab [ t ]] = 1 return encoded_all_actions encoded_all_label_ids = create_encoded_all_actions () encoded_all_label_ids . shape # 62 num of action, 72 bot vocab size (62, 72) # extract actual training data to feed to tf session print ( y . shape ) y # One-hot encode. (1, 4, 62): 1 story, 4 turns dialogue(one turn is one action), 62 vector of action (1, 4, 62) array([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]) label_ids = y . argmax ( - 1 ) label_ids array([[ 0, 14, 50, 0]]) d = [ - 1 , - 1 , - 1 ] d = np . array ( d ) d . argmax ( - 1 ) 0 label_ids . shape (1, 4) # full dialogue res = [] for seq_label_ids in label_ids : for label_idx in seq_label_ids : res . append ( encoded_all_label_ids [ label_idx ]) res [array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int32), array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)] res = np . stack ( res ) res array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32) label_ids . shape # explicitly add last dimension to label_ids to track correctly dynamic sequences (1, 4) label_ids = np . expand_dims ( label_ids , - 1 ) label_ids array([[[ 0], [14], [50], [ 0]]]) FullDialogueTrackerFeaturizer # Training data is padded up to the length of the longest dialogue with -1. ! jupyter nbconvert -- to markdown featurizer . ipynb [ NbConvertApp ] Converting notebook featurizer . ipynb to markdown [ NbConvertApp ] Writing 27001 bytes to featurizer . md","tags":"NLP","url":"articles/RASA-Featurizer.html","loc":"articles/RASA-Featurizer.html"},{"title":"ã€ NLP ã€‘Embedding","text":"embedding_dim=16 model = keras.Sequential([ layers.Embedding(vocab_size, embedding_dim, input_length=maxlen), layers.GlobalAveragePooling1D(), layers.Dense(16, activation='relu'), layers.Dense(1, activation='sigmoid') ]) Embedding: This layer takes the integer-encoded vocabulary and looks up the embedding vector for each word-index. These vectors are learned as the model trains. Embeddingå±‚çš„ä»»åŠ¡ï¼š å®šä¹‰çŸ©é˜µï¼Œå¤§å°ä¸º[vocab_size, embedding_dim] å¯¹äºidxåçš„æ–‡æœ¬å‘é‡[102, 33, 41, â€¦]ï¼ŒæŸ¥çŸ©é˜µï¼Œå°†idx -> embeddingå‘é‡ã€‚æœ€åå°†å¥å­è¡¨ç¤ºä¸º[max_len, embedding_size]çš„çŸ©é˜µã€‚å…¶ä¸­max_lenæ˜¯åšäº†paddingè¡¥å…¨æˆ–è€…æˆªæ–­æ“ä½œï¼Œå˜é•¿æ–‡æœ¬->å®šé•¿ã€‚ æ¨¡å‹è®­ç»ƒæ—¶æ˜¯ä»¥batch_sizeä¸ºå•ä½çš„ï¼Œæ‰€ä»¥embeddingå±‚æœ€ç»ˆçš„è¾“å‡ºæ˜¯ï¼šbatch_size * max_len * embedding_dimçš„3ç»´çŸ©é˜µã€‚ embeddingå±‚è¾“å‡ºçš„æ•°æ®å¯ä»¥åš GlobalAveragePooling1D åˆå¹¶ã€‚","tags":"NLP","url":"articles/ã€NLPã€‘Embedding.html","loc":"articles/ã€NLPã€‘Embedding.html"},{"title":"ã€ NLP ã€‘GlobalAveragePooling1D","text":"embedding_dim=16 model = keras.Sequential([ layers.Embedding(vocab_size, embedding_dim, input_length=maxlen), layers.GlobalAveragePooling1D(), layers.Dense(16, activation='relu'), layers.Dense(1, activation='sigmoid') ]) GlobalAveragePooling1D: return a fixed-length output vector for each example by averaging over the steps dimension. This allows the model to handle input of variable length, in the simplest way possible. Embedding è¾“å‡ºçš„æ–‡æœ¬æ•°æ®batch_size * max_len * embedding_sizeçš„ åˆå¹¶ -> å…¨å±€å¹³å‡æ± åŒ–æ“ä½œGlobalAveragePooling1D ï¼š è¾“å…¥æ•°æ®ï¼š(batch-size, steps, features)ã€‚æ˜¯ç»è¿‡embeddingå±‚çš„ç¨ å¯†çŸ©é˜µï¼Œstepsæ˜¯æ–‡æœ¬ä¸­tokensçš„ä¸ªæ•°ï¼ˆå˜é•¿ï¼‰ï¼Œfeaturesæ˜¯embedding-dimçš„ç»´åº¦ã€‚ è¾“å‡ºæ•°æ®ï¼š(batch-size, features)ã€‚å¯¹äºæ¯ä¸€ä¸ªfeature mapå³ä¸€æ¡æ–‡æœ¬è¯­å¥çš„embeddingçŸ©é˜µï¼ŒæŒ‰ç…§stepsæ–¹å‘æ±‚å¹³å‡ï¼ŒembeddingçŸ©é˜µè¢«æ± åŒ–ä¸ºembedding-dimç»´åº¦çš„å‘é‡ï¼Œæ¥è¡¨ç¤ºæœ¬æ¡æ–‡æœ¬è¯­å¥ã€‚ ä¼˜ç‚¹ï¼šè§£å†³æœ¬æ–‡è¯­å¥çš„å˜é•¿é—®é¢˜ ç¼ºç‚¹ï¼š ä¿¡æ¯æŸå¤±ï¼Œç”±äºæ˜¯å‡å€¼é™ç»´ä¸”paddingå™ªéŸ³ç¨€é‡Šæ•°æ®ã€‚ æ— æ•ˆè®¡ç®—è¿‡å¤šï¼Œç”±äºpaddingã€‚ è§£å†³æ–¹æ³•ï¼šå¾ªç¯ç¥ç»ç½‘ç»œRNN","tags":"NLP","url":"articles/ã€NLPã€‘GlobalAveragePooling1D.html","loc":"articles/ã€NLPã€‘GlobalAveragePooling1D.html"},{"title":"Cross Validation- CV","text":"CVè¦è§£å†³çš„é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ KæŠ˜äº¤å‰éªŒè¯ Cross Validation CVè¦è§£å†³çš„é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ å½“è¯„ä»·æ¨¡å‹çš„ä¸åŒè®¾ç½®ï¼ˆ\"hyperparameters(è¶…å‚æ•°)\"ï¼‰æ—¶ï¼Œ ç”±äºåœ¨è®­ç»ƒé›†ä¸Šï¼Œé€šè¿‡è°ƒæ•´å‚æ•°è®¾ç½®ä½¿æ¨¡å‹çš„æ€§èƒ½è¾¾åˆ°äº†æœ€ä½³çŠ¶æ€ï¼›ä½†åœ¨æµ‹è¯•é›†ä¸Š å¯èƒ½ä¼šå‡ºç°è¿‡æ‹Ÿåˆçš„æƒ…å†µã€‚ æ­¤æ—¶ï¼Œæµ‹è¯•é›†ä¸Šçš„ä¿¡æ¯åé¦ˆè¶³ä»¥é¢ è¦†è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè¯„ä¼°çš„æŒ‡æ ‡ä¸å†æœ‰æ•ˆåæ˜ å‡ºæ¨¡å‹çš„æ³›åŒ–æ€§èƒ½ã€‚ ä¸ºäº†è§£å†³æ­¤ç±»é—®é¢˜ï¼Œè¿˜åº”è¯¥å‡†å¤‡å¦ä¸€éƒ¨åˆ†è¢«ç§°ä¸º \"validation set(éªŒè¯é›†)\" çš„æ•°æ®é›†ï¼Œæ¨¡å‹è®­ç»ƒå®Œæˆä»¥ååœ¨éªŒè¯é›†ä¸Šå¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚ å½“éªŒè¯é›†ä¸Šçš„è¯„ä¼°å®éªŒæ¯”è¾ƒæˆåŠŸæ—¶ï¼Œåœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæœ€åçš„è¯„ä¼°ã€‚ ç„¶è€Œï¼Œé€šè¿‡å°†åŸå§‹æ•°æ®åˆ†ä¸º3ä¸ªæ•°æ®é›†åˆï¼Œæˆ‘ä»¬å°±å¤§å¤§å‡å°‘äº†å¯ç”¨äºæ¨¡å‹å­¦ä¹ çš„æ ·æœ¬æ•°é‡ï¼Œ å¹¶ä¸”å¾—åˆ°çš„ç»“æœä¾èµ–äºé›†åˆå¯¹ï¼ˆè®­ç»ƒï¼ŒéªŒè¯ï¼‰çš„éšæœºé€‰æ‹©ã€‚è¿™ä¸ªé—®é¢˜å¯ä»¥é€šè¿‡ äº¤å‰éªŒè¯ï¼ˆ CV ï¼‰ jæ¥è§£å†³ã€‚ äº¤å‰éªŒè¯ä»éœ€è¦æµ‹è¯•é›†åšæœ€åçš„æ¨¡å‹è¯„ä¼°ï¼Œä½†ä¸å†éœ€è¦éªŒè¯é›†ã€‚ KæŠ˜äº¤å‰éªŒè¯","tags":"ML","url":"articles/Cross-Validation-CV.html","loc":"articles/Cross-Validation-CV.html"},{"title":"Docker","text":"nvidia-dockerå¤šç”¨æˆ·å…±äº«GPUæœåŠ¡å™¨ç¯å¢ƒæ­å»º åˆ›å»ºå®¹å™¨ è¿›å…¥å®¹å™¨ æ·»åŠ å·²è¿è¡Œå®¹å™¨ç«¯å£ ä¿®æ”¹å®¹å™¨å®¹é‡ dockeræˆæƒérootç”¨æˆ· å®¹å™¨å†…ä¸­æ–‡ä¹±ç  æœåŠ¡å™¨dockerä¸­å¯å¯è¿œç¨‹notebook PyCharm + Dockerç‚¼ä¸¹ç‚‰ åˆ¶ä½œé•œåƒå¹¶ä¸Šä¼ ä»“åº“ docker-compose && dockerfile nvidia-dockerå¤šç”¨æˆ·å…±äº«GPUæœåŠ¡å™¨ç¯å¢ƒæ­å»º https://blog.csdn.net/hangvane123/article/details/88639279 nvidiaé©±åŠ¨ docker-ce nvidia-docker pullå¸¦æœ‰cudaå’Œcudnnçš„ubuntué•œåƒ https://hub.docker.com/r/nvidia/cuda docker pull nvidia/cuda:10.1-cudnn7-devel-ubuntu18.04 å‹¿ä¸‹è½½runtimeç‰ˆï¼Œè€Œæ˜¯develï¼Œå¦åˆ™å¾ˆå¤šé…ç½®æ–‡ä»¶æ‰¾ä¸åˆ°ã€‚ å¯åŠ¨å®¹å™¨ï¼Œè¿›å…¥å®¹å™¨ apt-get update apt-get install python3-pip å®‰è£…ä¸cuda, cudnnç‰ˆæœ¬åŒ¹é…çš„tensorflow-gpu åˆ›å»ºå®¹å™¨ # - itäº¤äº’å¼ç»ˆç«¯è¿è¡Œ , å‚æ•° / bin / bashå¯åŠ¨ubuntu , -- nameå‘½åå®¹å™¨ # docker run - it - p [ host_port ] : [ container_port ] ( do not use 8888 ) -- name =[ container_name ] [ image_name ] - v [ host_path ] : [ container_path ] / bin / bash $ nvidia - docker run - itd -- name = dev -- shm - size 10 g - v / data / mnt : / home - p 8180 : 8180 - p 8280 : 8280 - p 8380 : 8380 - p 8480 : 8480 - p 9380 : 22 nvidia / cuda : 10.1 - cudnn7 - devel - ubuntu18 .04 / bin / bash # æŸ¥çœ‹æ‰€æœ‰å®¹å™¨ $ docker ps - a è¿›å…¥å®¹å™¨ $: docker exec - it cuda10_0 env LANG = C . UTF - 8 / bin / bash æ·»åŠ å·²è¿è¡Œå®¹å™¨ç«¯å£ æŸ¥çœ‹å®¹å™¨å· docker ps -a åœæ­¢å®¹å™¨ docker stop æŸ¥æ‰¾å®¹å™¨ç›®å½• docker inspect [å®¹å™¨å·ID] | grep Id åœæ­¢dockeræœåŠ¡(systemctl stop docker) æŸ¥æ‰¾å®¹å™¨è·¯å¾„ï¼š find / -name containers ä¿®æ”¹è¿™ä¸ªå®¹å™¨çš„ /usr/local/docker/containers/... hostconfig.jsonæ–‡ä»¶ä¸­çš„ç«¯å£: \"PortBindings\":{\"3306/tcp\":[{\"HostIp\":\"\",\"HostPort\":\"3307\"}]} å‰è€…æ˜¯å®¹å™¨ç«¯å£, åè€…æ˜¯å®¿ä¸»æœºç«¯å£ã€‚ ä¿®æ”¹è¯¥å®¹å™¨çš„config.v2.jsonæ–‡ä»¶ä¸­çš„ExposedPortsã€‚ å¯åŠ¨dockeræœåŠ¡(systemctl start docker) å¯åŠ¨å®¹å™¨ https://blog.csdn.net/lypeng_/article/details/98176138 https://blog.csdn.net/wesleyflagon/article/details/78961990 ä¿®æ”¹å®¹å™¨å®¹é‡ # CID ---> /dev/mapper/docker # 100 ---> 100G . / script . sh 100 ` CID = \"62f54c85d02ec67b64c1ea15b0c3820edeea6744f7a052f0e795ea127d3fb28e\" SIZE =$ 1 if [ \"$CID\" != \"\" ] && [ \"$SIZE\" != \"\" ]; then DEV =$ ( basename $ ( echo / dev / mapper / docker -*-$ CID )); dmsetup table $ DEV | sed \"s/0 [0-9]* thin/0 $(($SIZE*1024*1024*1024/512)) thin/\" | dmsetup load $ DEV ; dmsetup resume $ DEV ; xfs_growfs / dev / mapper /$ DEV ; docker start container_name docker exec - it container_name env LANG = C . UTF - 8 / bin / bash echo \"Resize $CID completed.\" else echo \"Usage: sh resize_container 459fd505311ad364309940ac24dcdb2bdfc68e3c3b0f291c9153fb54fbd46771 100\" ; fi dockeræˆæƒérootç”¨æˆ· sudo usermod -a -G docker AD\\\\yckj2939 sudo groupadd docker # æ·»åŠ dockerç”¨æˆ·ç»„ sudo gpasswd -a $USER docker # å°†ç™»é™†ç”¨æˆ·åŠ å…¥åˆ°dockerç”¨æˆ·ç»„ä¸­ newgrp docker # æ›´æ–°ç”¨æˆ·ç»„ docker ps # æµ‹è¯•dockerå‘½ä»¤æ˜¯å¦å¯ä»¥ä½¿ç”¨sudoæ­£å¸¸ä½¿ç”¨ systemctl restart docker # ï¼ï¼ï¼ä¸€å®šé‡å¯ å®¹å™¨å†…ä¸­æ–‡ä¹±ç  $ vim /etc/profile $ export LANG = C.UTF-8 æœåŠ¡å™¨dockerä¸­å¯å¯è¿œç¨‹notebook å¯ubuntuå®¹å™¨ï¼Œå¼€å‡ºç«¯å£8888 nvidia-docker run -itd --name=cuda10_0 -v /mnt/docker_share:/home/centos -p 8888:8888 nvidia/cuda è¿›å…¥å®¹å™¨å®‰è£…anaconda $: docker exec - it cuda10_0 / bin / bash $: cd ~ | . / Anaconda . sh é…ç½®notebookåœ¨.jupyteræ–‡ä»¶å¤¹ä¸‹ $: jupyter notebook --generate-config # ä¼šè‡ªåŠ¨ç”Ÿæˆ.jupyteræ–‡ä»¶å¤¹ $: jupyter notebook password ç”Ÿæˆå¯†é’¥ï¼š jupyter_notebook_config.json ä¿®æ”¹æ–‡ä»¶ï¼š jupyter_notebook_config.py c.NotebookApp.ip='*' c.NotebookApp.password = u'ç”Ÿæˆçš„å¯†é’¥' # jupyter_notebook_config.jsonæ–‡ä»¶ä¸­çš„passwordå­—æ®µ c.NotebookApp.open_browser = False c.NotebookApp.port = 8888 #å¯æŒ‡å®šä¸€ä¸ªç«¯å£, è®¿é—®æ—¶ä½¿ç”¨è¯¥ç«¯å£ï¼ˆè™½ç„¶è¿è¡Œjupyteræ—¶å¯ä»¥ç›´æ¥æŒ‡å®šç«¯å£ï¼‰ c.NotebookApp.notebook_dir = '/home' # è‡ªå®šä¹‰å¯åŠ¨ç›®å½• https://blog.csdn.net/qq_42001765/article/details/96144442 åå°è¿è¡Œ nohup jupyter notebook --ip=0.0.0.0 --no-browser --allow-root --port 8888 > jupyter.log 2>&1 & è¿œç¨‹è®¿é—® # server_ip:port 10.235.3.43:8888 å®¹å™¨å†…è‡ªåŠ¨åŒ–è„šæœ¬ï¼š 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #!/bin/sh # enter docker cd ~ jupyter notebook --generate-config echo 'Please input jupyter notebook password' jupyter notebook password echo 'Password input success!' chmod 777 ~/.jupyter/jupyter_notebook_config.json PASSWORD = $( cat ~/.jupyter/jupyter_notebook_config.json | grep password | awk -F '\"' '{print $4}' ) echo \"c.NotebookApp.ip='*'\" >> ~/.jupyter/jupyter_notebook_config.py echo \"c.NotebookApp.password = ' $PASSWORD '\" >> ~/.jupyter/jupyter_notebook_config.py echo \"c.NotebookApp.open_browser = False\" >> ~/.jupyter/jupyter_notebook_config.py echo \"c.NotebookApp.port = 8480\" >> ~/.jupyter/jupyter_notebook_config.py echo \"c.NotebookApp.notebook_dir = '/home'\" >> ~/.jupyter/jupyter_notebook_config.py nohup jupyter notebook --ip = 0 .0.0.0 --no-browser --allow-root --port 8480 > jupyter.log 2 > & 1 & PyCharm + Dockerç‚¼ä¸¹ç‚‰ PyCharm Pro + Nvidia Docker å‚ç…§ä¸Šæ–‡å¢åŠ å®¹å™¨22ç«¯å£ï¼ŒSFTPé»˜è®¤ä½¿ç”¨22ç«¯å£ã€‚ è¿œç¨‹æœåŠ¡å™¨å‚æ•°æŸ¥çœ‹ $ docker port <your container name> 22 # æ­¤æ“ä½œå°†æŸ¥çœ‹docker containerä¸­ç«¯å£22ï¼Œåœ¨è¿œç¨‹æœåŠ¡å™¨ä¸Šç«¯å£çš„æ˜ å°„ # è¾“å‡ºç»“æœå¦‚ä¸‹æ‰€ç¤º 0 .0.0.0:9380 # è¡¨æ˜åªè¦sshé“¾æ¥è¿œç¨‹æœåŠ¡å™¨çš„9380ç«¯å£ï¼Œå®é™…æ˜¯é“¾æ¥docker containerä¸­çš„22ç«¯å£ ssh root@<æœåŠ¡å™¨çš„ipåœ°å€> -p 9380 # å¯ä»¥è¿›å…¥å®¹å™¨ï¼Œpasswdå‘½ä»¤å¯ä»¥ä¿®æ”¹å®¹å™¨rootå¯†ç  è¿›å…¥å®¹å™¨é…ç½®sshæœåŠ¡ # ä¿®æ”¹rootå¯†ç  $ passwd # å®‰è£…open-ssh $ apt-get update $ apt-get install openssh-server $ vim /etc/ssh/sshd_config $ server ssh restart /etc/ssh/sshd_configä¿®æ”¹ä»¥ä¸‹ä½ç½®ï¼š # Subsystem sftp /usr/libexec/openssh/sftp-server Subsystem sftp internal-sftp PubkeyAuthentication yes AuthorizedKeysFile .ssh/authorized_keys #å…¬é’¥æ–‡ä»¶è·¯å¾„ï¼ˆå’Œä¸Šé¢ç”Ÿæˆçš„æ–‡ä»¶åŒï¼‰ PermitRootLogin yes æœ€å¸¸è§çš„é—®é¢˜å°±æ˜¯dockerå®¹å™¨åœäº†ä»¥åé‡Œé¢çš„SSHæœåŠ¡ä¹Ÿä¼šç›¸åº”åœæ­¢ï¼Œè®°å¾—å»dockeré‡Œé‡å¯ä¸€ä¸‹sshæœåŠ¡ï¼š $ service ssh restart https://www.cnblogs.com/ruiyang-/p/10158658.html åˆ¶ä½œé•œåƒå¹¶ä¸Šä¼ ä»“åº“ dockerhubä¸Šåˆ›å»ºä»“åº“ jerrysu666/cuda10.0 ç»ˆç«¯ç™»å½•ï¼š docker login åˆ¶ä½œé•œåƒï¼š docker commit containerId dockerUserName/repoName é•œåƒæ‰“æ ‡ç­¾ï¼š docker tag imageName dockerUserName/repoName[:tag] æ¨é€é•œåƒï¼š docker push dockerUserName/repoNme[:tag] docker tag local-image:tagname new-repo:tagname docker push new-repo:tagname docker push jerrysu666/cuda10.0:tagname docker-compose && dockerfile # docker - compose version : \"2.3\" services : detectron2 : build : context : . dockerfile : Dockerfile args : USER_ID : $ { USER_ID :- 1000 } runtime : nvidia shm_size : \"8gb\" ulimits : memlock : - 1 stack : 67108864 ports : - \"8170:8170\" - \"8270:8270\" - \"8370:8370\" - \"8470:8470\" - \"8570:22\" volumes : - / data : / home environment : - DISPLAY = $ DISPLAY - NVIDIA_VISIBLE_DEVICES = all # dockerfile FROM nvidia / cuda : 10.1 - cudnn7 - devel - ubuntu18 . 04 ENV DEBIAN_FRONTEND noninteractive RUN apt - get update && apt - get install - y \\ python3 - opencv ca - certificates python3 - dev git wget sudo && \\ rm - rf / var / lib / apt / lists /* # create a non-root user ARG USER_ID = 1000 RUN useradd - m -- no - log - init -- system -- uid $ { USER_ID } appuser - g sudo RUN echo ' %s udo ALL=(ALL) NOPASSWD:ALL' >> / etc / sudoers USER appuser WORKDIR / home / appuser ENV PATH = \"/home/appuser/.local/bin:${PATH}\" RUN wget https : // bootstrap . pypa . io / get - pip . py && \\ python3 get - pip . py -- user && \\ rm get - pip . py # install dependencies # See https://pytorch.org/ for other options if you use a different version of CUDA RUN pip install -- user torch torchvision tensorboard cython - i https : // pypi . doubanio . com / simple RUN pip install -- user 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI' RUN pip install -- user 'git+https://github.com/facebookresearch/fvcore' # install detectron2 RUN git clone https : // github . com / facebookresearch / detectron2 detectron2_repo ENV FORCE_CUDA = \"1\" # This will build detectron2 for all common cuda architectures and take a lot more time, # because inside `docker build`, there is no way to tell which architecture will be used. ENV TORCH_CUDA_ARCH_LIST = \"Kepler;Kepler+Tesla;Maxwell;Maxwell+Tegra;Pascal;Volta;Turing\" RUN pip install -- user - e detectron2_repo # Set a fixed model cache directory. ENV FVCORE_CACHE = \"/tmp\" WORKDIR / home / appuser / detectron2_repo","tags":"Tools","url":"articles/Docker.html","loc":"articles/Docker.html"},{"title":"Conda","text":"anaconda3å¤šç”¨æˆ·å…±äº«å®‰è£… åˆ›å»ºcondaè™šæ‹Ÿç¯å¢ƒ åœ¨Notebookä¸­åˆ‡æ¢condaè™šæ‹Ÿç¯å¢ƒ anaconda3å¤šç”¨æˆ·å…±äº«å®‰è£… > sudo bash Anaconda - latest - Linux - x86_64 . sh > åœ¨ linuxä¸‹å®‰è£…ç¬¬ä¸‰æ–¹å¤šç”¨æˆ·ä½¿ç”¨çš„å…±äº«è½¯ä»¶ä¸€èˆ¬éƒ½æŒ‰åœ¨ / usr / local ç›®å½• > é…ç½® / etc / profile æ–‡ä»¶ï¼Œåœ¨è¯¥æ–‡ä»¶æœ€ååŠ å…¥ export PATH =/ usr / local / anaconda3 / bin : $ PATH > source / etc / profile åˆ›å»ºcondaè™šæ‹Ÿç¯å¢ƒ > conda info --envs > conda create -n rasa_101 python=3.6.8 > conda activate rasa_101 > pip install rasa==1.0.1 -i https://pypi.tuna.tsinghua.edu.cn/simple > pip install tensorflow==1.14.0 -i https://pypi.tuna.tsinghua.edu.cn/simple > conda info --envs -i è±†ç“£æºhttps://pypi.doubanio.com/simple pychram->file-> Settings -> Project :-> Project Interpreter C : \\ Users \\ YCKJ2939 \\ AppData \\ Local \\ Continuum \\anaconda3\\envs\\rasa_101 åœ¨Notebookä¸­åˆ‡æ¢condaè™šæ‹Ÿç¯å¢ƒ è¿›å…¥å®¹å™¨å®‰è£…nb_condaæ’ä»¶ conda install nb_conda è¿›å…¥è™šæ‹Ÿç¯å¢ƒå®‰è£…jupyter $: source activate env_name $: conda install -y jupyter é€€å‡ºè™šæ‹Ÿç¯å¢ƒé‡å¯jupyter $: ps -aux | grep jupyter $: kill pid $: nohup jupyter notebook --ip=0.0.0.0 --no-browser --allow-root --port 8888 > jupyter.log 2>&1 & Error # An error occurred while retrieving installed packages . # EnvironmentLocationNotFound : Not a conda environment : / root / anaconda3 / envs / anaconda3 # è§£å†³æ–¹æ³• ï¼š # æ‰¾åˆ°Anacondaå®‰è£…è·¯å¾„ä¸‹nb_condaåº“çš„envmanager . pyæ–‡ä»¶ # winç³»ç»Ÿåœ¨ç›®å½• ï¼š Anaconda3 \\ Lib \\ site - packages \\ nb_conda \\ envmanager . py # linuxç³»ç»Ÿåœ¨ç›®å½• ï¼š / root / anaconda3 / pkgs / nb_conda - 2.2.1 - py37_0 / lib / python3 .7 / site - packages / nb_conda / envmanager . py # æ‰¾åˆ°è¯¥æ–‡ä»¶ååœ¨83 ~ 86 è¡Œä»£ç æ”¹æˆå¦‚ä¸‹ä»£ç  ï¼š return { \"environments\" : [ root_env ] + [ get_info(env) for env in info['envs' ] if env != root_env [ 'dir' ] ] } # é‡å¯jupyter ï¼Œ å‚è§ä¸Šè¿° https://blog.csdn.net/IT_xiao_bai/article/details/102765922","tags":"Tools","url":"articles/Conda.html","loc":"articles/Conda.html"},{"title":"Logistic Regression","text":"1. Linear Regression 1.1 çº¿æ€§æ¨¡å‹ 1.2 æ‹Ÿåˆçº¿æ€§æ¨¡å‹çš„æŸå¤±å‡½æ•° 1.3 çº¿æ€§å›å½’çš„æ­£åˆ™åŒ– 2. Logistic Regression 2.1 é€»è¾‘å›å½’æ¨¡å‹ 2.2 æ‹Ÿåˆé€»è¾‘å›å½’æ¨¡å‹çš„æŸå¤±å‡½æ•° 2.3 LRæ¨¡å‹çš„æŸå¤±å‡½æ•°å¯ä»¥ä½¿ç”¨çº¿æ€§æ¨¡å‹çš„å¹³æ–¹æŸå¤±å‡½æ•°å—ï¼Ÿ 2.3 LRæ¨¡å‹çš„æŸå¤±å‡½æ•°å¦‚ä½•æ¨å¯¼? 2.4 æŸå¤±å‡½æ•°çš„ç´§å‡‘å½¢å¼æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆæ˜¯è¿™ç§å½¢å¼ï¼Ÿ 2.5 å¦‚ä½•æ‹Ÿåˆå‚æ•°ï¼Ÿ 2.6 å¦‚ä½•æœ€å°åŒ–æŸå¤±å‡½æ•°ï¼Ÿ 2.7 æå¤§ä¼¼ç„¶ä¼°è®¡ 2.8 é€»è¾‘å›å½’çš„æ­£åˆ™åŒ– 3. å›å½’å’Œåˆ†ç±»çš„æœ¬è´¨åŒºåˆ« 1. Linear Regression 1.1 çº¿æ€§æ¨¡å‹ $$f(x) = \\Theta&#94;Tx$$ 1.2 æ‹Ÿåˆçº¿æ€§æ¨¡å‹çš„æŸå¤±å‡½æ•° å¹³æ–¹æŸå¤±ï¼š $$\\frac{1}{m}\\sum_{n=1}&#94;{m} \\frac{1}{2} \\left ( f(x&#94;{(n)}) - y&#94;{(n)} \\right )&#94;2$$ ä»€ä¹ˆæ˜¯æœ€å°äºŒä¹˜æ³•ï¼Ÿ åŸºäºå¹³æ–¹æŸå¤±è¯¯å·®æœ€å°åŒ–è¿›è¡Œæ¨¡å‹æ±‚è§£çš„æ–¹æ³•ç§°ä¸º æœ€å°äºŒä¹˜æ³• ã€‚åœ¨çº¿æ€§æ¨¡å‹ä¸­ï¼Œæœ€å°äºŒä¹˜æ³•å°±æ˜¯è¯•å›¾æ‰¾åˆ°ä¸€æ¡ç›´çº¿ï¼Œä½¿å¾—æ‰€æœ‰æ ·æœ¬åˆ°ç›´çº¿ä¸Šçš„æ¬§å¼è·ç¦»ä¹‹å’Œæœ€å°ã€‚ å¹³æ–¹æŸå¤±å‡½æ•°æ˜¯è¿ç»­å¯å¾®çš„å‡¸å‡½æ•°ï¼Œå­˜åœ¨å…¨å±€æœ€å°å€¼ï¼Œå¯ä»¥é€šè¿‡æ¢¯åº¦ä¸‹é™æ³•æ±‚è§£æœ€ä¼˜å€¼ã€‚ 1.3 çº¿æ€§å›å½’çš„æ­£åˆ™åŒ– 2. Logistic Regression 2.1 é€»è¾‘å›å½’æ¨¡å‹ Sigmoidå‡½æ•°: $$ f(x) = \\frac{1}{1+e&#94;{-z}} $$ 2.2 æ‹Ÿåˆé€»è¾‘å›å½’æ¨¡å‹çš„æŸå¤±å‡½æ•° $$-\\frac{1}{m}\\left [ \\sum_{i=1}&#94;{m} y&#94;{(i)}logf(x&#94;{(i)}) + (1-y&#94;{(i)})log(1-f(x&#94;{(i)})) \\right ], \\ \\ f(x)ä¸ºé€»è¾‘æ¨¡å‹$$ é€»è¾‘å›å½’è§£å†³çš„æ˜¯åˆ†ç±»é—®é¢˜ï¼Œæ˜¯ å¹¿ä¹‰çº¿æ€§æ¨¡å‹ ï¼Œåœ¨çº¿æ€§æ¨¡å‹$z=\\Theta&#94;Tx$ä¸Šå¥—ä¸€å±‚sigmoidå‡½æ•°ã€‚ 2.3 LRæ¨¡å‹çš„æŸå¤±å‡½æ•°å¯ä»¥ä½¿ç”¨çº¿æ€§æ¨¡å‹çš„å¹³æ–¹æŸå¤±å‡½æ•°å—ï¼Ÿ ä¸å¯ä»¥ï¼Œå°†LRæ¨¡å‹éçº¿æ€§çš„sigmoidå‡½æ•°å¸¦å…¥å¹³æ–¹æŸå¤±å‡½æ•°f(x)å¾—åˆ°çš„æ˜¯ä¸€ä¸ªéå‡¸å‡½æ•°ï¼Œå­˜åœ¨è‹¥å¹²ä¸ªå±€éƒ¨æœ€å°å€¼ï¼Œæ— æ³•åˆ©ç”¨æ¢¯åº¦ä¸‹é™æ³•æ±‚è§£æœ€ä¼˜å€¼é—®é¢˜ã€‚ 2.3 LRæ¨¡å‹çš„æŸå¤±å‡½æ•°å¦‚ä½•æ¨å¯¼? å›¾åƒæ€§è´¨ï¼š å¦‚æœæ ‡ç­¾y=1ï¼Œé¢„æµ‹å€¼h(x)ä¹Ÿä¸º1ï¼Œæ­¤æ—¶çš„æŸå¤±å€¼æœ€å°ä¸º0ï¼›å½“h(x)è¶‹å‘0æ—¶ï¼ŒæŸå¤±å€¼è¶‹è¿‘äºæ— ç©·å¤§ã€‚æ‰€ä»¥ï¼Œé¢„æµ‹å€¼h(x)ä¸yè¶Šæ¥è¿‘ï¼ŒæŸå¤±å€¼è¶Šè¶‹å‘äº0ã€‚ case y=0: åä¹‹ï¼Œé¢„æµ‹å€¼h(x)æ¥è¿‘æ ‡ç­¾yå€¼0ï¼Œåˆ™æŸå¤±å€¼æ”¶æ•›ä¸0ã€‚ 2.4 æŸå¤±å‡½æ•°çš„ç´§å‡‘å½¢å¼æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆæ˜¯è¿™ç§å½¢å¼ï¼Ÿ $$-\\frac{1}{m}\\left [ \\sum_{i=1}&#94;{m} y&#94;{(i)}logf(x&#94;{(i)}) + (1-y&#94;{(i)})log(1-f(x&#94;{(i)})) \\right ], \\ \\ f(x)ä¸ºé€»è¾‘æ¨¡å‹$$ æŸå¤±å‡½æ•°æ˜¯ç»Ÿè®¡å­¦ä¸­çš„æå¤§ä¼¼ç„¶ä¼°è®¡æ¨å¯¼è€Œæ¥ï¼Œæ˜¯ç»Ÿè®¡å­¦ä¸­ä¸ºä¸åŒæ¨¡å‹å¿«é€Ÿå¯»æ‰¾å‚æ•°çš„æ–¹æ³•ã€‚åŒæ—¶æ‹¥æœ‰ä¸€ä¸ªæ¯”è¾ƒå¥½çš„æ€§è´¨ï¼Œæ˜¯å‡¸å‡½æ•°ã€‚ 2.5 å¦‚ä½•æ‹Ÿåˆå‚æ•°ï¼Ÿ é€šè¿‡æœ€å°åŒ–æŸå¤±å‡½æ•°ï¼Œæ¥æ‹Ÿåˆè®­ç»ƒæ•°æ®é›†ï¼Œä»è€Œæ‰¾åˆ°æ¨¡å‹å‚æ•°$\\Theta$ï¼Œæœ€ç»ˆç¡®å®šæ¨¡å‹ã€‚ 2.6 å¦‚ä½•æœ€å°åŒ–æŸå¤±å‡½æ•°ï¼Ÿ å¯¹æŸå¤±å‡½æ•°ï¼š æ¢¯åº¦ä¸‹é™æ³• 2.7 æå¤§ä¼¼ç„¶ä¼°è®¡ 2.8 é€»è¾‘å›å½’çš„æ­£åˆ™åŒ– 3. å›å½’å’Œåˆ†ç±»çš„æœ¬è´¨åŒºåˆ« ç›®æ ‡å’Œæ–¹æ³•ï¼š å¯¹äºå›å½’é—®é¢˜ï¼šç›®æ ‡å’Œæ–¹æ³•æ˜¯ä¸€è‡´çš„ ç›®æ ‡ï¼š pred = y æ–¹æ³•ï¼š æœ€å°åŒ–é¢„æµ‹å€¼predå’ŒçœŸå®å€¼yçš„è·ç¦»ï¼Œå³ minimize dist(pred, y) å¯¹äºåˆ†ç±»é—®é¢˜ï¼š ç›®æ ‡ï¼š maxmize baseline. e.g. accuracy æ–¹æ³•ï¼š $$minimize dst(p_Î¸(y|x), p_r(y|x))$$ entropy","tags":"ML","url":"articles/Logistic-Regression.html","loc":"articles/Logistic-Regression.html"},{"title":"Spark","text":"3.sparkç®€ä»‹ 3.1.sparkå®šä¹‰ 3.2.sparkå’Œhadoopå…³ç³» 3.3.sparkä¼˜ç‚¹ 4. sparkéƒ¨ç½²æ¨¡å¼ 4.1.localæœ¬åœ°æ¨¡å¼ 4.2.standaloneé›†ç¾¤æ¨¡å¼ 4.3.yarné›†ç¾¤æ¨¡å¼ 5.sparké›†ç¾¤æ­å»º 5.1.æœºå™¨å‡†å¤‡ 5.2.æœºå™¨çš„ç¯å¢ƒé…ç½® 5.2.1.å…å¯†ç™»é™† 5.2.2.å…³é—­é˜²ç«å¢™ 5.2.3.ipä¸hostçš„æ˜ å°„å…³ç³» 3.sparkç®€ä»‹ 3.1.sparkå®šä¹‰ sparkæ˜¯åŸºäº å†…å­˜ çš„ï¼Œ åˆ†å¸ƒå¼ çš„ï¼Œ å¤§æ•°æ® å¹¶è¡Œè®¡ç®—æ¡†æ¶ ï¼ˆå¤„ç†å¼•æ“ï¼‰ è¿­ä»£å¼è®¡ç®—ï¼Œä¼˜å…ˆä½¿ç”¨å†…å­˜ï¼Œå†…å­˜ä¸è¶³ï¼Œå†ä½¿ç”¨ç£ç›˜ã€‚ åˆ†å¸ƒå¼ï¼šæ•°æ®å­˜å‚¨åˆ†å¸ƒå¼ï¼›è¿ç®—åˆ†å¸ƒå¼ã€‚ spark + æ•°æ®æºï¼ˆhdfsï¼‰ 3.2.sparkå’Œhadoopå…³ç³» hadoopï¼šhdfs mapreduce yarn spark + hadfs spark + yarn spark å’Œ mapreduceæ¯”è¾ƒ mapreduceï¼šç¬¬ä¸€ä»£åˆ†å¸ƒå¼è¿è¡Œæ¡†æ¶ã€‚åˆ†æ²»ç¼–ç¨‹æ€æƒ³ã€‚ mapreduceï¼š ä¸¤æ­¥è®¡ç®—ï¼Œç£ç›˜å­˜å‚¨; sparkï¼šå¤šæ­¥è®¡ç®—ï¼Œå†…å­˜å­˜å‚¨ã€‚ç±»ä¼¼äºscalaçš„å‡½æ•°å¼ç¼–ç¨‹ï¼Œé“¾å¼ç¼–ç¨‹ã€‚ sparkåŸºäºå†…å­˜ï¼Œè¿­ä»£æ•ˆç‡æ›´é«˜ï¼ˆç”±äºDAGæœ‰å‘æ— ç¯å›¾ï¼‰ sparkå®¹é”™æ€§æ›´å¥½ï¼ˆç”±äºRDDï¼‰ sparkç®—å­æ›´å¤š sparkæ”¯æŒçš„è¯­è¨€æ›´å¤šï¼ˆscalaã€javaã€pythonã€Rï¼‰ ç»“è®ºï¼šsparkæ˜¯mapreduceçš„æ›¿ä»£æ–¹æ¡ˆï¼Œå…¼å®¹hdfsã€hiveï¼Œå¯èå…¥hadoopç”Ÿæ€åœˆï¼Œå¼¥è¡¥mapreduceçš„ä¸è¶³ã€‚ 3.3.sparkä¼˜ç‚¹ é€Ÿåº¦å¿« æ˜“ç”¨æ€§ æ”¯æŒscalaã€javaã€pythonã€r é€šç”¨æ€§ã€ a. ä¸€ç«™å¼è§£å†³æ–¹æ¡ˆï¼šç¦»çº¿åˆ†æ å®æ—¶å¤„ç† æœºå™¨å­¦ä¹  å›¾è®¡ç®— sql b. å‡å°‘å…¬å¸å¼€å‘çš„äººåŠ›ç‰©åŠ›æˆæœ¬ å…¼å®¹æ€§ a. spark + mysql redis kafka hdfs yarn zookeeper 4. sparkéƒ¨ç½²æ¨¡å¼ 4.1.localæœ¬åœ°æ¨¡å¼ å¼€ç®±å³ç”¨ï¼Œä¸€å°æœºå™¨å³å¯ã€‚å¤šçº¿ç¨‹æ¨¡æ‹Ÿã€‚ 4.2.standaloneé›†ç¾¤æ¨¡å¼ æ˜¯sparkå®‰è£…åŒ…è‡ªå¸¦çš„é›†ç¾¤æ¨¡å¼ 4.3.yarné›†ç¾¤æ¨¡å¼ yarnï¼šèµ„æºè°ƒåº¦å¹³å°ï¼ˆå…¬å¸å¸¸ç”¨æ¨¡å¼ï¼‰ æŠŠsparkä»»åŠ¡æäº¤åˆ°yarné›†ç¾¤è¿è¡Œ 5.sparké›†ç¾¤æ­å»º é›†ç¾¤æ­å»ºç‰¹æŒ‡ï¼šstandsloneé›†ç¾¤ã€‚è§’è‰²ï¼šmaster å’Œ worker sshè¿œç¨‹æœåŠ¡å™¨ï¼šip port user password è·³æ¿æœºå™¨ï¼šå¦‚æœæœåŠ¡å™¨rnoæ˜¯å†…ç½‘çš„ï¼Œå¤–ç½‘æ— æ³•ç›´æ¥è®¿é—®ã€‚å¤–ç½‘éœ€è¦ä¸€ä¸ªè·³æ¿æœºï¼ˆbastionï¼‰ã€‚ 5.1.æœºå™¨å‡†å¤‡ a1 192.168.23.1 master a2 192.168.23.2 worker a3 192.168.23.3 worker è‡³å°‘ä¸¤å° 5.2.æœºå™¨çš„ç¯å¢ƒé…ç½® 5.2.1.å…å¯†ç™»é™† é…ç½®ä¸»èŠ‚ç‚¹åˆ°ä»èŠ‚ç‚¹çš„å…å¯†ç™»é™†å³å¯ã€‚ # ssh-keygen # ssh-copy-id ip 5.2.2.å…³é—­é˜²ç«å¢™ å¤§æ•°æ®é›†ç¾¤ï¼Œä¸€èˆ¬éƒ½æ˜¯å†…ç½‘é›†ç¾¤ï¼Œä¸éœ€è¦å¼€å¯é˜²ç«å¢™ã€‚ æœ‰å•ç‹¬çš„æœºå™¨ï¼Œå…·å¤‡å†…ç½‘å’Œå¤–ç½‘ç¯å¢ƒï¼Œå¯ä»¥é€šè¿‡è¯¥æœºå™¨è¿›è¡Œå¯¹å¤–é€šä¿¡ã€‚ # service iptables status // æŸ¥çœ‹é˜²ç«å¢™ # service iptables stop // å…³é—­é˜²ç«å¢™ # ckconfig iptables off // æ°¸ä¹…å…³é—­ 5.2.3.ipä¸hostçš„æ˜ å°„å…³ç³» ä½¿ç”¨hostname # cat /etc/hosts 127.0.0.1 localhost 255.255.255.255 broadcasthost ::1 localhost 202.76.247.23 ion-ljz.corp.ebay.com 192.168.23.1 a1 192.168.23.2 a2 192.168.23.3 a3","tags":"Programming","url":"articles/Spark.html","loc":"articles/Spark.html"},{"title":"Spark Partitions with Coalesce and Repartition","text":"Spark splits data into partitions and executes computations on the partitions in parallel. You should understand how data is partitioned and when you need to manually adjust the partitioning to keep your Spark computations running efficiently. https://medium.com/@mrpowers/managing-spark-partitions-with-coalesce-and-repartition-4050c57ad5c4","tags":"Programming","url":"articles/Spark-Partitions-with-Coalesce-and-Repartition.html","loc":"articles/Spark-Partitions-with-Coalesce-and-Repartition.html"},{"title":"Scala Tips","text":"foreach val xs = List ( \"date\" , \"since\" , \"other1\" , \"other2\" ) xs . foreach { str => str match { case \"date\" => println ( \"Match Date\" ) case \"since\" => println ( \"Match Since\" ) case unknow => println ( \"Others\" ) } println ( \"Put your post step here\" ) } æ³¨æ„: å¦‚æœè¦ä½¿ç”¨ä¸€æ®µä»£ç ä½œä¸ºforeachï¼ˆï¼‰çš„å‚æ•°ï¼Œåˆ™åº”ä½¿ç”¨{}è€Œä¸æ˜¯ï¼ˆï¼‰ã€‚","tags":"Programming","url":"articles/Scala-Tips.html","loc":"articles/Scala-Tips.html"},{"title":"Spark Tips","text":"Apache Spark - Best Practices and Tuning https://umbertogriffo.gitbooks.io/apache-spark-best-practices-and-tuning/content/ Big Data Analysis with Scala and Spark https://www.coursera.org/learn/scala-spark-big-data/home/welcome","tags":"Programming","url":"articles/Spark-Tips.html","loc":"articles/Spark-Tips.html"},{"title":"Scala Collection","text":"collection.mutable collection.immutable collection.mutable collection.immutable","tags":"Programming","url":"articles/Scala-Collection.html","loc":"articles/Scala-Collection.html"},{"title":"Automated Feature Engineering: Featuretools","text":"æ€è€ƒï¼š å½“ç‰¹å¾æ·±åº¦è¿‡æ·±å¤§äº2æ—¶çš„ç‰¹å¾å¯è§£é‡Šæ€§ï¼Ÿ ç”Ÿæˆçš„ç‰¹å¾è¿‡å¤šå¸¦æ¥æ–°çš„é—®é¢˜ï¼šç»´åº¦è¯…å’’ï¼Œé‚£ä¹ˆå¦‚ä½•é€‰å–ç‰¹å¾ï¼Ÿ feature reduction and selection feature selection http://www.jmaxkanter.com/static/papers/DSAA_DSM_2015.pdf http://featuretools.com https://github.com/Featuretools https://towardsdatascience.com/automated-feature-engineering-in-python-99baf11cc219 https://github.com/WillKoehrsen/automated-feature-engineering/blob/master/walk_through/Automated_Feature_Engineering.ipynb https://www.kaggle.com/liananapalkova/automated-feature-engineering-for-titanic-dataset","tags":"ML","url":"articles/Automated-Feature-Engineering:-Featuretools.html","loc":"articles/Automated-Feature-Engineering:-Featuretools.html"},{"title":"PCA","text":"åæ–¹å·®ä¸ç›¸å…³ç³»æ•° åæ–¹å·®çŸ©é˜µ åæ–¹å·®çŸ©é˜µçš„ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ åæ–¹å·®ä¸ç›¸å…³ç³»æ•° ç›¸å…³ç³»æ•°çš„ç›´è§‰ åæ–¹å·®çŸ©é˜µ å¦‚ä½•æ±‚å¾—åæ–¹å·®çŸ©é˜µï¼Ÿ åæ–¹å·®çŸ©é˜µçš„ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ PCA Tutorial Intuition","tags":"ML","url":"articles/PCA.html","loc":"articles/PCA.html"},{"title":"SQLite Full-text Search","text":"Sqlite Full-text Search Sqlite Full-text Search ç†è§£è™šè¡¨ ç†è§£å…¨æ–‡æœ¬æŸ¥æ‰¾ https://www.sqlite.org/fts5.html http://www.sqlitetutorial.net/sqlite-full-text-search def _is_to_exec ( self , sha1 ): \"\"\"Check whether the query has been run in the past. \"\"\" sql = f ''' SELECT DISTINCT sha1 FROM queries WHERE queries MATCH ' { sha1 } ' ''' if self . _conn . execute ( sql ) . fetchall (): answer = input ( 'The sql has been run. \\n Are you sure to run the sql again? (y/[n]): ' ) if answer . strip () . lower () != 'y' : return False return True Don't use match! match is for full-text search. Use ordinary SQL queries please. Just compare the column sha1 with the sha1sum of the query Pease refer to the search function to put the matched queries into the srps table so that you can print them to the user. Print out details of the matched queries here. You can simply use the function show_srps if you have put the matched queries into the srps table. As a related task, please make the command ./spark_sql.py run support option -i 2, â€”all. You can then add a -f/â€”force option to force rerun a query.","tags":"Programming","url":"articles/SQLite-Full-text-Search.html","loc":"articles/SQLite-Full-text-Search.html"},{"title":"L1 and L2 Regularization","text":"LèŒƒæ•° L1ä¸L2æ­£åˆ™åŒ– å¼•ç”¨ LèŒƒæ•° L0èŒƒæ•°ï¼šå‘é‡ä¸­éé›¶å…ƒç´ çš„ä¸ªæ•° åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œå¦‚æœä½¿ç”¨L0èŒƒæ•°å³å¸Œæœ›å¤§éƒ¨åˆ†æƒé‡wä¸º0ï¼Œå³wå‘é‡æ—¶ç¨€ç–çš„ï¼Œå¯ä»¥ç”¨äºç‰¹å¾é€‰æ‹©ï¼Œé€šè¿‡æœ€å°åŒ–L0ï¼Œæ¥å¯»æ‰¾æœ€ä¼˜çš„ç¨€ç–ç‰¹å¾ã€‚ç„¶è€ŒL0èŒƒæ•°çš„ä¼˜åŒ–é—®é¢˜æ—¶ä¸€ä¸ªNP Hardé—®é¢˜ï¼Œæ•…è€Œé€šå¸¸L1çš„æœ€ä¼˜åŒ–é—®é¢˜é€šå¸¸ä¼šæ”¾å®½åˆ°L1ï¼ŒL2ä¸‹çš„æœ€ä¼˜åŒ–ã€‚ L1èŒƒæ•°ï¼šå‘é‡ä¸­æ¯ä¸ªå…ƒç´ çš„ç»å¯¹å€¼ä¹‹å’Œ æ›¼å“ˆé¡¿è·ç¦» Lassoå›å½’ L2èŒƒæ•°ï¼šå‘é‡å…ƒç´ ç»å¯¹å€¼çš„å¹³æ–¹å’Œå†å¼€æ–¹ æ¬§å‡ é‡Œå¾—è·ç¦» Ridgeå›å½’ LPèŒƒæ•° LP -Normæ¨å¯¼ï¼š LP -Normæœ€ç»ˆæ˜¯ï¼š $max(x_1, x_2,..,x_n)$ ä¸­çš„ç»å¯¹å€¼æœ€å¤§çš„å…ƒç´ ï¼Œå³äºŒç»´æ˜¯ä¸€ä¸ªæ­£æ–¹å½¢ã€‚ L1ä¸L2æ­£åˆ™åŒ– ä¸ºä»€ä¹ˆéœ€è¦æ­£åˆ™åŒ–ï¼Ÿ æŠ‘åˆ¶æ¨¡å‹å¤æ‚åº¦ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚ å‡ ä½•è§£é‡Šï¼šè§£ç©ºé—´ è§£ç©ºé—´ï¼šæŸå¤±å‡½æ•°çš„ç­‰é«˜çº¿ä¸åœ†å½¢æ­£æ–¹å½¢ç›¸äº¤çš„åŒºåŸŸã€‚ L1ï¼šå‡½æ•°è¿ç»­ï¼Œä½†å­˜åœ¨ä¸å¯å¯¼ç‚¹ã€‚åœ¨ç‰¹å¾ä¸ºäºŒç»´æ—¶ï¼Œçº¦æŸçº¿æ˜¯ä¸€ä¸ªè±å½¢ï¼Œç­‰å€¼çº¿ å¤§æ¦‚ç‡ æœ€å…ˆä¸é¡¶ç‚¹ç›¸äº¤ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹æœ‰ä¸€ä¸ªç»´åº¦çš„ç‰¹å¾å°±ä¼šä¸º0ï¼Œè¿™å°±å¸¦æ¥äº†ç¨€ç–ã€‚å½“ç‰¹å¾çš„ç»´åº¦å˜é«˜ï¼Œåæ ‡è½´ä¸Šè§’ä¸è¾¹éƒ½ä¼šå˜å¤šï¼Œè¿™æ›´ä¼šåŠ å¤§ç­‰å€¼çº¿ä¸ä»–ä»¬å…ˆç›¸äº¤çš„æ¦‚ç‡ï¼Œä»è€Œå¯¼è‡´äº†ç¨€ç–æ€§ã€‚ L2ï¼šå‡½æ•°è¿ç»­ä¸”å¤„å¤„å¯å¯¼ã€‚å®ƒçš„çº¦æŸçº¿æ˜¯ä¸€ä¸ªåœ†å½¢ï¼Œç­‰å€¼çº¿å¯èƒ½ä¸å®ƒä»»æ„ä¸€ä¸ªä½ç½®çš„ç‚¹é¦–å…ˆç›¸åˆ‡ï¼Œè¿™ä¸ªåˆ‡ç‚¹åœ¨åæ ‡è½´ä¸Šçš„æ¦‚ç‡å¤§å¤§å‡å°ï¼Œä»è€Œä¸å¤ªå®¹æ˜“å¯¼è‡´ç¨€ç–ã€‚L2æ­£åˆ™åŒ–é€šè¿‡ æƒé‡è¡°å‡ ï¼Œåœ¨æƒé‡è¾ƒå¤§æ—¶è¡°å‡åœ°å¿«ï¼Œæƒé‡è¾ƒå°æ—¶è¡°å‡å¾—æ…¢ï¼Œä¿è¯äº†æ¨¡å‹çš„ç®€å•ï¼Œæé«˜äº†æ³›åŒ–èƒ½åŠ›ã€‚ ä¸‹é™é€Ÿåº¦ å½“wè¾ƒå¤§æ—¶ï¼ŒL2çš„æ–œç‡å¤§äºL1ï¼ŒL2æ­£åˆ™åŒ–æƒé‡è¡°å‡åœ°æ¯”L1æ­£åˆ™åŒ–å¿«ã€‚ å½“wè¾ƒå°æ—¶ï¼ŒL2çš„æ–œç‡å°äºL1ï¼ŒL1æ­£åˆ™åŒ–æƒé‡è¡°å‡åœ°æ¯”L2æ­£åˆ™åŒ–å¿«ã€‚ å› æ­¤L1æ­£åˆ™åŒ–æœ€ç»ˆä¼šå¯¼è‡´æ¨¡å‹ä¿ç•™äº†é‡è¦çš„å¤§æƒé‡ï¼Œä¸é‡è¦çš„å°æƒé‡éƒ½è¢«è¡°å‡ä¸º0ï¼Œäº§ç”Ÿäº†ç¨€ç–ã€‚è€ŒL2æ­£åˆ™åŒ–å¯ä»¥é€šè¿‡é™åˆ¶æƒé‡å¤§å°è®©æ¨¡å‹å˜å¾—ç®€å•ï¼Œä½†å´ä¸ä¼šå¯¼è‡´ç¨€ç–ã€‚ å¼•ç”¨ L1 and L2 regularization L0ã€L1ã€L2èŒƒæ•°åœ¨æœºå™¨å­¦ä¹ ä¸­çš„åº”ç”¨","tags":"ML","url":"articles/L1-and-L2-Regularization.html","loc":"articles/L1-and-L2-Regularization.html"},{"title":"Bias vs Variance","text":"æ–¹å·®ä¸åå·® ä¸ºä»€ä¹ˆRFçš„æ ‘æ·±ä¸€èˆ¬å¤§äºGBDTæ ‘çš„æ·±åº¦ï¼Ÿ æ–¹å·®ä¸åå·® æ³›åŒ–è¯¯å·®åˆ†ä¸ºï¼šåå·®å’Œæ–¹å·® åå·®ï¼šæŒ‡ç®—æ³•çš„æœŸæœ›é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´çš„åå·®ç¨‹åº¦ï¼Œååº”çš„æ˜¯æ¨¡å‹æœ¬èº«æ‹Ÿåˆèƒ½åŠ›ã€‚(å•æ¨¡å‹) æ–¹å·®ï¼šåº¦é‡äº†åŒç­‰å¤§å°æ•°æ®é›†çš„å˜åŠ¨å¯¼è‡´å­¦ä¹ æ€§èƒ½çš„å˜åŒ–ï¼Œåˆ»ç”»æ•°æ®æ‰°åŠ¨æ‰€å¯¼è‡´çš„å½±å“ã€‚(å¤šæ¨¡å‹) å½“æ¨¡å‹è¶Šå¤æ‚æ—¶ï¼Œè®­ç»ƒæ•°æ®çš„æ‹Ÿåˆç¨‹åº¦å°±è¶Šé«˜ï¼Œæ¨¡å‹çš„è®­ç»ƒåå·®å°±è¶Šå°ã€‚ä½†å¦‚æœè¿˜ä¸€ç»„æ•°æ®å¯èƒ½æ¨¡å‹çš„å˜åŒ–å°±å¾ˆå¤§ï¼Œå³æ¨¡å‹çš„æ–¹å·®å¾ˆå¤§ã€‚æ‰€ä»¥å¤æ‚åº¦é«˜çš„æ¨¡å‹å®¹æ˜“äº§ç”Ÿè¿‡æ‹Ÿåˆã€‚ å½“æ¨¡å‹ç®€å•æ—¶ï¼Œå³ä½¿è¿˜ä¸€ç»„è®­ç»ƒæ•°æ®ï¼Œå¾—å‡ºçš„å­¦ä¹ å™¨ä¹‹é—´å·®åˆ«ä¸æ˜¯å¾ˆå¤§ï¼Œå³æ¨¡å‹çš„æ–¹å·®è¾ƒå°ã€‚ä½†ç”±äºæ¨¡å‹ç®€å•ï¼Œæ‰€ä»¥å­˜åœ¨æ¯”è¾ƒå¤§çš„åå·®ã€‚ æ‰€ä»¥ï¼Œåœ¨è®­ç»ƒä¸€ä¸ªæ¨¡å‹æ—¶ï¼Œéœ€è¦å¹³è¡¡å¥½æ–¹å·®å’Œåå·®ã€‚ ä¸ºä»€ä¹ˆRFçš„æ ‘æ·±ä¸€èˆ¬å¤§äºGBDTæ ‘çš„æ·±åº¦ï¼Ÿ å¯¹äºBaggingç®—æ³•ï¼Œç”±äºæ—¶å¹¶è¡Œçš„è®­ç»ƒè‹¥å¹²ä¸ªå¼±å­¦ä¹ å™¨ï¼Œä»–ä»¬ä¹‹é—´ç›¸äº’ç‹¬ç«‹ï¼Œä¸»è¦ç›®çš„é™ä½æ–¹å·®ã€‚æ‰€ä»¥ä¸ºäº†å¹³è¡¡å¥½æ–¹å·®ä¸åå·®ï¼Œæ¯ä¸€ä¸ªå¼±å­¦ä¹ å™¨ç›®æ ‡ä¾¿æ˜¯å¦‚ä½•é™ä½åå·®ï¼Œå› è€Œä¼šé‡‡ç”¨å¤æ‚åº¦é«˜çš„æ¨¡å‹ä½œä¸ºå¼±å­¦ä¹ å™¨ï¼Œä¾‹å¦‚æ·±åº¦è¾ƒæ·±ç”šè‡³ä¸å‰ªæçš„æ ‘ï¼Œç¥ç»ç½‘ç»œç­‰ã€‚ å¯¹äºBoostingç®—æ³•ï¼Œè®­ç»ƒçš„å¼±å­¦ä¹ å™¨éƒ½æ˜¯åœ¨ä¸Šä¸€è½®åŸºç¡€ä¸Šæ›´åŠ çš„æ‹Ÿåˆæ•°æ®ï¼Œä¿è¯çš„æ˜¯æ¨¡å‹çš„åå·®ã€‚æ‰€ä»¥ä¸ºäº†å¹³è¡¡å¥½æ–¹å·®ä¸åå·®ï¼Œæ¯ä¸€ä¸ªå¼±å­¦ä¹ å™¨ç›®æ ‡ä¾¿æ˜¯å¦‚ä½•é™ä½å¼±å­¦ä¹ å™¨ä¹‹é—´çš„æ–¹å·®ï¼Œå› è€Œä¼šé‡‡ç”¨å¤æ‚åº¦ä½çš„æ¨¡å‹ä½œä¸ºå¼±å­¦ä¹ å™¨ï¼Œä¾‹å¦‚æ·±åº¦å¾ˆæµ…çš„æ ‘ã€‚","tags":"ML","url":"articles/Bias-vs-Variance.html","loc":"articles/Bias-vs-Variance.html"},{"title":"Topological Sorting","text":"Topological Sorting Topological Sorting # Definition for a Directed graph node class DirectedGraphNode : def __init__ ( self , x ): self . label = x self . neighbors = [] class Solution : \"\"\" @param graph: A list of Directed graph node @return: A list of integer \"\"\" def topSort ( self , graph ): # 1. ç»Ÿè®¡ç»“ç‚¹å…¥åº¦ indegree = self . get_indegree ( graph ) # 2. BFS order = [] start_nodes = [ n for n in graph if indegree [ n ] == 0 ] # å…¥åº¦ä¸º0çš„æ‰€æœ‰ç»“ç‚¹ queue = collections . deque ( start_nodes ) # é˜Ÿåˆ—ä¸­å­˜å‚¨çš„æ˜¯å…¥åº¦ä¸º0çš„ç‚¹ while queue : node = queue . popleft () order . append ( node ) for neighbor in node . neighbors : # éå†è¯¥èŠ‚ç‚¹çš„æ‰€æœ‰é‚»å±…èŠ‚ç‚¹ï¼Œç¬¬ä¸€å±‚éå†ã€‚ indegree [ neighbor ] -= 1 # å°†é˜Ÿåˆ—ä¸­è¾“å‡ºçš„ç‚¹çš„æ‰€ä»¥ä¸´ç•Œç‚¹å…¥åº¦å‡1 if indegree [ neighbor ] == 0 : # å°†å…¥åº¦ä¸º0çš„ç»“ç‚¹æ”¾å…¥é˜Ÿåˆ— queue . append ( neighbor ) return order def get_indegree ( self , graph ): \"\"\" è®¡ç®—æ¯ä¸€ä¸ªç»“ç‚¹çš„å…¥åº¦æ•° \"\"\" indegree = { x : 0 for x in graph } # åˆå§‹åŒ–æ¯ä¸€ä¸ªç»“ç‚¹çš„å…¥åº¦æ•°ä¸º0 for node in graph : for neighbor in node . neighbors : indegree [ neighbor ] += 1 return indegree","tags":"Algorithms","url":"articles/Topological-Sorting.html","loc":"articles/Topological-Sorting.html"},{"title":"Breadth First Search","text":"æ¦‚è¿° å®½æœè¦ç‚¹ äºŒå‰æ ‘ä¸Šçš„å®½æœ Binary Tree Level Order Traversal Binary Tree Zigzag Level Order Traversal Serialize and Deserialize Binary Tree å›¾ä¸Šçš„å®½æœ å›¾çš„éå† å±‚çº§éå† ç”±ç‚¹åŠé¢ æ‹“æ‰‘æ’åº çŸ©é˜µä¸Šçš„å®½æœ æ¦‚è¿° å…¸å‹BFSä¸‰å±‚å¾ªç¯: å…ˆæ˜ç¡®é˜Ÿåˆ—ä¸­æ”¾çš„æ˜¯ä»€ä¹ˆï¼Œå³æ»¡è¶³æ€æ ·çš„æ¡ä»¶æ‰èƒ½å…¥é˜Ÿã€‚ä¾‹å¦‚ï¼Œæ‹“æ‰‘æ’åºå…¥åº¦ä¸º0çš„èŠ‚ç‚¹å…¥é˜Ÿã€‚ é˜Ÿåˆ—ä¸ç©º, while queue åˆ†å±‚éå†ï¼Œforå½“å‰å±‚çš„sizeã€‚ å¾ªç¯ä½•æ—¶å¯çœï¼Ÿ ä¸éœ€è¦åˆ†å±‚ ä»å½“å‰ç‚¹å‡ºå‘ï¼Œå‘å‘¨å›´ç‚¹å»å¾ªç¯ ä¾‹å¦‚:æ‹“æ‰‘æ’åºå»forå¾ªç¯éå†å½“å‰ç‚¹çš„é‚»å±…èŠ‚ç‚¹ã€‚ å¾ªç¯ä½•æ—¶å¯çœï¼Ÿ äºŒå‰æ ‘å±‚åºéå†ï¼Œå‘¨å›´ç‚¹åªå¯èƒ½æœ‰å·¦å³å­©å­ï¼Œæ— éœ€forå¾ªç¯ã€‚node.left, node.rightåˆ†åˆ«çœ‹ä¸€çœ¼å³å¯ã€‚ å®½æœè¦ç‚¹ ä½¿ç”¨é˜Ÿåˆ—ä¸ºä¸»è¦æ•°æ®ç»“æ„Queue æ˜¯å¦éœ€è¦åˆ†å±‚å®ç°ï¼šåˆ†å±‚æ‰“å°å¤šä¸€å±‚forå¾ªç¯ï¼Œlen(queue)ç¼“å­˜é˜Ÿåˆ—æ¯ä¸€å±‚å¤§å°ã€‚ for _ range(len(queue)): é”™ï¼Œéœ€ç¼“å­˜ äºŒå‰æ ‘ä¸Šçš„å®½æœ Binary Tree Level Order Traversal Binary Tree Zigzag Level Order Traversal Serialize and Deserialize Binary Tree åºåˆ—åŒ–æ˜¯æŒ‡å°† å†…å­˜ ä¸­çš„æ•°æ®ç»“æ„è½¬ä¸º å­—ç¬¦ä¸² çš„è¿‡ç¨‹ã€‚ç³»åˆ—åŒ–ï¼šobject -> stringï¼›ååºåˆ—åŒ–: string -> objectã€‚ å›¾ä¸Šçš„å®½æœ å›¾ä¸Šçš„å®½æœä¸æ ‘çš„åŒºåˆ«ï¼š å›¾æœ‰ç¯ï¼ŒåŒä¸€èŠ‚ç‚¹å¯èƒ½é‡å¤è¿›å…¥é˜Ÿåˆ—ã€‚éœ€ç”¨é›†åˆå­˜å‚¨è®¿é—®è¿‡çš„ç»“ç‚¹ã€‚queue.appendä¸visited.addæˆå¯¹å­˜åœ¨ã€‚ æ•°æ®ç»“æ„ï¼š é˜Ÿåˆ— + é›†åˆ å›¾å¦‚ä½•å­˜å‚¨ï¼Ÿ ä¸´æ¥ç‚¹ class GraphNode : def __init__ ( self , x ): self . label = x self . neighbors = [] å›¾çš„éå† å±‚çº§éå† ç”±ç‚¹åŠé¢ æ‹“æ‰‘æ’åº Topological Sorting çŸ©é˜µä¸Šçš„å®½æœ","tags":"Algorithms","url":"articles/Breadth-First-Search.html","loc":"articles/Breadth-First-Search.html"},{"title":"GBDT","text":"é—®é¢˜å¼•å…¥ æ®‹å·®ä¸æ¢¯åº¦ä¸‹é™çš„å…³ç³» é—®é¢˜å¼•å…¥ ç»™å®šæ•°æ®é›†$(x_1, y_1), (x_2, y_2),â€¦,(x_n, y_n)$, æ‹Ÿåˆä¸€ä¸ªæ¨¡å‹$F(x)$ã€‚ $F(x_1) = 1.4$è€Œ$y_1=1.3$ $F(x_2) = 0.9$è€Œ$y_2=0.8$ â€¦ åœ¨ä¸æ”¹å˜$F(x)$æ¨¡å‹å‰æä¸‹ï¼Œå¦‚ä½•æå‡æ¨¡å‹$F(x)$ï¼Ÿ åœ¨åŸæœ‰æ¨¡å‹$F(x)$åŸºç¡€ä¸Šå¢åŠ æ¨¡å‹$h(x)$,å³$F(x) + h(x)$ã€‚ $$F(x_n) + h(x_n) = y_n$$ $$h(x_n) = y_n - F(x_n)$$ æ‰€ä»¥å¯¹æ•°æ®$(x_1, y_1-F(x_1)), (x_2, y_2-F(x_2)),â€¦,(x_n, y_n-F(x_n))$æ‹Ÿåˆä¸€ä¸ªå›å½’æ ‘$h$ã€‚ $y_i - F(x_i)$æ˜¯ æ®‹å·® ï¼Œå°±æ˜¯æ¨¡å‹$F(x)$æœªå¾ˆå¥½æ‹Ÿåˆçš„é‚£ä¸€éƒ¨åˆ†è¯¯å·®ã€‚$h(x)$ä½œç”¨å°±æ˜¯å¼¥è¡¥ç°æœ‰æ¨¡å‹çš„æ®‹å·®ã€‚å¦‚æœ$F+h$ä¾ç„¶æ²¡æœ‰å¾ˆå¥½çš„æ‹ŸåˆåŸæ•°æ®ï¼Œåˆ™ç»§ç»­æ·»åŠ å¦ä¸€ä¸ªå›å½’æ ‘æ¨¡å‹å»æ‹Ÿåˆæ–°çš„æ®‹å·®ã€‚ æ®‹å·®ä¸æ¢¯åº¦ä¸‹é™çš„å…³ç³» æ¢¯åº¦ä¸‹é™æ˜¯æŒ‡åœ¨å‡½æ•°å½“å‰ç‚¹å¯¹åº”æ¢¯åº¦çš„åæ–¹å‘è¿­ä»£ç§»åŠ¨ä»¥è¾¾åˆ°å‡½æ•°çš„å±€éƒ¨æœ€å°ã€‚ æŸå¤±å‡½æ•°ï¼š$L(y, F(x)) = \\frac{1}{2} (y - F(x))&#94;2$ æˆ‘ä»¬é€šè¿‡è¿­ä»£è°ƒæ•´$F(x_1), F(x_2),..,F(x_n)$ä»¥åˆ°è¾¾æŸå¤±å‡½æ•°$J = \\sum_i L(y_i, F(x_i))$çš„æœ€å°åŒ–ã€‚ æ³¨ï¼š$F(x_1), F(x_2),â€¦,F(x_n)$ä»…ä»…æ˜¯ä¸€äº›æ•°ï¼Œæ‰€ä»¥å¯ä»¥å°†$F(x_i)$å½“ä½œæ˜¯å˜é‡ã€‚é‚£ä¹ˆæ¢¯åº¦æ¨å¯¼ï¼š \\begin{align} \\frac{\\partial J}{\\partial F(x_i)} & = \\frac{\\partial \\sum_i L(y_i, F(x_i))}{\\partial F(x_i)} \\ & = \\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)} \\ & = \\frac{\\partial \\frac{1}{2}(y_i-F(x_i))&#94;2}{\\partial x} \\ & = F(x_i)-y_i \\end{align} æ‰€ä»¥å¯¹äºå…·æœ‰å¹³æ–¹æŸå¤±çš„å›å½’ï¼š \\begin{align} æ®‹å·®y_i-F(x_i) &<===>è´Ÿæ¢¯åº¦-\\frac{\\partial J}{\\partial F(x_i)} \\ å¯¹æ®‹å·®æ‹Ÿåˆh &<===> å¯¹è´Ÿæ¢¯åº¦æ‹Ÿåˆh \\ åŸºäºæ®‹å·®æ›´æ–°æ¨¡å‹F &<===> åŸºäºè´Ÿæ¢¯åº¦æ›´æ–°F \\ \\end{align} æ‰€ä»¥ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ¥æ›´æ–°æ¨¡å‹Fï¼Œæ¢¯åº¦ä¸‹é™çš„æ¦‚å¿µæ¯”æ®‹å·®æ›´é€šç”¨ä¸”æœ‰ç”¨ã€‚ æ®‹å·®ä¸è´Ÿæ¢¯åº¦çš„å…³ç³»ï¼šæ˜¯ç”±å¹³æ–¹æŸå¤±å‡½æ•°å»ºç«‹çš„ï¼Œå¹³æ–¹æŸå¤±å‡½æ•°çš„ä¸€é˜¶å¯¼æ•°å³æ¢¯åº¦æ­£æ˜¯è´Ÿæ®‹å·®ï¼Œè€Œå¹³æ–¹æŸå¤±å‡½æ•°åˆå¸¸ç”¨äºå›å½’é—®é¢˜","tags":"ML","url":"articles/GBDT.html","loc":"articles/GBDT.html"},{"title":"Dynamic Programming","text":"ä»€ä¹ˆæ˜¯åŠ¨æ€è§„åˆ’ ä¸é€’å½’ä¸‰è¦ç´ å¯¹æ¯” Triangle Minimum Path Sum Maximal Square Longest Increasing Subsequence ( LIS ) Longest Common Subsequence ( LCS ) Longest Palindromic Substring Maximum Subarray Maximum Product Subarray Coin Change ä»€ä¹ˆæ˜¯åŠ¨æ€è§„åˆ’ åŠ¨æ€è§„åˆ’æ˜¯ä¸€ç§æœ€ä¼˜åŒ–æ–¹æ³•ï¼Œä¸€èˆ¬çš„è¡¨ç°å½¢å¼æ˜¯æ±‚æœ€å€¼ã€‚å› è€Œæ±‚è§£åŠ¨æ€è§„åˆ’çš„æ ¸å¿ƒé—®é¢˜ä¾¿æ˜¯ç©·ä¸¾ï¼Œç©·ä¸¾æ‰€æœ‰ç»“æœè·å–æœ€ä¼˜å€¼ã€‚ç±»ä¼¼äºå›æº¯é—®é¢˜ï¼Œæš´åŠ›ç©·ä¸¾æ‰€æœ‰å¯èƒ½çš„ç»“æœï¼Œä½†ç©·ä¸¾çš„æ•ˆç‡æå…¶ä½ä¸‹ã€‚é’ˆå¯¹äºåŠ¨æ€è§„åˆ’è¿™ç±»é—®é¢˜ï¼Œå‡æœ‰ä¸€ä¸ªå…±åŒçš„ç‰¹ç‚¹å°±æ˜¯å­˜åœ¨ é‡å å­é—®é¢˜ ï¼Œåˆ©ç”¨è¿™ä¸ªç‰¹æ€§é‡‡ç”¨DP Tableå¤‡å¿˜è¡¨çš„æŠ€å·§ä¼˜åŒ–ç©·ä¸¾ï¼Œé¿å…é‡å¤è®¡ç®—ã€‚ï¼ˆå¼•å‡ºè‡ªé¡¶å‘ä¸‹æ³•é€’å½’æ³•ï¼‰ ç„¶è€Œï¼Œå¯¹äºåŠ¨æ€è§„åˆ’çš„é—®é¢˜åƒå˜ä¸‡åŒ–ï¼Œè™½ç„¶æ ¸å¿ƒæ€æƒ³æ˜¯ç©·ä¸¾æ±‚æœ€å€¼ï¼Œä½†æ˜¯åœ¨å®é™…å®è·µä¸­ç©·ä¸¾æ‰€æœ‰å¯èƒ½çš„ç»“æœå¹¶æœªæ˜“äº‹ã€‚æ‰€ä»¥å¼•å‡ºåŠ¨æ€è§„åˆ’é—®é¢˜çš„å¦å¤–ä¸¤ä¸ªç‰¹æ€§ï¼š æœ€ä¼˜å­ç»“æ„ å’Œ çŠ¶æ€è½¬ç§»æ–¹ç¨‹ æ¥å¸®åŠ©æ­£ç¡®ç©·ä¸¾ã€‚æœ€ä¼˜å­ç»“æ„å³é€šè¿‡å­é—®é¢˜çš„æœ€ä¼˜è§£æ¨å‡ºåŸé—®é¢˜çš„æœ€ä¼˜è§£ï¼ˆé‡å¤å­é—®é¢˜æ— åæ•ˆæ€§ï¼‰ï¼ŒçŠ¶æ€çš„å®šä¹‰å’ŒçŠ¶æ€çš„è½¬ç§»æ–¹ç¨‹å°±æ˜¾å¾—å°¤ä¸ºé‡è¦ã€‚ï¼ˆå¼•å‡ºè‡ªåº•å‘ä¸Šé€’æ¨æ³•ï¼‰ æ€ç»´æ¡†æ¶ï¼šæ˜ç¡®çŠ¶æ€ -> å®šä¹‰dpæ•°ç»„çš„å«ä¹‰ -> æ˜ç¡®é€‰æ‹© -> æ˜ç¡®base case æ€»ç»“ï¼š åŠ¨æ€è§„åˆ’é—®é¢˜å…·å¤‡çš„ä¸‰è¦ç´ ï¼š é‡å å­é—®é¢˜ï¼Œæœ€ä¼˜å­ç»“æ„ï¼ŒçŠ¶æ€è½¬ç§»æ–¹ç¨‹ åŠ¨æ€è§„åˆ’é—®é¢˜çš„ä¸¤ç§è§£æ³•ï¼š å¸¦å¤‡å¿˜çš„è‡ªé¡¶å‘ä¸‹çš„é€’å½’æ³•ï¼šä¸»è¦æ ¹æ®é‡å å­é—®é¢˜ç‰¹æ€§ï¼Œé€šè¿‡å¤‡å¿˜å½•é¿å…é‡å¤è®¡ç®—çš„æ–¹æ³•ï¼Œæœ¬è´¨æ˜¯é€’å½’ç©·ä¸¾æœç´¢ã€‚ è‡ªåº•å‘ä¸Šçš„è¿­ä»£é€’æ¨æ³•ï¼šè¿™æ‰æ˜¯çœŸæ­£æ„ä¹‰ä¸Šçš„åŠ¨æ€è§„åˆ’ï¼Œé€šè¿‡å­é—®é¢˜çŠ¶æ€è¿­ä»£é€’æ¨å‡ºåŸé—®é¢˜çš„çŠ¶æ€ã€‚ çŠ¶æ€çš„å®šä¹‰ çŠ¶æ€çš„å®šä¹‰æ˜¯åŠ¨æ€è§„åˆ’æœ€éš¾çš„åœ°æ–¹ï¼Œæ ¹æ®å®šä¹‰çŠ¶æ€å¯ä»¥å°†å…¶åˆ†ç±»ã€‚ çŠ¶æ€çš„è½¬ç§»æ–¹ç¨‹ çŠ¶æ€ä¹‹é—´çš„è”ç³»ï¼Œå¦‚ä½•é€šè¿‡å°çŠ¶æ€æ¨å‡ºå¤§çŠ¶æ€ã€‚ çŠ¶æ€çš„åˆå§‹åŒ– æœ€å°çŠ¶æ€æ˜¯ä»€ä¹ˆï¼Œå³é€’å½’ä¸­çš„base caseèµ·ç‚¹ã€‚ ä»¥åŠè½¬ç§»æ–¹ç¨‹æ¨ç®—ä¸å‡ºçš„éœ€è¦æ‰‹å·¥è®¡ç®—çš„çŠ¶æ€ã€‚ è¿”å›ç»“æœ æœ€ç»ˆè¦æ±‚è§£çš„é—®é¢˜ï¼Œå³æœ€å¤§çš„çŠ¶æ€ã€‚ç»ˆç‚¹ ä¸é€’å½’ä¸‰è¦ç´ å¯¹æ¯” æ‰€æœ‰çš„åŠ¨æ€è§„åˆ’éƒ½æ˜¯ç”±æš´åŠ›é€’å½’ä¼˜åŒ–è€Œæ¥ åŠ¨æ€è§„åˆ’æ˜¯ä¸€ç§åˆ†é˜¶æ®µæ±‚è§£å†³ç­–é—®é¢˜çš„æ•°å­¦æ€æƒ³ã€‚ ä¸‰ä¸ªé‡è¦çš„æ¦‚å¿µï¼š çŠ¶æ€ ï¼ˆæœ€ä¼˜å­ç»“æ„ï¼‰ã€ é€’æ¨æ–¹ç¨‹ ã€ è¾¹ç•Œ ã€‚ åŠ¨æ€è§„åˆ’åˆ©ç”¨ è‡ªåº•å‘ä¸Šçš„é€’æ¨ æ–¹å¼ï¼Œå®ç°æ—¶é—´å’Œç©ºé—´ä¸Šçš„æœ€ä¼˜åŒ–ã€‚ é€’å½’å±•å¼€è¿‡ç¨‹ä¸­å­˜åœ¨é‡å¤çŠ¶æ€ï¼Œå³é‡å å­é—®é¢˜ é‡å¤çŠ¶æ€æ— åæ•ˆæ€§ï¼šä¸åˆ°è¾¾è¿™ä¸ªçŠ¶æ€çš„è·¯å¾„æ— å…³ï¼Œå³åªè¦è¿™ä¸ªçŠ¶æ€å‚æ•°ç¡®å®šï¼Œåˆ™è¿”å›å€¼ç¡®å®šã€‚ æš´åŠ›é€’å½’åˆ°åŠ¨æ€è§„åˆ’çš„è§£æ³•ï¼š æ‰¾å‡ºéœ€è¦æ±‚è§£çš„ çŠ¶æ€ä½ç½® å›åˆ°Base caseä¸­è®¾ç½®ä¸è¢«ä¾èµ–çš„ è¾¹ç•ŒçŠ¶æ€ åˆ†æ æ™®éçŠ¶æ€ å¦‚ä½•ä¾èµ– Triangle def minimumTotal ( self , triangle ): if not triangle : return None row = len ( triangle ) dp = [[ 0 for _ in range ( len ( row ))] for row in triangle ] dp [ 0 ][ 0 ] = triangle [ 0 ][ 0 ] for i in range ( 1 , row ): for j in range ( len ( triangle [ i ])): if j == 0 : dp [ i ][ j ] = triangle [ i ][ j ] + dp [ i - 1 ][ j ] elif j == len ( triangle [ i ]) - 1 : dp [ i ][ j ] = triangle [ i ][ j ] + dp [ i - 1 ][ j - 1 ] else : dp [ i ][ j ] = triangle [ i ][ j ] + min ( dp [ i - 1 ][ j ], dp [ i - 1 ][ j - 1 ]) return min ( dp [ - 1 ]) Minimum Path Sum Python def minPathSum ( self , grid ): if not grid : return row = len ( grid ) col = len ( grid [ 0 ]) #dp = [[0 for i in range(col)] for j in range(row)] dp = [[ 0 for _ in range ( len ( row ))] for row in grid ] dp [ 0 ][ 0 ] = grid [ 0 ][ 0 ] # the first row for i in range ( 1 , col ): dp [ 0 ][ i ] = grid [ 0 ][ i ] + dp [ 0 ][ i - 1 ] # the first column for i in range ( 1 , row ): dp [ i ][ 0 ] = grid [ i ][ 0 ] + dp [ i - 1 ][ 0 ] # other location for i in range ( 1 , row ): for j in range ( 1 , col ): dp [ i ][ j ] = grid [ i ][ j ] + min ( dp [ i ][ j - 1 ], dp [ i - 1 ][ j ]) print ( dp ) return dp [ - 1 ][ - 1 ] C ++ class Solution { public : int minPathSum ( vector < vector < int >>& grid ){ int row = grid . size (); int col = grid [ 0 ]. size (); vector < vector < int >> dp ( row , vector < int > ( col , 0 )); dp [ 0 ][ 0 ] = grid [ 0 ][ 0 ]; // first row for ( int i = 1 ; i < col ; ++ i ) dp [ 0 ][ i ] = grid [ 0 ][ i ] + dp [ 0 ][ i -1 ]; // first col for ( int i = 1 ; i < row ; ++ i ) dp [ i ][ 0 ] = grid [ i ][ 0 ] + dp [ i -1 ][ 0 ]; for ( int i = 1 ; i < row ; ++ i ){ for ( int j = 1 ; j < col ; ++ j ){ dp [ i ][ j ] = grid [ i ][ j ] + min ( dp [ i -1 ][ j ], dp [ i ][ j -1 ]); } } return dp [ row -1 ][ col -1 ]; } }; Maximal Square çŠ¶æ€å®šä¹‰ï¼šdp[i][j]è¡¨ç¤ºä»¥åæ ‡ä¸º i, j çš„è¿™ä¸ªç‚¹ï¼Œä½œä¸ºæ­£æ–¹å½¢çš„å³ä¸‹è§’ï¼Œå¯ä»¥æ‰©å±•çš„æœ€å¤§è¾¹é•¿ è½¬ç§»æ–¹ç¨‹ï¼šdp[i][j] = min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1]) + 1 å–æœ€å°çš„æ˜¯å› ä¸ºåŠ ä¸Š(i, j)è¿™ä¸€ç‚¹ä¸€å®šæ—¶æ­£æ–¹å½¢ã€‚ç”»å›¾ç†è§£ class Solution : def maximalSquare ( self , matrix : List [ List [ str ]]) -> int : if not matrix : return 0 row , col = len ( matrix ), len ( matrix [ 0 ]) dp = [[ int ( matrix [ i ][ j ]) for j in range ( col )] for i in range ( row )] res = max ( max ( row ) for row in dp ) # åˆå€¼ï¼Œç‰¹åˆ—[['1']] for i in range ( 1 , row ): for j in range ( 1 , col ): if matrix [ i ][ j ] == '1' : # æ³¨æ„å‹¿ä¸¢ dp [ i ][ j ] = min ( dp [ i - 1 ][ j ], dp [ i ][ j - 1 ], dp [ i - 1 ][ j - 1 ]) + 1 res = max ( res , dp [ i ][ j ]) else : dp [ i ][ j ] = 0 return res ** 2 Longest Increasing Subsequence ( LIS ) çŠ¶æ€çš„å®šä¹‰ï¼šdp[i]æ˜¯ä»¥ç¬¬iä¸ªå…ƒç´ ç»“å°¾çš„æœ€å¤§ä¸Šå‡åºåˆ—çš„é•¿åº¦ æœ¬é¢˜ç‰¹æ®Šåœ¨äºï¼šå½“å‰çŠ¶æ€dp[i]å¹¶éç”±å‰ä¸€ä¸ªçŠ¶æ€dp[i-1]ç›´æ¥æ¨æ¥ï¼Œè€Œæ˜¯ç”±å‰dp[0] ~ dp[i-1]çŠ¶æ€ä¸­ä¸­æœ€å¤§çš„æ¨æ¥ã€‚å¦‚ä¸‹ï¼š dp[j]æ˜¯å‰ä¸€ä¸ªçŠ¶æ€ï¼Œ jå±äº0 ~ i-1ä¸­æœ€å¤§çš„çŠ¶æ€ Python class Solution : def lengthOfLIS ( self , nums : List [ int ]) -> int : if not nums : return 0 dp = [ 1 ] * len ( nums ) for i in range ( len ( nums )): # åˆ†åˆ«è®¡ç®—æ¯ä¸€ä¸ªçŠ¶æ€ for j in range ( i ): # éå†å¯»ä¸Šå‰ä¸€ä¸ªæ»¡è¶³æ¡ä»¶çš„çŠ¶æ€ if nums [ j ] < nums [ i ]: dp [ i ] = max ( dp [ i ], dp [ j ] + 1 ) # dp[i]è¿­ä»£æ”¾ç½®æœ€å¤§çŠ¶æ€ return max ( dp ) C ++ class Solution { public : int lengthOfLIS ( vector < int >& nums ){ int n = nums . size (); if ( n < 1 ) return n ; vector < int > dp ( n , 1 ); for ( int i = 1 ; i < n ; ++ i ){ for ( int j = 0 ; j < i ; ++ j ){ if ( nums [ j ] < nums [ i ]){ dp [ i ] = max ( dp [ i ], dp [ j ] + 1 ); } } } int max_length = 1 ; for ( auto & ele : dp ) max_length = max ( max_length , ele ); return max_length ; } }; Longest Common Subsequence ( LCS ) çŠ¶æ€çš„å®šä¹‰ï¼š dp[i][j]æ˜¯å­ä¸²string1[0 ~ i]ä¸å­—ä¸²string[0 ~ j]çš„æœ€é•¿å…¬å…±å­—ä¸²çš„é•¿åº¦ã€‚ é€’æ¨æ–¹ç¨‹ï¼š è‹¥æ±‚åŸé—®é¢˜dp[i][j]ï¼Œä»å­é—®é¢˜dp[i-1][j-1]æˆ–è€…max(dp[i-1][j], dp[i][j-1])é€’æ¨è€Œæ¥ã€‚ å½“string1[i] == string2[j]æ—¶ï¼ŒåŸé—®é¢˜dp[i][j] = dp[i-1][j-1] + 1ï¼Œå³string1[0 ~ i-1]ä¸å­—ä¸²string[0 ~ j-1]çš„æœ€é•¿å…¬å…±å­—ä¸²çš„é•¿åº¦åŠ 1 å½“string1[i] != string2[j]æ—¶ï¼Œåˆ™å¿…é¡»æ±‚è§£dp[i-1][j]å’Œdp[i][j-1]ä¸¤ä¸ªå­é—®é¢˜å¹¶å–æœ€å¤§çš„ç»“æœï¼ŒåŸé—®é¢˜dp[i][j] = max(dp[i-1][j], dp[i][j-1])ï¼Œå³å­ä¸²string1[0 ~ i-1]ä¸string[0 ~ j]çš„LCSä¸å­ä¸²string1[0 ~ i]ä¸string[0 ~ j-1]çš„LCSä¸­æœ€å¤§çš„LCSã€‚ è¾¹ç•Œåˆå§‹åŒ–æŠ€å·§ï¼šå­—ç¬¦ä¸²å‰å¢åŠ ä¸€ä¸ªç©ºå­—ç¬¦#ã€‚ C ++ class Solution { public : int longestCommonSubsequence ( string text1 , string text2 ){ int len1 = text1 . size (); int len2 = text2 . size (); if ( len1 == 0 || len2 == 0 ) return 0 ; vector < vector < int >> dp ( len1 + 1 , vector < int > ( len2 + 1 , 0 )); /* å¢åŠ ä¸€ä¸ªç‰¹æ®Šå­—ç¬¦#ï¼Œåˆ©äºåˆå§‹åŒ–base case # a b a c k # 0 0 0 0 0 0 a 0 b 0 s 0 */ for ( int i = 1 ; i <= len1 ; ++ i ){ for ( int j = 1 ; j <= len2 ; ++ j ){ if ( text1 [ i -1 ] == text2 [ j -1 ]) dp [ i ][ j ] = dp [ i -1 ][ j -1 ] + 1 ; else dp [ i ][ j ] = max ( dp [ i -1 ][ j ], dp [ i ][ j -1 ]); } } return dp [ len1 ][ len2 ]; } }; Longest Palindromic Substring çŠ¶æ€å®šä¹‰ï¼šdp[i][j]æ˜¯å­—ç¬¦ä¸²s[i:j]æ˜¯å¦ä¸ºå›æ–‡å­ä¸²ã€‚ base caseï¼š1. å•ä¸ªå­—æ¯dp[i][i] 2. ç›¸é‚»å­—æ¯dp[i][i+1] dpæ•°ç»„éå†æ–¹å¼ï¼šéå†æ‰€æœ‰å¯èƒ½å­—ä¸²é•¿åº¦len ï¼ˆå­ä¸²é•¿åº¦len + å¼€å§‹ä½ç½®startï¼‰æ–¹å¼ class Solution { public : string longestPalindrome ( string s ){ int n = s . size (); if ( n == 0 ) return s ; int start_substr = 0 ; int max_len = 1 ; vector < vector < bool >> dp ( n , vector < bool > ( n , false )); // base case one letter for ( int i = 0 ; i < n ; ++ i ) dp [ i ][ i ] = true ; // nase case two letter for ( int i = 0 ; i < n - 1 ; ++ i ){ if ( s [ i ] == s [ i + 1 ]){ dp [ i ][ i + 1 ] = true ; start_substr = i ; max_len = 2 ; } } // length of substring for ( int len = 3 ; len <= n ; ++ len ){ // start position of substring for ( int start = 0 ; start < n - len + 1 ; ++ start ){ // end position of substring int end = start + len - 1 ; if ( dp [ start + 1 ][ end -1 ] && s [ start ] == s [ end ]){ start_substr = start ; max_len = len ; dp [ start ][ end ] = true ; } } } return s . substr ( start_substr , max_len ); } }; Maximum Subarray çŠ¶æ€å®šä¹‰ï¼š dp[i]è¡¨ç¤ºä»¥nums[i]å…ƒç´ ç»“å°¾ï¼ˆåŒ…å«nums[i]ï¼‰æœ€å¤§å­æ•°ç»„çš„å’Œ è½¬ç§»æ–¹ç¨‹ï¼š $$dp[i] = \\begin{cases} nums[i], &\\ dp[i-1] \\leq 0 \\ dp[i-1] + nums[i], &\\ dp[i-1] > 0 \\end{cases}$$ æ³¨ï¼šå› ä¸ºæ˜¯è¿ç»­å­æ•°ç»„ï¼Œæ‰€ä»¥dp[i]å½“å‰çŠ¶æ€ï¼Œåªèƒ½ç”±dp[i-1]çŠ¶æ€æ¨æ¥ã€‚ è½¬ç§»æ–¹ç¨‹ä»£ç å®ç°ï¼š dp[i] = max(dp[i-1] + nums[i], nums[i]) åˆ†æï¼š å½“ä»¥ç¬¬i-1å…ƒç´ ç»“å°¾çš„å­æ•°ç»„ä¸­æ‰€æœ‰æ•°å­—çš„å’Œå°äº0æ—¶ï¼Œå¦‚æœæŠŠè¿™ä¸ªè´Ÿæ•°ä¸ç¬¬iä¸ªå…ƒç´ ç´¯åŠ ï¼Œå¾—åˆ°çš„ç»“æœæ¯”nums[i]æœ¬èº«è¿˜å°ï¼Œæ‰€ä»¥dp[i]å°±æ˜¯nums[i]æœ¬èº«ã€‚ è‹¥dp[i-1] < 0ï¼šdp[i] = nums[i] nums[i]åŠ ä¸Šè´Ÿdp[i-1]ä¸€å®šæ¯”è‡ªèº«å°ï¼Œå–nums[i] è‹¥dp[i-1] > 0ï¼š dp[i] = dp[i-1] + nums[i] nums[i]åŠ ä¸Šæ­£dp[i-1]ä¸€å®šæ¯”è‡ªèº«å¤§ï¼Œå–$dp[i-1] + nums[i]$ ç”±äºdp[i]ä»…ä¸dpçš„å‰ä¸€ä¸ªçŠ¶æ€æœ‰å…³ï¼Œå³åœ¨è®¡ç®—dp[i]æ—¶ï¼Œ$dp[i-2],dp[i-3]â€¦,dp[0]$å¯¹äºdp[i]æ²¡æœ‰å½±å“ï¼Œå› æ­¤å¯ä»¥ç©ºé—´ä¼˜åŒ–çœå»dpæ•°ç»„ã€‚ def maxSubArray ( self , nums ): if not nums : return dp = [ 0 ] * len ( nums ) dp [ 0 ] = nums [ 0 ] for i in range ( 1 , len ( nums )): dp [ i ] = max ( dp [ i - 1 ] + nums [ i ], nums [ i ]) return max ( dp ) def maxSubArray ( self , nums ): # ç©ºé—´ä¼˜åŒ– if not nums : return dp , dp [ 0 ], res = [ 0 , 0 ], nums [ 0 ], nums [ 0 ] for i in range ( 1 , len ( nums )): x , y = i % 2 , ( i - 1 ) % 2 # æ»šåŠ¨æ•°ç»„ï¼Œç©ºé—´ä¼˜åŒ– dp [ x ] = max ( dp [ y ] + nums [ i ], nums [ i ]) res = max ( dp [ x ], res ) return res C ++ class Solution { public : int maxSubArray ( vector < int >& nums ) { int n = nums . size (); if ( n == 0 ) return 0 ; vector < int > dp ( n , 0 ); dp [ 0 ] = nums [ 0 ]; int s_max = nums [ 0 ]; for ( int i = 1 ; i < n ; ++ i ){ dp [ i ] = max ( nums [ i ], dp [ i -1 ] + nums [ i ]); s_max = max ( s_max , dp [ i ]); } return s_max ; } }; vector < int > nums { 2 , 4 , -1 , 7 , 3 , -3 , 1 }; // dp = [2, 6, 5, 12 ,15, 1,2 ,13] Maximum Product Subarray dpçŠ¶æ€ï¼š dp [ i ][ 2 ] dp [ i ][ 0 ] => max dp [ i ][ 1 ] => min dpåˆå§‹çŠ¶æ€ï¼š dp[0][0], dp[0][1] = nums[0], nums[0] dpçŠ¶æ€è½¬ç§»æ–¹ç¨‹ï¼š å–å†³äºå½“å‰å€¼ nums[i] çš„æ­£è´Ÿæƒ…å†µã€‚ è‹¥ä¸ºæ­£ nums[i] >= 0 ï¼š åˆ™å½“å‰çŠ¶æ€çš„æœ€å¤§å€¼ä¸ºä¸Šä¸ªçŠ¶æ€çš„æœ€å¤§å€¼ä¹˜ä»¥å½“å‰å€¼ dp[i][0] = max(dp[i - 1][0] * nums[i], nums[i]) åˆ™å½“å‰çŠ¶æ€çš„æœ€å°å€¼ä¸ºä¸Šä¸ªçŠ¶æ€çš„æœ€å°å€¼ä¹˜ä»¥å½“å‰å€¼ dp[i][1] = min(dp[i - 1][1] * nums[i], nums[i]) è‹¥ä¸ºè´Ÿ nums[i] < 0 ï¼š åˆ™å½“å‰çŠ¶æ€çš„æœ€å¤§å€¼ä¸ºä¸Šä¸ªçŠ¶æ€çš„æœ€å°å€¼ä¹˜ä»¥å½“å‰å€¼ dp[i][0] = max(dp[i - 1][1] * nums[i], nums[i]) åˆ™å½“å‰çŠ¶æ€çš„æœ€å°å€¼ä¸ºä¸Šä¸ªçŠ¶æ€çš„æœ€å¤§å€¼ä¹˜ä»¥å½“å‰å€¼ dp[i][1] = min(dp[i - 1][0] * nums[i], nums[i]) dp [ i ][ 0 ] = max ( dp [ i - 1 ][ 0 ] * nums [ i ] , dp [ i - 1 ][ 1 ] * nums [ i ] , nums [ i ] ) dp [ i ][ 1 ] = min ( dp [ i - 1 ][ 0 ] * nums [ i ] , dp [ i - 1 ][ 1 ] * nums [ i ] , nums [ i ] ) def maxProduct ( self , nums : List [ int ]) -> int : if not nums : return dp = [[ 0 for _ in range ( 2 )] for _ in range ( 2 )] dp [ 0 ][ 0 ], dp [ 0 ][ 1 ], res = nums [ 0 ], nums [ 0 ], nums [ 0 ] for i in range ( 1 , len ( nums )): x , y = i % 2 , ( i - 1 ) % 2 # æ»šåŠ¨æ•°ç»„ dp [ x ][ 0 ] = max ( dp [ y ][ 0 ] * nums [ i ], dp [ y ][ 1 ] * nums [ i ], nums [ i ]) dp [ x ][ 1 ] = min ( dp [ y ][ 0 ] * nums [ i ], dp [ y ][ 1 ] * nums [ i ], nums [ i ]) res = max ( res , dp [ x ][ 0 ]) return res Coin Change åˆ†æ: æœ‰å¤šå°‘ç§é¢å€¼çš„ç¡¬å¸ï¼Œå‰ä¸€ä¸ªçŠ¶æ€dp[i - coin]å°±æœ‰å¤šå°‘ç§ã€‚ iè¡¨ç¤ºå½“å‰çš„è¦è®¡ç®—çš„æ€»é¢ï¼Œi - coinè¡¨ç¤ºå»æ‰æ·»åŠ ä¸Šæ¥çš„ç¡¬å¸é¢å€¼å‰©ä¸‹æ€»é¢ã€‚ æ‰€ä»¥éœ€è¦éå†å‡å»å„ç§é¢å€¼è€Œå¾—åˆ°çš„å‰ä¸€ä¸ªçŠ¶æ€ï¼Œæ‰¾åˆ°æœ€å°å€¼ï¼Œå³æœ€å°ç¡¬å¸æ•°ã€‚ dp[i - coin]æ˜¯å‰ä¸€ä¸ªçŠ¶æ€,æœ‰å¤šå°‘é¢å€¼çš„ç¡¬å¸å‰ä¸€ä¸ªçŠ¶æ€å°±æœ‰å¤šå°‘ç§ï¼Œ éå†æ‰€æœ‰çš„å‰ä¸€ä¸ªçŠ¶æ€å–å€¼æœ€å°çš„é‚£ä¸ªçŠ¶æ€ + 1ä¸ªç¡¬å¸æ•°ï¼ˆåŠ ä¸Šå½“å‰é¢å€¼ï¼‰ã€‚ çŠ¶æ€çš„å®šä¹‰ï¼š dp[i]åˆ°é‡‘é¢iï¼ˆç±»ä¼¼äºå°é˜¶ï¼‰æ‰€éœ€è¦çš„æœ€å°‘ç¡¬å¸æ•°ã€‚ è½¬ç§»æ–¹ç¨‹ï¼š $dp[i] = min(dp[i-coin_1],\\ dp[i-coin_2],â€¦,\\ dp[i-coin_n])$ åˆå§‹çŠ¶æ€ï¼šdp[0] = 0ï¼šé¢å€¼ä¸º0éœ€è¦0ä¸ªç¡¬å¸æ•°; è‹¥ç¡¬å¸é¢å€¼æœ‰2ï¼Œ 5ï¼Œ 7ä¸‰ç§ï¼Œåˆ™dp[1]æ˜¯è½¬ç§»æ–¹ç¨‹æ— æ³•è®¡ç®—å‡ºçš„ï¼Œæ‰€ä»¥ä¹Ÿéœ€è¦æ‰‹å·¥åˆå§‹åŒ–ï¼Œå› ä¸ºè¿™é‡Œæ±‚æœ€å°æ‰€ä»¥å°†å…¶åˆå§‹åŒ–ä¸ºæ— ç©·å¤§float(â€˜inf')ã€‚ æ—¶é—´å¤æ‚åº¦$O(M*N)$ï¼š Mæ˜¯å¾…å…‘æ¢çš„æ€»é‡‘é¢ï¼Œä»1é€’æ¨åˆ°Mï¼›Næ˜¯å¯ä»¥å…‘æ¢çš„ç¡¬å¸ç§ç±»æ•°ï¼Œä¹Ÿæ˜¯loopæ‰€æœ‰å¸ç§ã€‚ def coinChange ( self , coins : List [ int ], amount : int ) -> int : dp = [ 0 ] + [ float ( 'inf' )] * amount for i in range ( 1 , amount + 1 ): for coin in coins : # éå†å‰ä¸€ä¸ªçŠ¶æ€ if coin <= i : # ç¡¬å¸çš„é¢å€¼éœ€è¦å°äºiï¼Œå³å½“å‰æ€»amount dp [ i ] = min ( dp [ i ], dp [ i - coin ] + 1 ) # dp[i]è¿­ä»£æ”¾ç½®æœ€å°çŠ¶æ€ï¼Œ 1è¡¨ç¤ºåŠ ä¸Šä¸€ä¸ªé¢å€¼ç¡¬å¸åçš„æœ€å°‘ç¡¬å¸æ•° return dp [ - 1 ] if dp [ - 1 ] != float ( 'inf' ) else - 1","tags":"Algorithms","url":"articles/Dynamic-Programming.html","loc":"articles/Dynamic-Programming.html"},{"title":"Closure","text":"ä»€ä¹ˆæ˜¯é—­åŒ…ï¼Ÿ å¦‚æœè‡ªç”±å˜é‡å€¼å‘ç”Ÿå˜åŒ–ä¼šæ€æ ·ï¼Ÿ å¦‚æœé—­åŒ…ä¿®æ”¹äº†è‡ªç”±å˜é‡çš„å€¼ä¼šæ€æ ·ï¼Ÿ ä¸ºä»€ä¹ˆéœ€è¦é—­åŒ…ï¼Œæœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ ä»€ä¹ˆæ˜¯é—­åŒ…ï¼Ÿ å¼•ç”¨è‡³å°‘ä¸€ä¸ªè‡ªç”±å˜é‡çš„å‡½æ•°ç§°ä¸ºé—­åŒ…ã€‚ é—­åŒ…æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œå¯çº¯å‡½æ•°æˆ–éçº¯å‡½æ•°ï¼Œå¯æœ‰åå­—æˆ–åŒ¿åï¼Œä½†é‡è¦çš„æ˜¯å®ƒæ˜¯ä¸€ä¸ªå‡½æ•°ã€‚ ä¸ºä½•ç§°å…¶ä¸ºé—­åŒ…ï¼Œå®ƒä¸å‡½æ•°æœ€é‡è¦çš„åŒºåˆ«æ˜¯ï¼š å¼•ç”¨è‡ªç”±å˜é‡ ã€‚ // pç›¸å¯¹äºgetHikeï¼Œæ˜¯å…¶è‡ªç”±å˜é‡ã€‚getHikeå‡½æ•°æ²¡æœ‰å±€éƒ¨å˜é‡å’Œåˆ—è¡¨å‚æ•°pã€‚ var p = 10 def getHike ( salary : Double ) = salary * p / 100 getHike ( 5000 ) å¦‚æœè‡ªç”±å˜é‡å€¼å‘ç”Ÿå˜åŒ–ä¼šæ€æ ·ï¼Ÿ æ‰§è¡Œé—­åŒ…æ—¶ï¼Œå®ƒé‡‡ç”¨æœ€æ–°çš„è‡ªç”±å˜é‡çš„å€¼ã€‚ var p = 10 def getHike ( salary : Double ) = salary * p / 100 getHike ( 5000 ) //res1: Double = 500.0 p = 20 getHike ( 5000 ) //res2: Double = 1000.0 é—­åŒ…æ˜¯å¦ä¸ºçº¯å‡½æ•°ï¼šå–å†³äºè‡ªç”±å˜é‡çš„ç±»å‹varå’Œval å¦‚æœé—­åŒ…ä¿®æ”¹äº†è‡ªç”±å˜é‡çš„å€¼ä¼šæ€æ ·ï¼Ÿ å¦‚æœé—­åŒ…ä¿®æ”¹äº†è‡ªç”±å˜é‡ï¼Œåˆ™æ›´æ”¹åœ¨é—­åŒ…å¤–éƒ¨å¯è§ã€‚ var p = 10 def getHike ( salary : Double ) = { p = p * 2 salary * p / 100 } println ( p ) //10 getHike ( 5000 ) //res8: Double = 1000.0 println ( p ) //20 ä¸ºä»€ä¹ˆéœ€è¦é—­åŒ…ï¼Œæœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ å‡½æ•°å¼ç¼–ç¨‹ï¼Œå‡½æ•°å¯ä»¥æœ€ä¸ºå‚æ•°ä¼ é€’å’Œè¿”å›ï¼Œä¸é¢å‘å¯¹è±¡ç±»ä¼¼ã€‚ å¯¹äºæŸäº›ä¾‹å­ï¼Œå¯¹è±¡æ›´çµæ´»ï¼Œå› ä¸ºå¯¹è±¡æºå¸¦æ–¹æ³•å’Œæ•°æ®å…ƒç´ ï¼ˆçŠ¶æ€ï¼‰ã€‚ç„¶è€Œï¼Œå‡½æ•°æ˜¯å”¯ä¸€çš„ï¼Œå› ä¸ºå®ƒæ²¡æœ‰ä»»ä½•æ•°æ®å…ƒç´ ï¼ˆçŠ¶æ€ï¼‰ã€‚ æ‰€ä»¥ï¼Œå¦‚æœæˆ‘ä»¬éœ€è¦ä¼ é€’ä¸€å †çŠ¶æ€å’Œä¸€ä¸ªå‡½æ•°ï¼Œé‚£ä¹ˆä½¿ç”¨ï¼š é—­åŒ… å’Œ è‡ªç”±å˜é‡ ã€‚ val l = ( 1001 to 1005 ). toList l . map ( getHike ) def getHike = { //Load employee and their current salary val e : Map [ Int , Double ] = Map ( 1001 -> 35000.00 , 1002 -> 43000.00 , 1003 -> 28000.00 , 1004 -> 54000.00 , 1005 -> 17000.00 ) // Some logic to derive percentage for each employee val p : Map [ Int , Double ] = Map ( 1001 -> 10.00 , 1002 -> 12.00 , 1003 -> 7.50 , 1004 -> 6.80 , 1005 -> 20.00 ) ( empID : Int ) => ( empID , e ( empID ) * p ( empID ) / 100.00 ) // è¿”å›ä¸€ä¸ªåŒ¿åå‡½æ•°ï¼Œå³é—­åŒ… } val f = getHike f : Int => ( Int , Double ) = < function1 > //Get Hike for an employee f ( 1001 ) //res10: (Int, Double) = (1001,3500.0) //Get Hike for a non existant employee f ( 1006 ) //java.util.NoSuchElementException: key not found: 1006 ä»æœ€åä¸€è¡Œè¿”å›çš„åŒ¿åå‡½æ•°æ˜¯ä¸€ä¸ªé—­åŒ…ã€‚å®ƒä½¿ç”¨ä¸¤ä¸ªè‡ªç”±å˜é‡eå’Œpã€‚ å½“æˆ‘ä»¬ä»getHikeè¿”å›å®ƒæ—¶ï¼Œå®ƒå¸¦æœ‰eå’Œpçš„çŠ¶æ€ã€‚ æ‰€ä»¥ï¼ŒfåŒ…å«å®ƒçš„æ•°æ®ã€‚ é—­åŒ…å°±åƒé¢å‘å¯¹è±¡ä¸–ç•Œé‡Œä¼ é€’çš„ä¸€ä¸ªå¯¹è±¡ï¼ å®ƒèŠ‚çœäº†å¤§é‡å¤æ‚ä¸”ä¸å¿…è¦çš„ä»£ç ï¼Œå¹¶ç®€åŒ–äº†è§£å†³æ–¹æ¡ˆã€‚","tags":"Programming","url":"articles/Closure.html","loc":"articles/Closure.html"},{"title":"Passing a function as an argument: Lambda Function","text":"f = lambda x: x * 2 is exactly the same thing as def f ( x ) : return x * 2 Lambdas are usually used to create small, anonymous functions. Actually, they are just a syntatic sugar to define functions. The lambda expression above is exactly the same as your function, only without a name. The main difference between lambda expressions and regular functions: Lambdaè¡¨è¾¾å¼åªèƒ½åŒ…å«è¡¨è¾¾å¼ï¼Œä¸èƒ½åŒ…å«è¯­å¥ã€‚è¡¨è¾¾å¼æ˜¯ä»»ä½•å¯ä»¥æ”¾åœ¨=èµ‹å€¼å³ä¾§çš„ã€‚ # lambda function pass logger.add(tmpfile.name, compression=lambda path: email(path, app_name=conf['app_name'], model_owner=conf['model_owner'])) # function call !!! logger.add(tmpfile.name, compression=email(path, app_name=conf['app_name'], model_owner=conf['model_owner']))","tags":"Programming","url":"articles/Passing-a-function-as-an-argument:-Lambda-Function.html","loc":"articles/Passing-a-function-as-an-argument:-Lambda-Function.html"},{"title":"Using groupBy on multiple columns","text":"Group By X means put all those with the same value for X in the one group. Group By X, Y means put all those with the same values for both X and Y in the one group. To illustrate using an example, let's say we have the following table, to do with who is attending what subject at a university: Table: Subject_Selection Subject Semester Attendee --------------------------------- ITB001 1 John ITB001 1 Bob ITB001 1 Mickey ITB001 2 Jenny ITB001 2 James MKB114 1 John MKB114 1 Erica When you use a group by on the subject column only; say: select Subject, Count(*) from Subject_Selection group by Subject You will get something like: Subject Count ------------------------------ ITB001 5 MKB114 2 â€¦because there are 5 entries for ITB001 , and 2 for MKB114 If we were to group by two columns: select Subject, Semester, Count(*) from Subject_Selection group by Subject, Semester we would get this: Subject Semester Count ------------------------------ ITB001 1 3 ITB001 2 2 MKB114 1 2 This is because, when we group by two columns, it is saying \"Group them so that all of those with the same Subject and Semester are in the same group, and then calculate all the aggregate functions (Count, Sum, Average, etc.) for each of those groups\".","tags":"Programming","url":"articles/Using-groupBy-on-multiple-columns.html","loc":"articles/Using-groupBy-on-multiple-columns.html"},{"title":"Python Object and Reference","text":"å˜é‡ä¸å¯¹è±¡ Pythonä¸€åˆ‡çš†å¯¹è±¡ å¯å˜å¯¹è±¡å’Œä¸å¯å˜å¯¹è±¡ æ·±æ‹·è´ æµ…æ‹·è´ C/C++ä¸­å‡½æ•°ä¼ é€’å‚æ•°æ–¹å¼æœ‰ï¼šæŒ‰å€¼ä¼ é€’ å’Œ æŒ‰å€ä¼ é€’ã€‚è€Œåœ¨ä¸€åˆ‡çš†å¯¹è±¡çš„Pythonä¸­åˆ™å®Œå…¨ä¸å¯å»¶ç»­C/C++çš„æ€æƒ³ï¼Œè€Œæ˜¯è¦æœ‰ å¯å˜å¯¹è±¡ å’Œ ä¸å¯å˜å¯¹è±¡ çš„æ¦‚å¿µæ‰èƒ½ç†è§£ã€‚ å˜é‡ä¸å¯¹è±¡ Pythonä¸­çš„å˜é‡ä¸C/C++ä¸­å˜é‡çš„æ¦‚å¿µæ˜¯ä¸åŒçš„ã€‚ C/C++ï¼š int a = 1 # åœ¨æ ˆä¸Šå¼€è¾Ÿåœ°å€ä¸º a çš„å†…å­˜ç©ºé—´ï¼Œå­˜å…¥å€¼ 1 ã€‚ a = 2 # ä¿®æ”¹å˜é‡ a çš„å€¼ã€‚ int b = a # å°†å˜é‡ a èµ‹å€¼ç»™å¦ä¸€ä¸ªå˜é‡å˜é‡ b ,æœ¬è´¨æ˜¯ï¼šæ‹·è´ a çš„å€¼ç»™ b ã€‚ Python Pythonçš„å˜é‡æœ¬è´¨æ˜¯ï¼š å†…å­˜å¯¹è±¡çš„å¼•ç”¨ ã€‚ a = 1 # å˜é‡ a æŒ‡å‘äº†å†…å­˜ä¸­çš„ä¸€ä¸ªintå‹çš„å¯¹è±¡ã€‚ a = 2 # å¹¶éåƒC/C++ä¸­ç»™å˜é‡ a é‡æ–°èµ‹å€¼ï¼Œè€Œæ˜¯ a å°†ä¼šç§»åŠ¨å¹¶æŒ‡å‘å¦ä¸€ä¸ªå¯¹è±¡ 2 ã€‚å½“ä¸€ä¸ªå¯¹è±¡æ²¡æœ‰ä»»ä½•æ ‡ç­¾æˆ–å¼•ç”¨æŒ‡å‘å®ƒæ—¶ï¼Œå®ƒå°±ä¼šè¢«è‡ªåŠ¨é‡Šæ”¾ã€‚ b = a # æŠŠå˜é‡ a èµ‹ç»™å¦ä¸€ä¸ªå˜é‡ b ï¼Œåªæ˜¯ç»™å½“å‰å†…å­˜ä¸­å¯¹è±¡å¢åŠ ä¸€ä¸ªå¼•ç”¨è€Œå·²ã€‚ Pythonä¸€åˆ‡çš†å¯¹è±¡ Pythonä½¿ç”¨å¯¹è±¡æ¨¡å‹æ¥å‚¨å­˜æ•°æ®ï¼Œä»»ä½•ç±»å‹çš„å€¼éƒ½æ˜¯ä¸€ä¸ªå¯¹è±¡ã€‚æ‰€æœ‰çš„pythonå¯¹è±¡éƒ½æœ‰3ä¸ªç‰¹å¾ï¼š èº«ä»½ã€ç±»å‹ã€å€¼ã€‚ èº«ä»½ï¼šæ¯ä¸€ä¸ªå¯¹è±¡éƒ½æœ‰è‡ªå·±çš„å”¯ä¸€çš„æ ‡è¯†ï¼Œå¯ä»¥ä½¿ç”¨å†…å»ºå‡½æ•° id() æ¥å¾—åˆ°å®ƒã€‚è¿™ä¸ªå€¼å¯ä»¥è¢«è®¤ä¸ºæ˜¯è¯¥å¯¹è±¡çš„å†…å­˜åœ°å€ã€‚ ç±»å‹ï¼šå¯¹è±¡çš„ç±»å‹å†³å®šäº†è¯¥å¯¹è±¡å¯ä»¥ä¿å­˜çš„ä»€ä¹ˆç±»å‹çš„å€¼ï¼Œå¯ä»¥è¿›è¡Œä»€ä¹ˆæ“ä½œï¼Œä»¥åŠéµå¾ªä»€ä¹ˆæ ·çš„è§„åˆ™ã€‚ type() å‡½æ•°æ¥æŸ¥çœ‹å¯¹è±¡çš„ç±»å‹ã€‚ å€¼ï¼šå¯¹è±¡è¡¨ç¤ºçš„æ•°æ®é¡¹ã€‚ a is b ï¼šé€šè¿‡ id() åˆ¤æ–­æ˜¯å¦ä¸ºåŒä¸€ä¸ªå¯¹è±¡çš„å¼•ç”¨ã€‚ a == b ï¼šåˆ¤æ–­ a å’Œ b å¼•ç”¨çš„å¯¹è±¡çš„å€¼æ˜¯å¦ç›¸åŒã€‚ å¯å˜å¯¹è±¡å’Œä¸å¯å˜å¯¹è±¡ Pythonçš„åŸºæœ¬æ•°æ®ç±»å‹ä¸­ã€‚ å¯å˜å¯¹è±¡ï¼š åˆ—è¡¨ï¼Œ å­—å…¸ ä¸å¯å˜å¯¹è±¡ï¼š æ•°å­—ï¼Œå­—ç¬¦ä¸²ï¼Œå…ƒç»„ a = 1 # a æŒ‡å‘å†…å­˜ä¸­ä¸€ä¸ªintå‹å¯¹è±¡ a = 2 # å½“å°† a é‡æ–°èµ‹å€¼æ—¶ï¼Œå› ä¸º 1 æ˜¯ä¸å¯å˜å¯¹è±¡ï¼Œæ‰€ä»¥ a ä¼šæŒ‡å‘ä¸€ä¸ªæ–°çš„intå‹å¯¹è±¡ï¼Œå…¶å€¼ä¸º 2 ã€‚ lst = [1, 2] # lst æŒ‡å‘å†…å­˜ä¸­ä¸€ä¸ªlistç±»å‹çš„å¯¹è±¡ lst[0] = 2 # é‡æ–°èµ‹å€¼ lst ä¸­ç¬¬ä¸€ä¸ªå…ƒç´  å› ä¸ºlistç±»å‹æ˜¯å¯ä»¥æ”¹å˜çš„ï¼Œæ‰€ä»¥ç¬¬ä¸€ä¸ªå…ƒç´ å˜æ›´ä¸º2ã€‚æ›´ç¡®åˆ‡çš„è¯´ï¼Œlstçš„ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯intå‹ï¼Œé‡æ–°èµ‹å€¼æ—¶ä¸€ä¸ªæ–°çš„intå¯¹è±¡è¢«æŒ‡å®šç»™ç¬¬ä¸€ä¸ªå…ƒç´ ï¼Œä½†æ˜¯å¯¹äºlstæ¥è¯´ï¼Œå®ƒæ‰€æŒ‡çš„åˆ—è¡¨å‹å¯¹è±¡æ²¡æœ‰å˜ï¼Œåªæ˜¯åˆ—è¡¨çš„å†…å®¹ï¼ˆå…¶ä¸­ä¸€ä¸ªå…ƒç´ ï¼‰æ”¹å˜äº†ã€‚ def foo ( arg ): arg = 5 print ( arg ) x = 1 # ä¸å¯å˜å¯¹è±¡ foo ( x ) # 5 print ( x ) # 1 def foo ( arg ): arg . append ( 3 ) x = [ 1 , 2 ] # å¯å˜å¯¹è±¡ print ( x ) # [1, 2] foo ( x ) print ( x ) # [1, 2, 3] å¯¹äºä¸å¯å˜çš„å¯¹è±¡ï¼Œç±»ä¼¼ä¼ å€¼æ–¹å¼ï¼›å¯¹äºå¯å˜å¯¹è±¡ï¼Œç±»ä¼¼æŒ‰å€ä¼ é€’ã€‚ æ·±æ‹·è´ æµ…æ‹·è´ èµ‹å€¼ï¼šç®€å•åœ°æ‹·è´å¯¹è±¡çš„å¼•ç”¨ï¼Œä¸¤ä¸ªå¯¹è±¡çš„idç›¸åŒã€‚ æµ…æ‹·è´ï¼šåˆ›å»ºä¸€ä¸ªæ–°çš„ç»„åˆå¯¹è±¡ï¼Œè¿™ä¸ªæ–°å¯¹è±¡ä¸åŸå¯¹è±¡å…±äº«å†…å­˜ä¸­çš„å­å¯¹è±¡ã€‚ æ·±æ‹·è´ï¼šåˆ›å»ºä¸€ä¸ªæ–°çš„ç»„åˆå¯¹è±¡ï¼ŒåŒæ—¶é€’å½’åœ°æ‹·è´æ‰€æœ‰å­å¯¹è±¡ï¼Œæ–°çš„ç»„åˆå¯¹è±¡ä¸åŸå¯¹è±¡æ²¡æœ‰ä»»ä½•å…³è”ã€‚è™½ç„¶å®é™…ä¸Šä¼šå…±äº«ä¸å¯å˜çš„å­å¯¹è±¡ï¼Œä½†ä¸å½±å“å®ƒä»¬çš„ç›¸äº’ç‹¬ç«‹æ€§ã€‚ æµ…æ‹·è´å’Œæ·±æ‹·è´çš„ä¸åŒä»…ä»…æ˜¯å¯¹ç»„åˆå¯¹è±¡æ¥è¯´ï¼Œæ‰€è°“çš„ç»„åˆå¯¹è±¡å°±æ˜¯åŒ…å«äº†å…¶å®ƒå¯¹è±¡çš„å¯¹è±¡ï¼Œå¦‚åˆ—è¡¨ï¼Œç±»å®ä¾‹ã€‚è€Œå¯¹äºæ•°å­—ã€å­—ç¬¦ä¸²ä»¥åŠå…¶å®ƒ\"åŸå­\"ç±»å‹ï¼Œæ²¡æœ‰æ‹·è´ä¸€è¯´ï¼Œäº§ç”Ÿçš„éƒ½æ˜¯åŸå¯¹è±¡çš„å¼•ç”¨ã€‚ æ·±æ‹·è´ æµ…æ‹·è´","tags":"Programming","url":"articles/Python Object and Reference.html","loc":"articles/Python Object and Reference.html"},{"title":"Cygwin","text":"Cygwinä¸­å®‰è£…è½¯ä»¶ Pycahrmä¸­å¯Cygwinç»ˆç«¯ Cygwinä¸­ä½¿ç”¨windows anaconda Cygwinä¸­å®‰è£…è½¯ä»¶ #download setup-x86_64.exe https://cygwin.com/setup-x86_64.exe $ cd C : cygwin64 $ ./ setup - x86_64 . exe - q - P wget , tar , qawk , bzip2 , subversion , vim , git # git clone https://github.com/transcode-open/apt-cyg $ cd apt-cyg $ mv apt-cyg /usr/local/bin/ $ apt-cyg --help $ cygcheck --help # modify mirror $ apt-cyg --mirror http://mirrors.163.com/cygwin # mirrors backup # ftp://mirror.mcs.anl.gov/pub/cygwin # http://mirrors.163.com/cygwin # ftp://ftp.ges.redhat.com/private/releng/cygwin-1.8 # apt-cyg install man cygwin-doc apt-cyg install vim screenwget subversion openssh Pycahrmä¸­å¯Cygwinç»ˆç«¯ Files|Settings|Tools|Terminal|Shellpath path: C:\\cygwin64\\bin\\bash.exe This is a non-interactive shell, and does not source your profile. The next try is: C:\\cygwin64\\bin\\bash.exe --login -i This produces an error from Pycharm that it cannot start the program correctly. A little checking says the leading command needs to be quoted, else Pycahrm treats the entire line as the name of the command, not as a command followed by flags. OK : \"C:\\cygwin64\\bin\\bash.exe\" --login -i It starts in my home directory, not in my project root. Starting in the project root is one of the nice features of the terminal in IntelliJ. Finally, two changes. First the IntelliJ setting: `\"C:\\cygwin64\\bin\\bash\" -c \"exec /usr/bin/env INTELLIJ=true $SHELL --login -i\" And an addition to my ~/.bashrc : ${INTELLIJ-false} && cd ${OLDPWD-.} Cygwinä¸­ä½¿ç”¨windows anaconda vim ~/.bashrc åŠ å…¥ä»¥ä¸‹è„šæœ¬ï¼š #####################By Jerry for using Anaconda on Cygwin################# # Anaconda Environment Selection - Plese set CONDA_BASE_DIR to the directory # containing the base installation of anaconda/miniconda. export CONDA_BASE_DIR =/ cygdrive / c / Users / YCKJ2939 / AppData / Local / Continuum / anaconda3 # Proxy Servers & Network Setup (if needed) export HTTP_PROXY = export HTTPS_PROXY = # IMPORTANT - Ignore carriage returns when using a Cygwin environment. export SHELLOPTS set - o igncr ############################################################################### # Manage conda environments for Python. We check the environment variable # $CONDA_DEFAULT_ENV to see which environment is desired. The default (base) # environment will be chosen if nothing is specified. Note that this variable # will be explicitly managed by the cactivate ( ) function we have defined # below, specifically for the purpose of changing environments. The root # environment is also handled slightly different from the others when it comes # to setting the CONDA_DEFAULT_ENV variable. if [ $ { CONDA_DEFAULT_ENV } ] && [ $ { CONDA_DEFAULT_ENV } != 'base' ] then # SELECT ONE OF THE NON-DEFAULT ENVIRONMENTS export CONDA_PREFIX =$ { CONDA_BASE_DIR } / envs /$ { CONDA_DEFAULT_ENV } else # SELECT THE DEFAULT ENVIRONMENT (and set CONDA_DEFAULT_ENV full path) export CONDA_DEFAULT_ENV = root export CONDA_PREFIX =$ { CONDA_BASE_DIR } fi ############################################################################### # Define cconda and cactivate to facilitate management of conda. alias cconda =$ { CONDA_BASE_DIR } / Scripts / conda . exe cactivate () { export CONDA_DEFAULT_ENV =$ 1 source ~/. bashrc cconda info -- envs } ############################################################################### # PATH - ALl of the anaconda/miniconda path entries appear first. PATH = PATH =$ PATH : $ CONDA_PREFIX PATH =$ PATH : $ CONDA_PREFIX / Library / mingw - w64 / bin PATH =$ PATH : $ CONDA_PREFIX / Library / usr / bin PATH =$ PATH : $ CONDA_PREFIX / Library / bin PATH =$ PATH : $ CONDA_PREFIX / Scripts PATH =$ PATH : $ HOME / scripts PATH =$ PATH : $ HOME / local / bin PATH =$ PATH : / usr / local / bin PATH =$ PATH : / usr / bin export PATH ############################################################################### Somethings to remember for this integration to work. Please install Anaconda directly from installer and not from package manager like Chocolatey, since for this approach to work the envs must be within the anaconda root directory. In order for anaconda python to work in cygwin commandline, you must use python -i . Using just python freezes the screen. Ref: using-anaconda-environments-with-cygwin-on-windows","tags":"Tools","url":"articles/Cygwin.html","loc":"articles/Cygwin.html"},{"title":"Case Class vs Class","text":"å®šä¹‰ æ¯”è¾ƒ pattern matching ç»§æ‰¿ case classçš„ä»£ç å®ç° å®šä¹‰ classçš„å®šä¹‰: class BankAccount { def deposit ( amount : Int ): Unit = { if ( amount > 0 ) balance = balance + amount } case classçš„å®šä¹‰: case class Note ( name : String , duration : String , octave : Int ) åˆ›å»º BankAccount å’Œ Note çš„å®ä¾‹ï¼š val aliceAccount = new BankAccount () val c3 = Note ( \"C\" , \"Quarter\" , 3 ) case class ç±»å®ä¾‹åŒ–ä¸éœ€è¦ new , case class æœ‰ä¸€ä¸ªé»˜è®¤çš„ apply æ–¹æ³•æ¥è´Ÿè´£å¯¹è±¡çš„åˆ›å»ºã€‚ åˆ›å»ºå¸¦å‚ case class æ—¶ï¼Œå‚æ•°æ—¶ val ç±»å‹çš„ã€‚ e.gï¼š c3.name = â€˜Jerry' //does not compile æ¯”è¾ƒ val aliceAccount = new BankAccount val bobAccount = new BankAccount // aliceAccount == bobAccount shouldBe False val c3 = Note ( \"C\" , \"Quarter\" , 3 ) val cThree = Note ( \"C\" , \"Quarter\" , 3 ) // c3 == cThree shouldBe True åœ¨Scalaä¸­ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œæ¯”è¾ƒå¯¹è±¡å°†æ¯”è¾ƒå®ƒä»¬çš„å¼•ç”¨ï¼Œå³ **æŒ‰å¼•ç”¨æ¯”è¾ƒ** ã€‚ ä½†åœ¨ case class å®ä¾‹çš„æƒ…å†µä¸‹ï¼Œé‡æ–°å®šä¹‰ç›¸ç­‰æ€§ä»¥æ¯”è¾ƒèšåˆä¿¡æ¯çš„å€¼ï¼Œå³ **æŒ‰å€¼æ¯”è¾ƒ** ã€‚ pattern matching pattern matching ä¸é€‚ç”¨äº class ç”¨ pattern matching ä» case class å®ä¾‹ä¸­æŠ½å–ä¿¡æ¯ c3 match { case Note ( name , duration , octave ) => \"The duration of c3 is duration\" } ç»§æ‰¿ class å¯ç»§æ‰¿ï¼Œ case class ä¸å¯ç»§æ‰¿ï¼ˆå› ä¸ºä¸å¯èƒ½æ­£ç¡®åœ°å®ç°å®ƒä»¬çš„ç›¸ç­‰ï¼‰ case classçš„ä»£ç å®ç° case class åªæ˜¯ class çš„ä¸€ä¸ªç‰¹ä¾‹ï¼Œç›®çš„æ˜¯å°†å¤šä¸ªå€¼èšåˆä¸ºä¸€ä¸ªå•å€¼ã€‚Scalaæ˜¾ç¤ºçš„æ”¯æŒ case class æ˜¯å› ä¸ºåœ¨å®è·µä¸­å¸¸ç”¨ã€‚ å½“æˆ‘ä»¬åœ¨å®šä¹‰ä¸€ä¸ª case class æ—¶ï¼Œç¼–è¯‘å™¨å®é™…å®šä¹‰äº†ä¸€ä¸ª ä½¿ç”¨æ›´å¤šæ–¹æ³• å’Œ ä¼´éšå¯¹è±¡ çš„å¢å¼º class ã€‚ e.g: case class Note ( name : String , duration : String , octave : Int ) ç¼–è¯‘å™¨å®é™…å®šä¹‰ï¼š class Note ( _name : String , _duration : String , _octave : Int ) extends Serializable { // Note class // Constructor parameters are promoted to members val name = _name val duration = _duration val octave = _octave // Equality redefinition override def equals ( other : Any ): Boolean = other match { case that : Note => ( that canEqual this ) && name == that . name && duration == that . duration && octave == that . octave case _ => false } def canEqual ( other : Any ): Boolean = other . isInstanceOf [ Note ] // Java hashCode redefinition according to equality override def hashCode (): Int = { val state = Seq ( name , duration , octave ) state . map ( _ . hashCode ()). foldLeft ( 0 )(( a , b ) => 31 * a + b ) } // toString redefinition to return the value of an instance instead of its memory addres override def toString = \"Note(name,duration,octave)\" // Create a copy of a case class, with potentially modified field values def copy ( name : String = name , duration : String = duration , octave : Int = octave ): Note = new Note ( name , duration , octave ) } object Note { // ä¼´éšå¯¹è±¡ // Constructor that allows the omission of the `new` keyword def apply ( name : String , duration : String , octave : Int ): Note = new Note ( name , duration , octave ) // Extractor for pattern matching def unapply ( note : Note ): Option [( String , String , Int )] = if ( note eq null ) None else Some (( note . name , note . duration , note . octave )) }","tags":"Programming","url":"articles/Case-Class-vs-Class.html","loc":"articles/Case-Class-vs-Class.html"},{"title":"Singleton & Companion Object","text":"Static in Java Singleton object Companion object Notes for Java programmers Static in Java Static in Java Singleton object å•ä¾‹å¯¹è±¡æ˜¯ä¸€ç§ç‰¹æ®Šçš„ç±»ï¼Œæœ‰ä¸”åªæœ‰ä¸€ä¸ªå®ä¾‹ã€‚å’Œæƒ°æ€§å˜é‡ä¸€æ ·ï¼Œå•ä¾‹å¯¹è±¡æ˜¯å»¶è¿Ÿåˆ›å»ºçš„ï¼Œå½“å®ƒç¬¬ä¸€æ¬¡è¢«ä½¿ç”¨æ—¶åˆ›å»ºã€‚ å½“å¯¹è±¡å®šä¹‰äºé¡¶å±‚æ—¶(å³æ²¡æœ‰åŒ…å«åœ¨å…¶ä»–ç±»ä¸­)ï¼Œå•ä¾‹å¯¹è±¡åªæœ‰ä¸€ä¸ªå®ä¾‹ã€‚ å½“å¯¹è±¡å®šä¹‰åœ¨ä¸€ä¸ªç±»æˆ–æ–¹æ³•ä¸­æ—¶ï¼Œå•ä¾‹å¯¹è±¡è¡¨ç°å¾—å’Œæƒ°æ€§å˜é‡ä¸€æ ·ã€‚ package logging object Logger { def info ( message : String ): Unit = println ( message ) } æ–¹æ³• info å¯ä»¥åœ¨ç¨‹åºä¸­çš„ä»»ä½•åœ°æ–¹è¢«å¼•ç”¨ã€‚åƒè¿™æ ·åˆ›å»ºåŠŸèƒ½æ€§æ–¹æ³•æ˜¯å•ä¾‹å¯¹è±¡çš„ä¸€ç§å¸¸è§ç”¨æ³•ã€‚ å¦‚ä½•åœ¨å¦å¤–ä¸€ä¸ªåŒ…ä¸­ä½¿ç”¨ info æ–¹æ³•ï¼š import logging . Logger . info class Project ( name : String , daysToComplete : Int ) class Test { val project1 = new Project ( \"TPS Reports\" , 1 ) val project2 = new Project ( \"Website redesign\" , 5 ) info ( \"Created projects\" ) // Prints \"INFO: Created projects\" } å› ä¸º import è¯­å¥ import logging.Logger.info ï¼Œæ–¹æ³• info åœ¨æ­¤å¤„æ˜¯å¯è§çš„ã€‚ import è¯­å¥è¦æ±‚è¢«å¯¼å…¥çš„æ ‡è¯†å…·æœ‰ä¸€ä¸ª\"ç¨³å®šè·¯å¾„\"ï¼Œä¸€ä¸ªå•ä¾‹å¯¹è±¡ç”±äºå…¨å±€å”¯ä¸€ï¼Œæ‰€ä»¥å…·æœ‰ç¨³å®šè·¯å¾„ã€‚ æ³¨æ„ï¼š å¦‚æœä¸€ä¸ª object æ²¡å®šä¹‰åœ¨é¡¶å±‚è€Œæ˜¯å®šä¹‰åœ¨å¦ä¸€ä¸ªç±»æˆ–è€…å•ä¾‹å¯¹è±¡ä¸­ï¼Œé‚£ä¹ˆè¿™ä¸ªå•ä¾‹å¯¹è±¡å’Œå…¶ä»–ç±»æ™®é€šæˆå‘˜ä¸€æ ·æ˜¯\"è·¯å¾„ç›¸å…³çš„\"ã€‚è¿™æ„å‘³ç€æœ‰ä¸¤ç§è¡Œä¸ºï¼Œ class Milk å’Œ class OrangeJuice ï¼Œä¸€ä¸ªç±»æˆå‘˜ object NutritionInfo \"ä¾èµ–\"äºåŒ…è£…å®ƒçš„å®ä¾‹ï¼Œè¦ä¹ˆæ˜¯ç‰›å¥¶è¦ä¹ˆæ˜¯æ©™æ±ã€‚ milk.NutritionInfo åˆ™å®Œå…¨ä¸åŒäº oj.NutritionInfo ã€‚ Companion object å®šä¹‰ï¼šå½“ä¸€ä¸ªå•ä¾‹å¯¹è±¡å’ŒæŸä¸ªç±»å…±äº«ä¸€ä¸ªåç§°æ—¶ï¼Œè¿™ä¸ªå•ä¾‹å¯¹è±¡ç§°ä¸º ä¼´ç”Ÿå¯¹è±¡ã€‚ åŒç†ï¼Œè¿™ä¸ªç±»è¢«ç§°ä¸ºæ˜¯è¿™ä¸ªå•ä¾‹å¯¹è±¡çš„ä¼´ç”Ÿç±»ã€‚ ç±»å’Œå®ƒçš„ä¼´ç”Ÿå¯¹è±¡å¯ä»¥äº’ç›¸è®¿é—®å…¶ç§æœ‰æˆå‘˜ã€‚ ä½œç”¨ï¼šä½¿ç”¨ä¼´ç”Ÿå¯¹è±¡æ¥å®šä¹‰é‚£äº›åœ¨ä¼´ç”Ÿç±»ä¸­ä¸ä¾èµ–äºå®ä¾‹åŒ–å¯¹è±¡è€Œå­˜åœ¨çš„æˆå‘˜å˜é‡æˆ–è€…æ–¹æ³•ã€‚ import scala . math . _ case class Circle ( radius : Double ) { import Circle . _ def area : Double = calculateArea ( radius ) } object Circle { private def calculateArea ( radius : Double ): Double = Pi * pow ( radius , 2.0 ) } val circle1 = new Circle ( 5.0 ) circle1 . area è¿™é‡Œçš„ class Circle æœ‰ä¸€ä¸ªæˆå‘˜ area æ˜¯å’Œå…·ä½“çš„å®ä¾‹åŒ–å¯¹è±¡ç›¸å…³çš„. å•ä¾‹å¯¹è±¡ object Circle åŒ…å«ä¸€ä¸ªæ–¹æ³• calculateArea ï¼Œå®ƒåœ¨æ¯ä¸€ä¸ªå®ä¾‹åŒ–å¯¹è±¡ä¸­éƒ½æ˜¯å¯è§çš„ã€‚ Notes for Java programmers Javaä¸­ staticæˆå‘˜ <===> Scalaä¸­ ä¼´ç”Ÿå¯¹è±¡çš„æ™®é€šæˆå‘˜ å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œéœ€è¦ä¸€ä¸ªå¯¹è±¡æ¥ä¿å­˜å¯ç”¨çš„æ–¹æ³•å’Œå€¼/å˜é‡ï¼Œè€Œæ— éœ€é¦–å…ˆå®ä¾‹åŒ–æŸä¸ªç±»çš„å®ä¾‹ã€‚è¿™ä¸Javaä¸­çš„é™æ€æˆå‘˜å¯†åˆ‡ç›¸å…³ã€‚ object A { def twice ( i : Int ): Int = 2 * i } A . twice ( 2 ) // ç›´æ¥è°ƒç”¨ class A () { def twice ( i : Int ): Int = 2 * i } val a = new A () // éœ€å…ˆå®ä¾‹åŒ–ï¼Œå†è°ƒç”¨ a . twice ( 2 ) åœ¨ Java ä»£ç ä¸­è°ƒç”¨ä¼´ç”Ÿå¯¹è±¡æ—¶ï¼Œä¼´ç”Ÿå¯¹è±¡çš„æˆå‘˜ä¼šè¢«å®šä¹‰æˆä¼´ç”Ÿç±»ä¸­çš„ static æˆå‘˜ã€‚è¿™ç§°ä¸º é™æ€è½¬å‘ã€‚è¿™ç§è¡Œä¸ºå‘ç”Ÿåœ¨å½“ä½ è‡ªå·±æ²¡æœ‰å®šä¹‰ä¸€ä¸ªä¼´ç”Ÿç±»æ—¶ã€‚ Singleton objects Difference between object and class in scala","tags":"Programming","url":"articles/Singleton-&-Companion-Object.html","loc":"articles/Singleton-&-Companion-Object.html"},{"title":"Binary Tree","text":"äºŒå‰æ ‘ç»“æ„å®šä¹‰ åˆ†æ²»ç®—æ³• éå†æ³• VS åˆ†æ²»æ³• é€’å½’ VS éé€’å½’ å‰åºéå† ä¸­åºéå† ååºéå† å±‚åºéå† ä¹‹å­—å±‚åºéå† åºåˆ—åŒ–å’Œååºåˆ—åŒ– å‰ä¸­åºé‡æ„äºŒå‰æ ‘ äºŒå‰æ ‘æœ€å¤§æ·±åº¦ äºŒå‰æ ‘æœ€å°æ·±åº¦ å¹³è¡¡äºŒå‰æ ‘ äºŒå‰æœç´¢æ ‘ BST äºŒå‰æœç´¢æ ‘æœ€è¿‘å…¬å…±ç¥–å…ˆ äºŒå‰æ ‘çš„æœ€è¿‘å…¬å…±ç¥–å…ˆ Same Tree Subtree of Another Tree Binary Tree Maximum Path Sum äºŒå‰æ ‘ç»“æ„å®šä¹‰ struct TreeNode { int val ; TreeNode * left ; TreeNode * right ; TreeNode ( int val ) : val ( val ), left ( nullptr ), right ( nullptr ) {} }; åˆ†æ²»ç®—æ³• åˆ†æ²»æ³•çš„é‡ç‚¹åœ¨äº é—®é¢˜çš„åˆ’åˆ† å’Œ è¿”å›çŠ¶æ€çš„å®šä¹‰ éå†æ³• VS åˆ†æ²»æ³• é€’å½’ æ˜¯å®ç°æ–¹å¼ï¼Œ éå†æ³• å’Œ åˆ†æ²»æ³• æ˜¯å¯ä»¥ç”¨ é€’å½’ å®ç°çš„ç®—æ³•æ€æƒ³ Result in parameter vs Result in return value ï¼Œæ‰€ä»¥ åˆ†æ²»æ³• ä¸€èˆ¬ä¸éœ€è¦å…¨å±€å˜é‡ï¼Œå¯å®ç°å¹¶è¡Œã€‚ éå†æ³• çš„ç»“æœè¦æ”¹å‚æ•°ï¼Œè¿”å›å‚æ•°ï¼› åˆ†æ²»æ³• çš„ç»“æœç›´æ¥è¿”å›ï¼Œæ˜¯ä¸ªæ›´å¥½çš„æ¥å£ï¼Œå› ä¸ºä¼ å…¥çš„å‚æ•°æœ€å¥½ä¸è¦æ”¹ã€‚ é€’å½’æ˜¯è‡ªé¡¶å‘ä¸‹ Top down VS åˆ†æ²»æ˜¯è‡ªåº•å‘ä¸Š Bottom up é€’å½’ VS éé€’å½’ éé€’å½’å…¶å®æ˜¯æ¨¡æ‹Ÿé€’å½’ç”¨çš„Stack ä¸ºä»€ä¹ˆè‡ªå·±æ¨¡æ‹Ÿçš„å¯ä»¥ï¼Œè°ƒç”¨è®¡ç®—æœºçš„å°±ä¸è¡Œå‘¢ ï¼Ÿ å› ä¸º heap memory â‰ˆ memory size ï¼Œnewå‡ºçš„stackåœ¨é‡Œé¢ï¼Œä¸ç”¨æ‹…å¿ƒæ ˆæº¢å‡ºã€‚ è€Œ stack memory â‰ˆ process memory æ˜¯è®¡ç®—æœºåˆ†ç»™æ¯ä¸ªç¨‹åºçš„ä¸€ä¸ªå¾ˆå°çš„ç‹¬å çš„ç©ºé—´ï¼Œæ‰€ä»¥é€’å½’çš„æ·±åº¦å¤ªæ·±ï¼Œå®¹æ˜“æ ˆæº¢å‡ºã€‚ å‰åºéå† é€’å½’ def preorderTraversal ( root ): res = [] self . traversal ( root , res ) return res def traversal ( root , res ): if not root : return res . append ( root . val ) traversal ( root . left , res ) traversal ( root . right , res ) åˆ†æ²» åˆ†æ²»æ³•çš„è¿”å›çŠ¶æ€å®šä¹‰ï¼š å­æ ‘çš„å…ˆåºéå†ç»“æœ List def preorderTraversal ( root ): # end condition if not root : return [] # divide & conquer left = preorderTraversal ( root . left ) right = preorderTraversal ( root . right ) # combine res = [] res . append ( root . val ) res . extend ( left ) res . extend ( right ) # return result return res éé€’å½’ # 1. é¦–å…ˆæŠŠrootå…¥æ ˆ # 2. å‡ºæ ˆçš„å…ƒç´ åŒæ—¶æ”¾è¿›ç»“æœåˆ—è¡¨ # 3. å³å·¦å„¿å­ä¾æ¬¡å…¥æ ˆï¼Œè¿™æ ·å‡ºæ ˆçš„é¡ºåºæ˜¯å…ˆå·¦åå³ï¼ˆæ ¹èŠ‚ç‚¹å·²å‡ºï¼‰ # 4. æŒ‰ç…§æ¬¡åºç»§ç»­ï¼Œç›´åˆ°stackä¸ºç©º def preorderTraversal ( root ): if not root : return [] stack , res = [ root ], [] while stack : node = stack . pop () res . append ( node . val ) if node . right : stack . append ( node . right ) if node . left : stack . append ( node . left ) return res ä¸­åºéå† é€’å½’ def inorderTraversal ( root ): res = [] self . traversal ( root , res ) return res def traversal ( root , res ): if not root : return traversal ( root . left , res ) res . append ( root . val ) traversal ( root . right , res ) åˆ†æ²» def inorderTraversal ( root ): # end condition if not root : return [] # divide & conquer left = preorderTraversal ( root . left ) right = preorderTraversal ( root . right ) # combine res = [] res . extend ( left ) res . append ( root . val ) res . extend ( right ) # return result return res éé€’å½’ å¯¹äºä»»ä¸€ç»“ç‚¹ cur ï¼Œ è‹¥å…¶å·¦å­©å­ä¸ä¸ºç©ºï¼Œåˆ™å°† cur å…¥æ ˆå¹¶å°† cur çš„å·¦å­©å­ç½®ä¸ºå½“å‰çš„ cur ï¼Œç„¶åå¯¹å½“å‰ç»“ç‚¹ cur å†è¿›è¡Œç›¸åŒçš„å¤„ç†ï¼› è‹¥å…¶å·¦å­©å­ä¸ºç©ºï¼Œåˆ™å–æ ˆé¡¶å…ƒç´ å¹¶è¿›è¡Œå‡ºæ ˆæ“ä½œï¼Œè®¿é—®è¯¥æ ˆé¡¶ç»“ç‚¹ï¼Œç„¶åå°†å½“å‰çš„ cur ç½®ä¸ºæ ˆé¡¶ç»“ç‚¹çš„å³å­©å­ï¼› ç›´åˆ° cur ä¸º None å¹¶ä¸”æ ˆä¸ºç©ºåˆ™éå†ç»“æŸ class Solution : def inorderTraversal ( self , root : TreeNode ) -> List [ int ]: if not root : return [] stack = [] cur = root res = [] while stack or cur : if cur : # å·¦å­æ ‘å…¥æ ˆåˆ°åº•ï¼Œæ‰¾åˆ°æœ€å·¦å­©å­ã€‚ stack . append ( cur ) cur = cur . left else : cur = stack . pop () res . append ( cur . val ) cur = cur . right return res ååºéå† é€’å½’ def postorderTraversal ( root ): res = [] self . traversal ( root , res ) return res def traversal ( root , res ): if not root : return traversal ( root . left , res ) traversal ( root . right , res ) append ( root . val ) åˆ†æ²» def postorderTraversal ( root ): # end condition if not root : return [] # divide & conquer left = preorderTraversal ( root . left ) right = preorderTraversal ( root . right ) # combine res = [] res . extend ( left ) res . extend ( right ) res . append ( root . val ) # return result return res éé€’å½’ pass å±‚åºéå† ä½¿ç”¨é˜Ÿåˆ—æ•°æ®ç»“æ„ï¼šcollections.deque é˜Ÿåˆ—åˆå§‹åŒ–ï¼Œæ ¹èŠ‚ç‚¹å…ˆå…¥é˜Ÿåˆ—ï¼šqueue = [root] æŸ¥çœ‹é˜Ÿåˆ—æ˜¯å¦ä¸ºç©ºï¼šwhile queue å¦‚æœåˆ†å±‚æ‰“å°ï¼Œåˆ™å…ˆç«‹å³ç¼“å­˜è¯¥å±‚å¤§å°ï¼šn = len(queue), for _ range(n) éå†è¯¥å±‚èŠ‚ç‚¹ä¾æ¬¡å‡ºé˜Ÿï¼ŒæŸ¥çœ‹å·¦å³å­©å­ï¼Œå­˜åœ¨å³å…¥é˜Ÿå°¾ã€‚ Python from collections import deque class Solution : def levelOrder ( self , root : TreeNode ) -> List [ List [ int ]]: if not root : return [] res = [] queue = deque () queue . append ( root ) while queue : cur_level = [] n = len ( queue ) for _ in range ( n ): node = queue . popleft () cur_level . append ( node . val ) if node . left : queue . append ( node . left ) if node . right : queue . append ( node . right ) res . append ( cur_level ) return res CPP class Solution { public : vector < int > preorderTraversal ( TreeNode * root ) { vector < int > res ; if ( root == nullptr ) retur res ; stack < TreeNode *> stk ; stk . push ( root ); while ( ! stk . empty ()) { TreeNode * node = stk . top (); stk . pop (); res . push_back ( node -> val ); if ( node -> right ) stk . push ( node -> right ); if ( node -> left ) stk . push ( node -> left ); } return res ; } }; ä¹‹å­—å±‚åºéå† class Solution : def zigzagLevelOrder ( self , root : TreeNode ) -> List [ List [ int ]]: if not root : return [] res = [] queue = collections . deque () queue . append ( root ) level = 0 while queue : level_cur = [] n = len ( queue ) for _ in range ( n ): node = queue . popleft () level_cur . append ( node . val ) if node . left : queue . append ( node . left ) if node . right : queue . append ( node . right ) res . append ( level_cur if level % 2 == 0 else level_cur [:: - 1 ]) level += 1 return res åºåˆ—åŒ–å’Œååºåˆ—åŒ– from collections import deque class Codec : def serialize ( self , root ): if not root : return '' res = [] queue = deque () queue . append ( root ) while queue : node = queue . popleft () if node : res . append ( str ( node . val )) queue . append ( node . left ) queue . append ( node . right ) else : res . append ( '#' ) return ',' . join ( res ) def deserialize ( self , data ): if not data : return None nodes = data . split ( ',' ) root = TreeNode ( int ( nodes [ 0 ])) queue = deque ([ root ]) index = 1 while queue : node = queue . popleft () if nodes [ index ] is not '#' : node . left = TreeNode ( int ( nodes [ index ])) queue . append ( node . left ) index += 1 if nodes [ index ] is not '#' : node . right = TreeNode ( int ( nodes [ index ])) queue . append ( node . right ) index += 1 return root å‰ä¸­åºé‡æ„äºŒå‰æ ‘ leetcode solution class Solution { public : TreeNode * buildTree ( vector < int >& preorder , vector < int >& inorder ) { unordered_map < int , int > map ; int n = preorder . size (); // ä½¿ç”¨hashç»“æ„å¿«é€Ÿåœ¨ä¸­åºéå†çš„ç»“æœä¸­å®šä½æ ¹ç»“ç‚¹çš„ä½ç½® for ( int i = 0 ; i < n ; ++ i ) { map [ inorder[i ] ] = i ; } return myBuildTree ( map , preorder , inorder , 0 , n - 1 , 0 , n - 1 ); } TreeNode * myBuildTree ( unordered_map < int , int >& map , vector < int >& preorder , vector < int >& inorder , int preorder_left , int preorder_right , int inorder_left , int inorder_right ) { if ( preorder_left > preorder_right || inorder_left > inorder_right ) { return nullptr ; } // å‰åºéå†ç¬¬ä¸€ä¸ªç»“ç‚¹ä¸ºæ ¹ç»“ç‚¹ int preorder_root = preorder_left ; // å»ºç«‹æ ¹ç»“ç‚¹ TreeNode * root = new TreeNode ( preorder [ preorder_root ] ); // æ ¹ç»“ç‚¹åœ¨ä¸­åºä¸­çš„ä½ç½® int inorder_root = map [ preorder[preorder_root ] ] ; // ä¸­åºçš„å·¦å­æ ‘å·¦å³åŒºé—´ int inorder_sublefttree_left = inorder_left ; int inorder_sublefttree_right = inorder_root - 1 ; // ä¸­åºçš„å³å­æ ‘å·¦å³åŒºé—´ int inorder_subrighttree_left = inorder_root + 1 ; int inorder_subrighttree_right = inorder_right ; // å‰åºçš„å·¦å­æ ‘å·¦å³åŒºé—´ int preorder_sublefttree_left = preorder_left + 1 ; int preorder_sublefttree_right = inorder_sublefttree_right - inorder_sublefttree_left + preorder_sublefttree_left ; // å‰åºçš„å³å­æ ‘å·¦å³åŒºé—´ int preorder_subrighttree_left = preorder_sublefttree_right + 1 ; int preorder_subrighttree_right = preorder_right ; root -> left = myBuildTree ( map , preorder , inorder , preorder_sublefttree_left , preorder_sublefttree_right , inorder_sublefttree_left , inorder_sublefttree_right ); root -> right = myBuildTree ( map , preorder , inorder , preorder_subrighttree_left , preorder_subrighttree_right , inorder_subrighttree_left , inorder_subrighttree_right ); return root ; } } ; äºŒå‰æ ‘æœ€å¤§æ·±åº¦ åˆ†æ²»æ³•çš„è¿”å›çŠ¶æ€å®šä¹‰ï¼š å­æ ‘çš„æœ€å¤§æ·±åº¦ class Solution : def maxDepth ( self , root ): # end condition if not root : return 0 # divide & conquer leftDepth = self . maxDepth ( root . left ) rightDepth = self . maxDepth ( root . right ) # combineï¼šæ ¹èŠ‚ç‚¹çš„æœ€å¤§æ·±åº¦ = max(å·¦å­æ ‘æœ€å¤§æ·±åº¦ï¼Œå³å­æ ‘æœ€å¤§æ·±åº¦) + 1 res = max ( leftDepth , rightDepth ) + 1 # return result return res äºŒå‰æ ‘æœ€å°æ·±åº¦ åˆ†æ²»æ³•çš„è¿”å›çŠ¶æ€å®šä¹‰ï¼š å­æ ‘çš„æœ€å°æ·±åº¦ class Solution : def minDepth ( self , root : TreeNode ) -> int : # end condition if not root : return 0 if None in [ root . left , root . right ]: # éœ€è¦è®¨è®ºå·¦å³å­æ ‘ä¸ºç©ºçš„æƒ…å†µ # divide conquer leftDepth = self . minDepth ( root . left ) rightDepth = self . minDepth ( root . right ) # combine res = max ( leftDepth , rightDepth ) + 1 # return result return res else : # divide conquer leftDepth = self . minDepth ( root . left ) rightDepth = self . minDepth ( root . right ) # combine res = min ( leftDepth , rightDepth ) + 1 # return result return res å¹³è¡¡äºŒå‰æ ‘ åˆ†æ²»æ³•çš„è¿”å›çŠ¶æ€å®šä¹‰ï¼š å­æ ‘çš„æ˜¯å¦æ˜¯å¹³è¡¡äºŒå‰æ ‘å’Œå­æ ‘çš„æ·±åº¦ (bool, int) class Solution : def isBalanced ( self , root : TreeNode ) -> bool : balance , _ = self . helper ( root ) return balance def helper ( self , root ): # end condition if not root : return True , 0 # divide conquer leftBalance , leftDepth = self . helper ( root . left ) rightBalance , rightDepth = self . helper ( root . right ) # combine & return result if not leftBalance : return False , 0 if not rightBalance : return False , 0 return abs ( leftDepth - rightDepth ) <= 1 , max ( leftDepth , rightDepth ) + 1 äºŒå‰æœç´¢æ ‘ BST äºŒå‰æœç´¢æ ‘åŸºæœ¬æ€§è´¨ å®šä¹‰ï¼šå·¦å­æ ‘éƒ½æ¯”æ ¹èŠ‚ç‚¹å°ï¼Œå³å­æ ‘éƒ½ä¸å°äºæ ¹èŠ‚ç‚¹ã€‚å·¦å³å­æ ‘ä¹Ÿå¿…é¡»æ˜¯BSTã€‚å•èŠ‚ç‚¹æ ‘æ˜¯BSTã€‚ BSTçš„ä¸­åºéå†æ˜¯ ä¸é™åºåˆ— äºŒå‰æœç´¢æ ‘æœ€è¿‘å…¬å…±ç¥–å…ˆ class Solution : def lowestCommonAncestor ( self , root : 'TreeNode' , p : 'TreeNode' , q : 'TreeNode' ) -> 'TreeNode' : if not root : return None if root . val > p . val and root . val > q . val : return self . lowestCommonAncestor ( root . left , p , q ) if root . val < p . val and root . val < q . val : return self . lowestCommonAncestor ( root . right , p , q ) else : return root # åŒ…å«pæˆ–qå°±æ˜¯rootå’Œpï¼Œqåœ¨rootä¸¤è¾¹æƒ…å†µã€‚ äºŒå‰æ ‘çš„æœ€è¿‘å…¬å…±ç¥–å…ˆ æˆ‘ä»¬è‡ªåº•éƒ¨éå†ï¼Œä¸€æ—¦æˆ‘ä»¬åˆ°è¾¾ä¸€ä¸ªä¸ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹ä¸€åŒ¹é…çš„èŠ‚ç‚¹ï¼Œæˆ‘ä»¬å°±å°†å®ƒä¼ é€’ç»™å®ƒçš„çˆ¶èŠ‚ç‚¹ã€‚ å¦åˆ™ï¼Œåœ¨å·¦å³å­©å­ä¸­æŸ¥æ‰¾ï¼š - å¦‚æœå·¦å³å­©å­å‡è¿”å›ä¸€ä¸ªèŠ‚ç‚¹ï¼Œpå’Œqå­˜åœ¨ï¼Œrootå°±æ˜¯LCAã€‚ å¦‚æœåªæœ‰å…¶ä¸­ä¸€ä¸ªå­©å­è¿”å›ä¸€ä¸ªèŠ‚ç‚¹ï¼Œæ„å‘³ç€åœ¨å·¦æˆ–å³åˆ†æ”¯ä¸Šæ‰¾åˆ°pæˆ–qã€‚ å¦‚æœå·¦å³å­©å­å‡æ²¡è¿”å›èŠ‚ç‚¹ï¼Œåˆ™è¿”å›Noneã€‚ åªæœ‰ä¸€ä¸ªè¿”å›èŠ‚ç‚¹æƒ…å†µç†è§£ï¼šå‡è®¾åœ¨å·¦å­©å­è¿”å›pï¼Œå³å­©å­è¿”å›Noneã€‚è¿™æ„å‘³ç€qä½äºèŠ‚ç‚¹pä¸‹é¢çš„æŸå¤„ï¼Œå…¶ä¸­pè¢«å‘ç°æˆ‘ä»¬ä¸éœ€è¦ä¸€ç›´æœç´¢ï¼Œå› ä¸ºåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‰¾åˆ°pçš„èŠ‚ç‚¹æ˜¯LCAã€‚ åˆ†æ²»æ³•çš„è¿”å›çŠ¶æ€å®šä¹‰ï¼š æ‰¾åˆ°çš„ pèŠ‚ç‚¹ æˆ– qèŠ‚ç‚¹ class Solution : def lowestCommonAncestor ( self , root : 'TreeNode' , p : 'TreeNode' , q : 'TreeNode' ) -> 'TreeNode' : # end condition if root in [ None , p , q ]: return root # divide conquer left = self . lowestCommonAncestor ( root . left , p , q ) right = self . lowestCommonAncestor ( root . right , p , q ) # conbine & return result return root if left and right else left or right Same Tree class Solution : def isSameTree ( self , p , q ): if not p and not q : return True if not p or not q : return False if p . val != q . val : return False return self . isSameTree ( p . left , q . left ) and self . isSameTree ( p . right , q . right ) Subtree of Another Tree DST + DST class Solution : def isSubtree ( self , s : TreeNode , t : TreeNode ) -> bool : if not s and not t : return True if not s or not t : return False return self . isSameTree ( s , t ) or self . isSubtree ( s . left , t ) or self . isSubtree ( s . right , t ) Binary Tree Maximum Path Sum è¿”å›çŠ¶æ€çš„å®šä¹‰ï¼š maxPathSum , singlePathSum é¦–å…ˆï¼Œæƒ³ä¸€ä¸ªç®€åŒ–ç‰ˆ(single path)ï¼Œæ‰¾ä»rootåˆ°ä»»æ„ç‚¹å¾—æœ€å¤§å€¼ã€‚ç±»ä¼¼äºmaxDepthï¼Œæ¯æ¬¡åŠ root.valè€Œä¸å†æ˜¯+1 æ±‚å•è·¯çš„æ—¶å€™ï¼Œå¦‚æœrootåŠ å·¦å„¿å­å•è·¯æˆ–è€…å³å„¿å­å•è·¯æœ€åçš„å€¼éƒ½å°äº0ï¼Œåˆ™è¿”å›0ï¼Œæ„å‘³ç€ä¸è¦rootå¼€å§‹çš„è¿™ä¸ªå•è·¯äº† æœ¬é¢˜æ€è·¯ divide & conquer æ±‚æœ€å¤§è·¯å¾„å’Œå°±ç­‰äºä¸‹é¢ä¸‰ä¸ªå€¼çš„æœ€å¤§å€¼ï¼š å·¦å­æ ‘çš„æœ€å¤§è·¯å¾„å’Œ å³å­æ ‘çš„æœ€å¤§è·¯å¾„å’Œ å·¦å­æ ‘å•è·¯ + å³å­æ ‘å•è·¯ + root.val class Solution ( object ): def maxPathSum ( self , root ): if not root : return 0 res , _ = self . helper ( root ) return res def helper ( self , root ): if not root : return - 0x7fffffff , 0 left = self . helper ( root . left ) right = self . helper ( root . right ) singlePathSum = max ( left [ 1 ] + root . val , right [ 1 ] + root . val , 0 ) maxPathSum = max ( left [ 0 ], right [ 0 ], left [ 1 ] + right [ 1 ] + root . val ) return maxPathSum , singlePathSum æ€è·¯äºŒï¼š DFS ï¼Œè¿”å›çŠ¶æ€çš„å®šä¹‰ï¼š dfs(root)è¿”å›çš„æ˜¯åŒ…æ‹¬rootè¿™ä¸ªç»“ç‚¹çš„å•ä¸€è·¯å¾„ä¸Šçš„æœ€å¤§å€¼ã€‚ åˆ™å¯èƒ½çš„ç»“æœæœ‰ï¼š left + right +root.val (å·¦å³å­æ ‘å’Œæ ¹æ„æˆè·¯å¾„ä¸ºæœ€å¤§å€¼ï¼‰ max(left, right) + root.val(å·¦æˆ–è€…å³å­æ ‘å’Œæ ¹æ„æˆæœ€å¤§å€¼ï¼‰ root.valæœ¬èº«ä¸ºæœ€å¤§å€¼ å’Œå…¨å±€å˜é‡resæ¯”è¾ƒæ›´æ–°å³å¯ã€‚ éœ€è¦æ³¨æ„çš„æ˜¯dfsè¿”å›å€¼ï¼Œå¯èƒ½æ˜¯ max(left, right) + root.val æŸä¸€æ¡è·¯å¾„ root.val åªæ˜¯è¯¥ç»“ç‚¹ï¼ˆä¸‹é¢éƒ½æ˜¯è´Ÿçš„äº†ï¼‰ class Solution : def maxPathSum ( self , root : TreeNode ) -> int : if not root : return 0 self . res = - 0x7fffffff self . helper ( root ) return self . res def helper ( self , root : TreeNode ): if not root : return - 0x7fffffff left = self . helper ( root . left ) right = self . helper ( root . right ) if left + right + root . val > self . res : self . res = left + right + root . val if max ( left , right ) + root . val > self . res : self . res = max ( left , right ) + root . val if root . val > self . res : self . res = root . val return max ( max ( left , right ) + root . val , root . val )","tags":"Algorithms","url":"articles/Binary-Tree.html","loc":"articles/Binary-Tree.html"},{"title":"Auto-generated subtitles for any video","text":"Autosub Install ffmpeg Install autosub Usage Autosub Autosub is a utility for automatic speech recognition and subtitle generation. It takes a video or an audio file as input, performs voice activity detection to find speech regions, makes parallel requests to Google Web Speech API to generate transcriptions for those regions, (optionally) translates them to a different language, and finally saves the resulting subtitles to disk. It supports a variety of input and output languages (to see which, run the utility with the argument â€”list-languages) and can currently produce subtitles in either the SRT format or simple JSON . Install ffmpeg sudo add-apt-repository ppa:djcj/hybrid sudo apt-get update sudo apt-get install ffmpeg Install autosub pip install autosub Usage autosub -S en -D en file_path","tags":"Programming","url":"articles/Auto-generated-subtitles-for-any-video.html","loc":"articles/Auto-generated-subtitles-for-any-video.html"},{"title":"Using loguru and notifiers instead of logging","text":"Configuring loguru Recording logging from loguru import logger import tempfile import notifiers Configuring loguru def email ( file_path : str , to : list ): with open ( file_path , 'r' ) as file : msg = file . read () if not msg : return params = { \"subject\" : 'Title' , \"from\" : \"receivers@163.com\" , \"to\" : to , \"host\" : \"smtp.163.com\" , } notifier = notifiers . get_notifier ( \"email\" ) notifier . notify ( message = msg , ** params ) logger . add ( sys . stdout , level = \"DEBUG\" , format = FORMAT ) # output stdout if send_email : tmpfile = tempfile . NamedTemporaryFile () logger . add ( tmpfile . name , # output email level = \"WARNING\" , format = FORMAT , compression = email ( file_path = tmpfile . name , to = 'name@gmail.com' )) Recording logging logger . info ( '...' ) logger . debug ( '...' ) logger . warning ( '...' ) logger . error ( '...' )","tags":"Programming","url":"articles/Using-loguru-and-notifiers-instead-of-logging.html","loc":"articles/Using-loguru-and-notifiers-instead-of-logging.html"},{"title":"Checking DataFrame/Series missing values","text":"Checking DataFrame missing values Checking Series missing values has_missing method Checking DataFrame missing values cols_missing = frame.columns[frame.isna().any()] Checking Series missing values series.isna().any() has_missing method from loguru import logger import pandas as pd from pandas.core.frame import DataFrame from pandas.core.series import Series import traceback def has_missing ( self , values ): \"\"\"Check whether values have missing value. \"\"\" if isinstance ( values , DataFrame ): cols_missing = values . columns [ values . isna () . any ()] if not cols_missing . empty : logger . warning ( f 'The columns { \", \" . join ( cols_missing ) } contain missing values!' + '' . join ( traceback . format_stack ())) return if isinstance ( values , Series ): if values . isna () . any (): logger . warning ( f 'The { Series . name } Series contain missing values! \\n ' + '' . join ( traceback . format_stack ())) return raise ValueError ( 'The argument values requires a DataFrame or a Series.' )","tags":"Programming","url":"articles/Checking-DataFrame/Series-missing-values.html","loc":"articles/Checking-DataFrame/Series-missing-values.html"},{"title":"Binary Search","text":"äºŒåˆ†æŸ¥æ‰¾åˆçº§ï¼šäºŒåˆ†æ¨¡æ¿ Classical Binary Search Find First and Last Position of Target ( lower & upper Bound ) Search a 2D Matrix æ€»ç»“ äºŒåˆ†æŸ¥æ‰¾è¿›é˜¶ï¼šè½¬åŒ–ä¸ºäºŒåˆ†é—®é¢˜ Find Minimum in Rotated Sorted Array Find Minimum in Rotated Sorted Array II Search in Rotated Sorted Array II äºŒåˆ†æŸ¥æ‰¾é«˜é˜¶ï¼šHalf Find Peak Element äºŒåˆ†æŸ¥æ‰¾åˆçº§ï¼šäºŒåˆ†æ¨¡æ¿ Classical Binary Search æ•°ç»„å…ƒç´ æ— é‡å¤ class Solution : def search ( self , nums : List [ int ], target : int ) -> int : if not nums or len ( nums ) == 0 : return - 1 left , right = 0 , len ( nums ) - 1 while left + 1 < right : # ç›¸é‚»å³é€€å‡ºï¼Œé˜²æ­¢æŸäº›é—®é¢˜é€ æˆæ­»å¾ªç¯ã€‚ mid = left + (( right - left ) >> 1 ) if nums [ mid ] == target : # find target and return immediately due to no duplicated elements return mid elif target < nums [ mid ]: right = mid else : left = mid #if the target is not the mid, check the right and left if target == nums [ left ]: return left if target == nums [ right ]: return right return - 1 æ¨¡æ¿å››è¦ç´ ï¼š 1. left + 1 < right ç›¸é‚»æ—¶ç»“æŸ 2. left + ((right - left) >> 1) 3. nums[mid] == < > ä¸‰ç§æƒ…å†µè®¨è®º 4. nums[left] A[right] ? target 35. Search Insert Position 704. Binary Search Find First and Last Position of Target ( lower & upper Bound ) Targetæœ‰é‡å¤ï¼Œå…¶ä»–å…ƒç´ æ— é‡å¤ã€‚ class Solution : def searchRange ( self , nums : List [ int ], target : int ) -> List [ int ]: if not nums : return [ - 1 , - 1 ] lower , upper = - 1 , - 1 # lower left , right = 0 , len ( nums ) - 1 while left + 1 < right : mid = left + (( right - left ) >> 1 ) if target == nums [ mid ]: # targetæœ‰é‡å¤ï¼Œæ‰¾åˆ°targetä¸ç«‹å³é€€å‡ºã€‚ç”±äºæ‰¾ä¸‹ç•Œï¼Œæ‰€ä»¥ç§»åŠ¨rightæŒ‡é’ˆã€‚ right = mid elif target < nums [ mid ]: right = mid else : left = mid if target == nums [ right ]: lower = right if target == nums [ left ]: lower = left # upper left , right = 0 , len ( nums ) - 1 while left + 1 < right : mid = left + (( right - left ) >> 1 ) if target == nums [ mid ]: # targetæœ‰é‡å¤ï¼Œæ‰¾åˆ°targetä¸ç«‹å³é€€å‡ºã€‚ç”±äºæ‰¾ä¸Šç•Œï¼Œæ‰€ä»¥ç§»åŠ¨leftæŒ‡é’ˆã€‚ left = mid elif target < nums [ mid ]: right = mid else : left = mid if target == nums [ left ]: upper = left if target == nums [ right ]: upper = right return [ lower , upper ] 34. Find First and Last Position of Element in Sorted Array Search a 2D Matrix class Solution : def searchMatrix ( self , matrix , target : int ) -> bool : if not matrix or not matrix [ 0 ]: return False row , col = len ( matrix ), len ( matrix [ 0 ]) left , right = 0 , row * col - 1 while left + 1 < right : mid = left + (( right - left ) >> 1 ) i , j = mid // col , mid % col if matrix [ i ][ j ] < target : left = mid elif matrix [ i ][ j ] > target : right = mid else : return True i , j = left // col , left % col if matrix [ i ][ j ] == target : return True i , j = right // col , right % col if matrix [ i ][ j ] == target : return True return False æ€»ç»“ äºŒåˆ†æŸ¥æ‰¾çš„æœ¬è´¨æ˜¯ç¼©å°æœç´¢èŒƒå›´ï¼š åŒºé—´ç¼©å° ===> å‰©ä¸‹ä¸¤ä¸ªä¸‹æ ‡ ===> åˆ¤æ–­ä¸¤ä¸ªä¸‹æ ‡ æ—¶é—´å¤æ‚åº¦ T(n) = T(n/2) + O(1) = T(n/4) + O(1) + O(1) = T(n/8) + O(1) +O(1) +O(1) = T(1) + logn * O(1) = O(logn) O(1) æå°‘ O(logn) å‡ ä¹éƒ½æ˜¯äºŒåˆ†æ³• O(âˆšn) å‡ ä¹æ˜¯åˆ†è§£è´¨å› æ•° O(n) é«˜é¢‘ O(nlogn) ä¸€èˆ¬éƒ½å¯èƒ½è¦æ’åº O(n2) æ•°ç»„ï¼Œæšä¸¾ï¼ŒåŠ¨æ€è§„åˆ’ O(n3) æ•°ç»„ï¼Œæšä¸¾ï¼ŒåŠ¨æ€è§„åˆ’ O(2&#94;n) ä¸ç»„åˆæœ‰å…³çš„æœç´¢ combination O(n!) ä¸æ’åˆ—æœ‰å…³çš„æœç´¢ permutation æ¯” O(n) æ›´ä¼˜çš„æ—¶é—´å¤æ‚åº¦ï¼Œå‡ ä¹åªèƒ½æ˜¯ O(logn) çš„äºŒåˆ†æ³•ã€‚ç»éªŒä¹‹è°ˆï¼š æ ¹æ®æ—¶é—´å¤æ‚åº¦å€’æ¨ç®—æ³•æ˜¯é¢è¯•ä¸­çš„å¸¸ç”¨ç­–ç•¥ äºŒåˆ†æŸ¥æ‰¾è¿›é˜¶ï¼šè½¬åŒ–ä¸ºäºŒåˆ†é—®é¢˜ æŠŠå…·ä½“çš„é—®é¢˜è½¬å˜ä¸ºï¼š æ‰¾åˆ°æ•°ç»„ä¸­çš„ ç¬¬ä¸€ä¸ª/æœ€åä¸€ä¸ª æ»¡è¶³æŸä¸ªæ¡ä»¶çš„ä½ ç½®/å€¼ ã€‚ Find Minimum in Rotated Sorted Array æ•°ç»„æ²¡æœ‰é‡å¤å…ƒç´  class Solution : def findMin ( self , nums : List [ int ]) -> int : if not nums : return - 1 left , right = 0 , len ( nums ) - 1 if nums [ right ] > nums [ left ]: return nums [ left ] while left + 1 < right : mid = left + (( right - left ) >> 1 ) if nums [ mid ] < nums [ left ]: right = mid else : # nums[mid] > nums[left] ï¼Œ ä¸å­˜åœ¨nums[mid] == nums[left]æƒ…å†µã€‚ left = mid return min ( nums [ left ], nums [ right ]) 153. Find Minimum in Rotated Sorted Array Find Minimum in Rotated Sorted Array II æ•°ç»„åŒ…å« é‡å¤å…ƒç´  class Solution : def findMin ( self , nums : List [ int ]) -> int : if not nums : return - 1 left , right = 0 , len ( nums ) - 1 while left + 1 < right : mid = left + (( right - left ) >> 1 ) if nums [ mid ] < nums [ right ]: # ä¸å¯ä¸nums[left]æ¯”è¾ƒï¼Œ [1, 2, 3, 4, 5] right = mid elif nums [ mid ] > nums [ right ]: left = mid else : right -= 1 # é‡å¤å…ƒç´ ï¼Œä¿å®ˆç¼©å°rightç•Œ, é˜²æ­¢è¶Šè¿‡[3, 4]ã€‚ [5, 5, 5, 5, 3, 4, 5, 5, 5] return min ( nums [ left ], nums [ right ]) ### Search in Rotated Sorted Array - æ•°ç»„æ²¡æœ‰é‡å¤å…ƒç´  class Solution : def search ( self , nums : List [ int ], target : int ) -> int : if not nums : return - 1 left , right = 0 , len ( nums ) - 1 while left + 1 < right : mid = left + (( right - left ) >> 1 ) if nums [ mid ] == target : return mid if nums [ mid ] > nums [ left ]: # ç¡®å®šæœ‰åºçš„å­æ•°ç»„, [left, mid]æœ‰åº if nums [ left ] <= target < nums [ mid ]: # ç¡®å®štargetæ˜¯å¦åœ¨[left, mid]æœ‰åºå­æ•°ç»„ right = mid else : left = mid else : # ç¡®å®šæœ‰åºçš„å­æ•°ç»„, [mid, right]æœ‰åº if nums [ mid ] < target <= nums [ right ]: # ç¡®å®štargetæ˜¯å¦åœ¨[mid, right]æœ‰åºå­æ•°ç»„ left = mid else : # å¦åˆ™ï¼Œtargetåœ¨æ— åºå­æ•°ç»„ right = mid if target == nums [ left ]: return left if target == nums [ right ]: return right return - 1 33. Search in Rotated Sorted Array Search in Rotated Sorted Array II æ•°ç»„åŒ…å« é‡å¤å…ƒç´  class Solution : def search ( self , nums : List [ int ], target : int ) -> int : if not nums : return False left , right = 0 , len ( nums ) - 1 while left + 1 < right : mid = left + (( right - left ) >> 1 ) if target == nums [ mid ]: return True if nums [ mid ] > nums [ left ]: # ç¡®å®šæœ‰åºçš„å­æ•°ç»„, [left, mid]æœ‰åº if nums [ left ] <= target < nums [ mid ]: # ç¡®å®štargetæ˜¯å¦åœ¨[left, mid]æœ‰åºå­æ•°ç»„ right = mid else : left = mid elif nums [ mid ] < nums [ left ]: # ç¡®å®šæœ‰åºçš„å­æ•°ç»„, [mid, right]æœ‰åº if nums [ mid ] < target <= nums [ right ]: # ç¡®å®štargetæ˜¯å¦åœ¨[mid, right]æœ‰åºå­æ•°ç»„ left = mid else : # å¦åˆ™ï¼Œtargetåœ¨æ— åºå­æ•°ç»„ right = mid else : # nums[mid] == nums[left] left += 1 if target == nums [ left ]: return True if target == nums [ right ]: return True return False 81. Search in Rotated Sorted Array II äºŒåˆ†æŸ¥æ‰¾é«˜é˜¶ï¼šHalf Find Peak Element Conditions: array length is 1 -> return the only index array length is 2 -> return the bigger number's index array length is bigger than 2 -> (1) find mid, compare it with its left and right neighbors (2) return mid if nums[mid] greater than both neighbors (3) take the right half array if nums[mid] smaller than right neighbor (4) otherwise, take the left half class Solution : def findPeakElement ( self , nums : List [ int ]) -> int : if not nums : return - 1 left , right = 0 , len ( nums ) - 1 while left + 1 < right : mid = left + (( right - left ) >> 1 ) if nums [ mid ] > nums [ mid - 1 ] and nums [ mid ] > nums [ mid + 1 ]: return mid if nums [ mid ] < nums [ mid - 1 ]: right = mid elif nums [ mid ] < nums [ mid + 1 ]: left = mid return left if nums [ left ] > nums [ right ] else right","tags":"Algorithms","url":"articles/Binary-Search.html","loc":"articles/Binary-Search.html"},{"title":"Python email","text":"import smtplib from email.mime.text import MIMEText from email.mime.multipart import MIMEMultipart from email.mime.image import MIMEImage #è®¾ç½®ç™»å½•åŠæœåŠ¡å™¨ä¿¡æ¯ mail_host = 'smtp.163.com' mail_user = 'jerrylsu' mail_pass = input ( 'è¾“å…¥æˆæƒç 102ï¼š' ) # æˆæƒç ï¼Œ éå¯†ç  sender = 'jerrylsu@163.com' receivers = [ 'sa517301@mail.ustc.edu.cn' ] #è®¾ç½®eamilä¿¡æ¯ #æ·»åŠ ä¸€ä¸ªMIMEmultipartç±»ï¼Œå¤„ç†æ­£æ–‡åŠé™„ä»¶ message = MIMEMultipart () message [ 'From' ] = sender message [ 'To' ] = receivers [ 0 ] message [ 'Subject' ] = 'title' #æ¨èä½¿ç”¨htmlæ ¼å¼çš„æ­£æ–‡å†…å®¹ï¼Œè¿™æ ·æ¯”è¾ƒçµæ´»ï¼Œå¯ä»¥é™„åŠ å›¾ç‰‡åœ°å€ï¼Œè°ƒæ•´æ ¼å¼ç­‰ with open ( 'Python-logging.md' , 'r' ) as f : content = f . read () #è®¾ç½®htmlæ ¼å¼å‚æ•° part1 = MIMEText ( content , 'html' , 'utf-8' ) #å°†å†…å®¹é™„åŠ åˆ°é‚®ä»¶ä¸»ä½“ä¸­ message . attach ( part1 ) #ç™»å½•å¹¶å‘é€ try : # SMTPæœåŠ¡å™¨è®¾ç½®(åœ°å€,ç«¯å£): server = smtplib . SMTP_SSL ( mail_host , 465 ) # server.set_debuglevel(1) # è¿æ¥SMTPæœåŠ¡å™¨(å‘ä»¶äººåœ°å€, å®¢æˆ·ç«¯æˆæƒå¯†ç ) server . login ( mail_user , mail_pass ) server . sendmail ( sender , receivers , message . as_string ()) print ( 'Send success!' ) except smtplib . SMTPException as e : print ( 'Error' , e ) finally : # é€€å‡ºSMTPæœåŠ¡å™¨ server . quit () #========================================================================= # åŠ å¯†SMTP # # ä½¿ç”¨æ ‡å‡†çš„25ç«¯å£è¿æ¥SMTPæœåŠ¡å™¨æ—¶ï¼Œä½¿ç”¨çš„æ˜¯æ˜æ–‡ä¼ è¾“ï¼Œå‘é€é‚®ä»¶çš„æ•´ä¸ªè¿‡ç¨‹å¯èƒ½ä¼šè¢«çªƒå¬ã€‚è¦æ›´å®‰å…¨åœ°å‘é€é‚®ä»¶ï¼Œå¯ä»¥åŠ å¯†SMTPä¼šè¯ï¼Œå®é™…ä¸Šå°±æ˜¯å…ˆåˆ›å»ºSSLå®‰å…¨è¿æ¥ï¼Œç„¶åå†ä½¿ç”¨SMTPåè®®å‘é€é‚®ä»¶ã€‚ #========================================================================= from email import encoders from email.header import Header from email.mime.base import MIMEBase from email.mime.multipart import MIMEMultipart from email.mime.text import MIMEText from email.utils import parseaddr , formataddr , formatdate import smtplib # return Alias_name <xxxx@example.com> def _format_addr ( s ): name , addr = parseaddr ( s ) return formataddr (( Header ( name , 'utf-8' ) . encode (), addr )) # æ¥æ”¶å‚æ•°: å‘ä»¶äººåœ°å€ from_addr = 'ä½ çš„é‚®ç®±åœ°å€' # æ¥æ”¶å‚æ•°: å®¢æˆ·ç«¯æˆæƒå¯†ç  passwd = 'ä½ çš„å®¢æˆ·ç«¯æˆæƒå¯†ç ' # æ¥æ”¶å‚æ•°: æ”¶ä»¶äººåœ°å€,å¯å¤šä¸ª to_addrs = [ 'ex@qq.com' , 'ex@163.com' , 'ex@gmail.com' ] # æ¥æ”¶å‚æ•°: SMTPæœåŠ¡å™¨(æ³¨æ„:æ˜¯å‘ä»¶äººçš„smtpæœåŠ¡å™¨) smtp_server = 'smtp.126.com' # æ¥æ”¶å‚æ•°: é‚®ä»¶ä¸»é¢˜ subject = 'äººç”Ÿè‹¦çŸ­' # æ¥æ”¶å‚æ•°: é‚®ä»¶æ­£æ–‡ plain = 'æˆ‘ç”¨python!' # å¸¦é™„ä»¶é‚®ä»¶ # æŒ‡å®šsubtypeä¸ºalternativeï¼ŒåŒæ—¶æ”¯æŒhtmlå’Œplainæ ¼å¼ msg = MIMEMultipart ( 'alternative' ) # é‚®ä»¶æ­£æ–‡ä¸­æ˜¾ç¤ºå›¾ç‰‡ï¼ŒåŒæ—¶é™„ä»¶çš„å›¾ç‰‡å°†ä¸å†æ˜¾ç¤º # plain = 'Hello world and hello me!' msg . attach ( MIMEText ( str ( plain ), 'plain' , 'utf-8' )) # çº¯æ–‡æœ¬ # html = '<html><body><h1>Hello</h1><p><img src=\"cid:0\"></p></body></html>' # msg.attach(MIMEText(html, 'html', 'utf-8')) # HTML # æ·»åŠ é™„ä»¶ï¼šå³å…³è”ä¸€ä¸ªMIMEBaseï¼Œå›¾ç‰‡ä¸ºæœ¬åœ°è¯»å– with open ( '/home/uxeix/Pictures/icon/favicon (Jianshu).ico' , 'rb' ) as f : # è®¾ç½®é™„ä»¶ä¸­çš„MIMEå’Œæ–‡ä»¶å mime = MIMEBase ( 'image' , 'jpeg' , filename = 'hot.jpg' ) # åŠ ä¸Šå¿…è¦çš„å¤´ä¿¡æ¯ mime . add_header ( 'Content-Disposition' , 'attachment' , filename = 'hot.jpg' ) mime . add_header ( 'Content-ID' , '<0>' ) mime . add_header ( 'X-Attachment-Id' , '0' ) # æŠŠé™„ä»¶çš„å†…å®¹è¯»è¿›æ¥ mime . set_payload ( f . read ()) # ç”¨Base64ç¼–ç  encoders . encode_base64 ( mime ) # æ·»åŠ åˆ°MIMEMultipart msg . attach ( mime ) # æœªæŒ‡å®šç”¨æˆ·åˆ«åï¼Œåˆ™å®¢æˆ·ç«¯ä¼šè‡ªåŠ¨æå–é‚®ä»¶åœ°å€ä¸­çš„åç§°ä½œä¸ºé‚®ä»¶çš„ç”¨æˆ·åˆ«å msg [ 'From' ] = _format_addr ( from_addr ) # msg['To'] = _format_addr(to_addrs) msg [ 'To' ] = ' %s ' % ',' . join ([ _format_addr ( '< %s >' % to_addr ) for to_addr in to_addrs ]) msg [ 'Subject' ] = Header ( str ( subject ), 'utf-8' ) . encode () msg [ 'Date' ] = formatdate () #========================================================================= # å‘é€é‚®ä»¶ #========================================================================= try : # SMTPæœåŠ¡å™¨è®¾ç½®(åœ°å€,ç«¯å£): server = smtplib . SMTP_SSL ( smtp_server , 465 ) # server.set_debuglevel(1) # è¿æ¥SMTPæœåŠ¡å™¨(å‘ä»¶äººåœ°å€, å®¢æˆ·ç«¯æˆæƒå¯†ç ) server . login ( from_addr , passwd ) # å‘é€é‚®ä»¶ server . sendmail ( from_addr , to_addrs , msg . as_string ()) print ( 'é‚®ä»¶å‘é€æˆåŠŸ' ) except smtplib . SMTPException as e : print ( e ) print ( 'é‚®ä»¶å‘é€å¤±è´¥' ) finally : # é€€å‡ºSMTPæœåŠ¡å™¨ server . quit ()","tags":"Programming","url":"articles/Python-email.html","loc":"articles/Python-email.html"},{"title":"Python logging","text":"loggingæ€»ç»“ Loggerï¼šè®°å½•å™¨ï¼Œæš´éœ²å‡½æ•°ç»™åº”ç”¨ç¨‹åºï¼ŒåŸºäºæ—¥å¿—è®°å½•å™¨å’Œè¿‡æ»¤å™¨çº§åˆ«å†³å®šå“ªäº›æ—¥å¿—æœ‰æ•ˆã€‚ Handler ï¼šå¤„ç†å™¨, å°†(æ—¥å¿—è®°å½•å™¨äº§ç”Ÿçš„)æ—¥å¿—è®°å½•å‘é€è‡³åˆé€‚çš„ç›®çš„åœ°ã€‚ Filter ï¼šè¿‡æ»¤å™¨, æä¾›äº†æ›´å¥½çš„ç²’åº¦æ§åˆ¶,å®ƒå¯ä»¥å†³å®šè¾“å‡ºå“ªäº›æ—¥å¿—è®°å½•ã€‚ Formatterï¼šæ ¼å¼åŒ–å™¨, æŒ‡æ˜äº†æœ€ç»ˆè¾“å‡ºä¸­æ—¥å¿—è®°å½•çš„å¸ƒå±€ã€‚ import logging from logging import handlers import sys if True : # 1. åˆ›å»ºè®°å½•å™¨ logger = logging . getLogger () logger . setLevel ( logging . INFO ) # logæ—¥å¿—æ€»å¼€å…³ï¼Œé»˜è®¤WARNINGçº§ # 2. åˆ›å»ºhandler # 2.1. è¾“å‡ºåˆ°ç»ˆç«¯ console = logging . StreamHandler ( sys . stdout ) # é…ç½®æ—¥å¿—è¾“å‡ºåˆ°æ§åˆ¶å° console . setLevel ( logging . WARNING ) # è®¾ç½®è¾“å‡ºåˆ°æ§åˆ¶å°çš„æœ€ä½æ—¥å¿—çº§åˆ« # 2.2. è¾“å‡ºåˆ°æ–‡ä»¶ file_logging = logging . FileHandler ( \"example.log\" ) # é…ç½®æ—¥å¿—è¾“å‡ºåˆ°æ–‡ä»¶ file_logging . setLevel ( logging . INFO ) # 2.3. å’Œä¸Šé¢çš„FIleHandlerå·®ä¸å¤šï¼Œåªæ˜¯handlerå¯¹è±¡å¯ä»¥ç®¡ç†æ–‡ä»¶å¤§å°ï¼Œå½“æ–‡ä»¶å¤§äºæŒ‡å®šçš„å¤§å°åï¼Œä¼šè‡ªåŠ¨å°†å½“å‰æ–‡ä»¶æ”¹åï¼Œç„¶åé‡æ–°åˆ›å»ºä¸€ä¸ªæ–°çš„åŒåæ–‡ä»¶ç»§ç»­è¾“å‡º # file_rotating_file = handlers.RotatingFileHandler(\"cat.log\",maxBytes=1024,backupCount=3) # file_rotating_file.setLevel(logging.INFO) # 2.4. å’Œä¸Šé¢çš„handleræœ‰ç‚¹ç±»ä¼¼ï¼Œä¸è¿‡ï¼Œå®ƒæ˜¯é€šè¿‡åˆ¤æ–­æ–‡ä»¶å¤§å°æ¥å†³å®šä½•æ—¶é‡æ–°åˆ›å»ºæ—¥å¿—æ–‡ä»¶ï¼Œè€Œæ˜¯é—´éš”ä¸€å®šçš„æ—¶å€™è‡ªåŠ¨åˆ›å»ºæ—¥å¿—æ–‡ä»¶ã€‚ä»£è¡¨æ¯7å¤©å¤‡ä»½æ–‡ä»¶ # file_time_rotating = handlers.TimedRotatingFileHandler(\"app.log\",when=\"s\",interval=10,backupCount=5) # file_time_rotating.setLevel(logging.INFO) # 2.5. è¾“å‡ºåˆ°é‚®ä»¶ # STMPHandler = logging.handlers.SMTPHandler(mailhost=('smtp.163.com', 25), # fromaddr='jerrylsu@163.com', # toaddrs=['sa517301@mail.ustc.edu.cn'], # subject='Data - Issues', # credentials=('jerrylsu','xinyu102')) # STMPHandler.setLevel(logging.WARNING) # 3. åˆ›å»ºæ ¼å¼åŒ–å™¨ formatter = logging . Formatter ( fmt = \" %(asctime)s %(filename)s [line: %(lineno)d ] %(levelname)s - %(message)s \" , datefmt = \"%m/ %d /%Y %I:%M:%S %p\" ) # åˆ›å»ºä¸€ä¸ªæ ¼å¼åŒ–å¯¹è±¡ console . setFormatter ( formatter ) # è®¾ç½®æ ¼å¼ file_logging . setFormatter ( formatter ) # file_rotating_file.setFormatter(formatter) # file_time_rotating.setFormatter(formatter) # STMPHandler.setFormatter(FORMATTER) # 4. æ·»åŠ å¤„ç†å™¨ logger . addHandler ( console ) logger . addHandler ( file_logging ) # logger.addHandler(file_rotating_file) # logger.addHandler(file_time_rotating) # logger.addHandler(STMPHandler) # 5. ç”¨æˆ·ä½¿ç”¨ logger . debug ( \"debug\" ) logger . info ( \"info\" ) logger . warning ( \"warning\" ) logger . error ( \"error\" ) logger . critical ( \"critical message\" ) logè¾“å‡ºåˆ°æ–‡ä»¶é™¤äº†ä¸Šé¢çš„æ–¹å¼ï¼Œè¿˜æœ‰ä¸€ç§ä¾¿æ·çš„æ–¹å¼ï¼šåŸºäº StreamHandler å’Œé‡å®šä½ç¬¦ > ã€‚ $ python3 script.py --argv > log_path è¾“å‡ºåˆ°ç»ˆç«¯çš„logæ•°æ®ï¼Œé‡å®šä½åˆ°logæ–‡ä»¶ä¸­ã€‚","tags":"Programming","url":"articles/Python-logging.html","loc":"articles/Python-logging.html"},{"title":"Spark SQL Join","text":"Join in Hive Common Join Map Join Skewed Join Bucket Join Join in Spark SQL Map Join Broadcast Map Join Join in Hive Common Join åœ¨HiveæŸ¥è¯¢çš„æ€§èƒ½è°ƒä¼˜æœŸé—´ï¼Œéœ€è¦æ³¨æ„çš„ä¸€ä¸ªæ–¹é¢æ˜¯æ‰§è¡ŒæœŸé—´çš„joinçš„ç±»å‹ã€‚ Common Joinæ˜¯Hiveä¸­çš„é»˜è®¤joinç±»å‹ï¼Œä¹Ÿç§°ä¸ºShuffle Join, Distributed Join, Sort Merged Join ã€‚ åœ¨joinæœŸé—´ï¼Œä¸¤ä¸ªè¡¨ä¸­çš„æ‰€æœ‰è¡Œéƒ½å°†æ ¹æ®join keyåˆ†å‘åˆ°æ‰€æœ‰èŠ‚ç‚¹ï¼Œæ¥è‡ªç›¸åŒjoin keyçš„å€¼æœ€ç»ˆåœ¨åŒä¸€èŠ‚ç‚¹ä¸Šã€‚ 1. In the map stage, mappers reads the tables and output the join-column value as the key. The key-value pairs are written into an intermediate file. 2. In the shuffle stage, these pairs are sorts and merged. All rows from the same key will be sent to the same reducer instance. 3. In the reduce stage, reducer gets the sorted data and performs the join. ä¼˜ç‚¹ï¼šé€‚ç”¨äºä»»ä½•å¤§å°çš„è¡¨ ç¼ºç‚¹ï¼š1. shuffleæ“ä½œä»£ä»·é«˜ï¼Œæ¶ˆè€—ç½‘ç»œèµ„æºã€‚ 2. å­˜åœ¨å…¸å‹æ•°æ®å€¾æ–œé—®é¢˜ã€‚å¦‚æœjoin keyæ•°æ®åˆ†å¸ƒä¸å‡åŒ€ï¼Œåˆ™ç›¸å…³çš„reducersä¼šæ•°æ®è¿‡è½½ï¼Œå¯¼è‡´å¤šæ•°reducerså·²ç»å®Œæˆjoinæ“ä½œï¼Œè€Œå°éƒ¨åˆ†reducersä»åœ¨æ‰§è¡Œjoinæ“ä½œã€‚æ•´ä½“çš„è¿è¡Œæ—¶é—´å–å†³äºå°éƒ¨åˆ†reducersã€‚ Common Join Map Join Broadcast join is called Map Join in Hive. Common joinæ•°æ®shuffleä»£ä»·æ¯”è¾ƒé«˜ã€‚ä¸ºäº†åŠ é€ŸHiveæŸ¥è¯¢ï¼Œå¯ä»¥ä½¿ç”¨Map Joinã€‚ Map Joinä½¿ç”¨å‡†åˆ™ï¼šå¦‚æœjoinæ“ä½œä¸­ï¼Œå­˜åœ¨å¯ä»¥è£…å…¥å†…å­˜çš„å°è¡¨å³å¯ã€‚ åœ¨joinæœŸé—´ï¼Œä¸¤ä¸ªè¡¨ä¸­çš„æ‰€æœ‰è¡Œéƒ½å°†æ ¹æ®join keyåˆ†å‘åˆ°æ‰€æœ‰èŠ‚ç‚¹ï¼Œæ¥è‡ªç›¸åŒjoin keyçš„å€¼æœ€ç»ˆåœ¨åŒä¸€èŠ‚ç‚¹ä¸Šã€‚ 1. Map Joinçš„ç¬¬ä¸€æ­¥æ˜¯åœ¨åŸå§‹Map Reduceä»»åŠ¡ä¹‹å‰åˆ›å»ºMap Reduceæœ¬åœ°ä»»åŠ¡,æ­¤map/reduceä»»åŠ¡ä»HDFSè¯»å–å°è¡¨çš„æ•°æ®å¹¶å°†å…¶ä¿å­˜åˆ°å†…å­˜ä¸­çš„å“ˆå¸Œè¡¨ä¸­,ç„¶åä¿å­˜åˆ°å“ˆå¸Œè¡¨æ–‡ä»¶ä¸­ã€‚ 2. å½“åŸå§‹join Map Reduceä»»åŠ¡å¯åŠ¨æ—¶ï¼Œå®ƒä¼šå°†å“ˆå¸Œè¡¨æ–‡ä»¶ç§»åŠ¨åˆ°Hadoopåˆ†å¸ƒå¼ç¼“å­˜(è¿™å°†æŠŠå“ˆå¸Œè¡¨æ–‡ä»¶å¡«å……åˆ°æ¯ä¸ªmapperçš„æœ¬åœ°ç£ç›˜,å³å¹¿æ’­broadcast)ã€‚ å¯¹äºå…·æœ‰å¤§è¡¨Aå’Œå°è¡¨Bçš„è¿æ¥ï¼Œå¯¹äºè¡¨Açš„æ¯ä¸ªæ˜ å°„å™¨ï¼Œå®Œå…¨è¯»å–è¡¨Bã€‚å½“è¾ƒå°çš„è¡¨è¢«åŠ è½½åˆ°å†…å­˜ä¸­ç„¶ååœ¨MapReduceä½œä¸šçš„mapé˜¶æ®µä¸­æ‰§è¡Œjoinæ—¶ï¼Œä¸éœ€è¦reducerå¹¶ä¸”è·³è¿‡reduceé˜¶æ®µã€‚Map Joinæ¯”å¸¸è§„é»˜è®¤joinæ‰§è¡Œå¾—æ›´å¿«ã€‚ There are two ways to enable MapJoin in Hive. /*+ MAPJOIN(aliasname), MAPJOIN(anothertable) */ ç±»ä¼¼äºCè¯­è¨€æ³¨é‡Šï¼Œç´§è·Ÿç€æ”¾åœ¨ SELECT ä¹‹åï¼ŒæŒ‡ç¤ºHiveå°†aliasnameè¡¨åŠ è½½å¦‚å†…å­˜ã€‚ ä½¿ç”¨æç¤ºä½¿ç”¨Map JoinæŒ‡å®šæŸ¥è¯¢ã€‚ä¸‹é¢çš„ç¤ºä¾‹æ˜¾ç¤ºè¾ƒå°çš„è¡¨ b æ˜¯æ”¾åœ¨æç¤ºä¸­çš„è¡¨ï¼Œå¹¶å¼ºåˆ¶æ‰‹åŠ¨ç¼“å­˜è¡¨Bã€‚ Select /*+ MAPJOIN(b) */ a.key, a.value from a join b on a.key = b.key You can force BroadcastHashJoin using SQL 's BROADCAST hint. Supported hints include BROADCAST , BROADCASTJOIN or MAPJOIN . va q = \"\"\" select /* + broadcast (I) */ C.* from dw_cmc_instnc_chdu I join dw_cmc_cntct C where C.dt >= '20150101' \"\"\" val qBroadcastRight = \"\"\" SELECT /*+ MAPJOIN (rt) */ * FROM range(100) lf inner join range(1000) rt WHERE lf.id = rt.id \"\"\" Map Join Skewed Join Skewed Join Bucket Join Bucket Join Join in Spark SQL SparkSQLæ”¯æŒä¸‰ç§Joinç®—æ³•: - shuffle map join - broadcast map join - sort merge join Map Join Map Join in Hive Map Joinæ—¶é—´å¤æ‚åº¦O(m + n), ç¬›å¡å°”é›†è¿ç®—O(m * n) Broadcast Hash Join & Shuffle Hash Join Broadcast Map Join broadcast-join-with-spark import org.apache.spark.sql.functions.broadcast def broadcast [ T ]( df : Dataset [ T ]): Dataset [ T ] Marks a DataFrame as small enough for use in broadcast joins . The following example marks the right DataFrame for broadcast hash join using joinKey . // left and right are DataFrames left_large_dataframe . join ( broadcast ( right_small_dataframe ), \"joinKey\" ) optimizing-apache-spark-sql-joins Broadcast Hash Join","tags":"Programming","url":"articles/Spark SQL Join.html","loc":"articles/Spark SQL Join.html"},{"title":"Spark: Shuffling and Partitioning","text":"Shuffling org.apache.spark.rdd. RDD [(String, Int)]= ShuffledRDD[366] Grouping and Reducing, Example Reminder: Latency Grouping and Reducing, Example - Optimized groupByKey and reduceByKey Running Times Shuffling Partitioning Partitions Hash partitioning Hash Partitioning: Example Range partitioning Range Partitioning: Example Partitioning Data Partitioning Data: partitionBy Shuffling org.apache.spark.rdd. RDD [(String, Int)]= ShuffledRDD[366] Think again what happens when you have to do a groupBy or a groupByKey. Remember our data is distributed! Did you notice anything odd? val pairs = sc . parallelize ( List (( 1 , \"one\" ), ( 2 , \"two\" ), ( 3 , \"three\" ))) pairs . groupByKey () // res2 : org . apache . spark . rdd . RDD [ (Int, Iterable[String ] ) ] // = ShuffledRDD [ 16 ] at groupByKey at < console > : 37 We typically have to move data from one node to another to be \"grouped with\" its key. Doing this is called \"shuffling\". Shuffles Happen Shuffles can be an enormous hit to because it means that Spark must send data from one node to another. Why? Latency! Grouping and Reducing, Example Let's start with an example. Given: case class CFFPurchase(customerid: Int, destination: String, price: Double) å‡è®¾æˆ‘ä»¬æœ‰ç‘å£«ç«è½¦å…¬å¸ï¼ˆ CFF ï¼‰ç§»åŠ¨åº”ç”¨ç¨‹åºç”¨æˆ·åœ¨è¿‡å»ä¸€ä¸ªæœˆå†…è´­ä¹°çš„æ•°æ®é›†RDDã€‚ val purchasesRdd: RDD[CFFPurchaseJ = sc.textFile( ... ) ç›®æ ‡ï¼šæ¯ä¸ªå®¢æˆ·åœ¨è¿™ä¸ªæœˆå†…çš„æ—…è¡Œæ¬¡æ•°å’ŒèŠ±è´¹é‡‘é¢ã€‚ val purchasesRdd: RDD[CFFPurchaseJ = sc.textFile( ... ) // Returns: Array[(Int, (Int, Double))] val purchasesPerMonth = purchasesRdd.map(p => (p.customerld, p.price)) // Pair RDD .groupByKey() // groupByKey returns RDD[(K, Iterable[VJ )J .map(p => (p._1, (p._2.size, p._2.sum))) .collect() An example dataset: val purchases = List(CFFPurchase(100, \"Geneva\", 22.25), CFFPurchase (300, ''Zurich'', 42. 10), CFFPurchase(100, \"Fribourg\", 12.40), CFFPurchase (200, ''St. Gallen'', 8. 20), CFFPurchase(100, ''Lucerne'', 31.60), CFFPurchase (300, ''Basel'', 16. 20)) æ³¨æ„ï¼š groupByKey ä¼šä¸ºæ¯ä¸ª Key ç”Ÿæˆä¸€ä¸ªé”®å€¼å¯¹ã€‚ ä¸”å•ä¸ªé”®å€¼å¯¹ä¸èƒ½è·¨è¶Šå¤šä¸ª worker èŠ‚ç‚¹ã€‚ Reminder: Latency å¦‚æœä¸æ˜¯ç»å¯¹å¿…è¦ï¼Œæˆ‘ä»¬ä¸å¸Œæœ›é€šè¿‡ç½‘ç»œå‘é€æ‰€æœ‰æ•°æ®ã€‚ å¤ªå¤šçš„ç½‘ç»œé€šä¿¡ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚ å¦‚ä½•ä¼˜åŒ–ï¼Ÿæˆ–è®¸æˆ‘ä»¬æ²¡æœ‰å¿…è¦é€šè¿‡ç½‘ç»œå‘é€æ‰€æœ‰çš„é”®å€¼å¯¹ã€‚ä¹Ÿè®¸æˆ‘ä»¬å¯ä»¥åœ¨shuffleä¹‹å‰å‡å°‘ã€‚ è¿™å¯ä»¥å¤§å¤§å‡å°‘æˆ‘ä»¬å¿…é¡»é€šè¿‡ç½‘ç»œå‘é€çš„æ•°æ®é‡ã€‚ Grouping and Reducing, Example - Optimized ä¼˜åŒ–ï¼šä½¿ç”¨ reduceByKey . ä»æ¦‚å¿µä¸Šè®²ï¼Œ reduceByKey å¯ä»¥è¢«è®¤ä¸ºæ˜¯ï¼š 1. é¦–å…ˆæ‰§è¡Œ groupByKey 2. ç„¶å reduce æ¯ä¸ªé”®åˆ†ç»„çš„æ‰€æœ‰å€¼çš„ç»„åˆ ç„¶è€Œï¼Œ reduceByKey æ¯”å•ç‹¬ä½¿ç”¨ groupByKey å’Œ reduce æ›´æœ‰æ•ˆã€‚ Signature: def reduceByKey(func: (V, V) => V): RDD[(K, V)] val purchasesRdd: RDD[CFFPurchaseJ = sc.textFile( ... ) val purchasesPerMonth = purchasesRdd.map(p => (p.customerld, (1, p.price))) // Pair ROD .reduceByKey( ... ) //? æ³¨æ„ï¼šä¼ é€’ç»™ map çš„å‡½æ•°å˜ä¸º p => (p.customerld, (1, p.price)) ä¼ é€’ç»™ reduceByKey æ€æ ·çš„å‡½æ•°å¯ä»¥è¿”å›è¿™æ ·å½¢å¼çš„ç»“æœ (customerid, (numTrips, totalSpent)) ï¼Ÿ val purchasesPerMonth = purchasesRdd.map(p => (p.customerld, (1, p.price))) // Pair ROD .reduceByKey((v1, v2) => (v1 ._1 + v2._1, v1 ._2 + v2._2)) .collect() 1. map 2. reduceByKey reduce on mapper side first ! ä»è€Œå‡å°‘äº†ç”¨äº shuffle çš„ key-value pairs æ•°æ®é‡ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š 3. reduce again after shuffle reduceByKey æ–¹æ³•æœ‰ä»€ä¹ˆå¥½å¤„ï¼Ÿ é€šè¿‡é¦–å…ˆå‡å°‘æ•°æ®é›†ï¼Œåœ¨ shuffle æœŸé—´é€šè¿‡ç½‘ç»œå‘é€çš„æ•°æ®é‡å¤§å¤§å‡å°‘ã€‚è¿™å¯èƒ½ä¼šå¯¼è‡´æ€§èƒ½ä¸Šçš„é‡å¤§æ”¹è¿›ï¼ groupByKey and reduceByKey Running Times åœ¨çœŸå®é›†ç¾¤ä¸Šè¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼š Shuffling å›æƒ³ä¸€ä¸‹ä½¿ç”¨ groupByKey çš„ç¤ºä¾‹ï¼š val purchasesPerCust = purchasesRdd.map(p => (p.customerld, p.price)) // Pair RDD .groupByKey() Grouping all values of key-value pairs with the same key requires collecting all key-value pairs with the same key on the same machine. Shuffling äº§ç”Ÿçš„åŸå› æ˜¯ï¼šå°†ä¸ Key ç›¸å…³çš„æ‰€æœ‰ Value ç§»åˆ°åŒä¸€å°æœºå™¨ä¸Šï¼Œä»è€Œå¯¼è‡´æ•°æ®åœ¨ç½‘ç»œä¸­ Shuffle ã€‚ ä½†æ˜¯Sparkæ€ä¹ˆçŸ¥é“å“ªä¸ª Key æ”¾åœ¨å“ªå°æœºå™¨ä¸Šå‘¢ï¼Ÿ - é»˜è®¤æƒ…å†µä¸‹ï¼ŒSparkä½¿ç”¨ hash partitioning æ¥ç¡®å®šå“ªä¸ª Key åº”è¯¥å°†å¯¹å‘é€åˆ°å“ªå°æœºå™¨ã€‚ Partitioning Partitions RDDä¸­çš„æ•°æ®è¢«åˆ†æˆè‹¥å¹²ä¸ªåˆ†åŒºã€‚ åˆ†åŒºå±æ€§ï¼š - åˆ†åŒºæ°¸è¿œä¸ä¼šè·¨è¶Šå¤šå°æœºå™¨ï¼Œå³åŒä¸€åˆ†åŒºä¸­çš„å…ƒç»„ä¿è¯åœ¨åŒä¸€å°æœºå™¨ä¸Šã€‚ - ç¾¤é›†ä¸­çš„æ¯å°è®¡ç®—æœºéƒ½åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªåˆ†åŒºã€‚ - è¦ä½¿ç”¨çš„åˆ†åŒºæ•°æ˜¯å¯é…ç½®çš„ã€‚ é»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒç­‰äºæ‰€æœ‰ executor èŠ‚ç‚¹ä¸Šçš„å†…æ ¸æ€»æ•°ã€‚ Sparkä¸­æä¾›ä¸¤ç§åˆ†åŒºï¼š - æ•£åˆ—åˆ†åŒºHash - èŒƒå›´åˆ†åŒºRange æ³¨æ„ï¼šåªèƒ½åœ¨Pair RDDä¸Šè‡ªå®šä¹‰åˆ†åŒºã€‚ Hash partitioning Given a Pair RDD that should be grouped: val purchasesPerCust = purchasesRdd.map(p => (p.customerld, p.price)) // Pair RDD .groupByKey() groupByKey é¦–å…ˆè®¡ç®—RDDå¯¹ä¸­æ¯ä¸ªå…ƒç»„çš„åˆ†åŒºp: p = k.hashCode() % numPartitions ç„¶ååŒä¸€åˆ†åŒºä¸­çš„å…ƒç»„å°†è¢«å‘é€åˆ°æ‰˜ç®¡è¯¥åˆ†åŒºçš„è®¡ç®—æœº ç›´è§‰ï¼šæ•£åˆ—åˆ†åŒºå°è¯•æ ¹æ® Key åœ¨åˆ†åŒºä¹‹é—´å‡åŒ€åœ°åˆ†å¸ƒæ•°æ®ã€‚ Hash Partitioning: Example è€ƒè™‘ä¸€ Pair RDD ï¼Œå…¶ä¸­ Keys ä¸º [8,96,240,400,401,800] å’Œ æ‰€éœ€åˆ†åŒºæ•°ä¸º 4 ã€‚ æ­¤å¤–ï¼Œå‡è®¾ hashCode() æ˜¯æ ‡è¯†ï¼ˆ n.hashCode() == n ï¼‰ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ•£åˆ—åˆ†åŒºåœ¨åˆ†åŒºä¹‹é—´æŒ‰å¦‚ä¸‹æ–¹å¼åˆ†é… Keys ï¼š p = key % 4 - partition 0: [8, 96, 240, 400, 800] - partition 1: [401] - partition 2: [ ] - partition 3: [ ] ç»“æœæ˜¯éå¸¸ä¸å¹³è¡¡çš„åˆ†å¸ƒï¼Œè¿™ä¼šæŸå®³æ€§èƒ½ã€‚ æ•£åˆ—åˆ†åŒºçš„ç›®æ ‡æ˜¯å°è¯•å‡åŒ€åœ°åˆ†æ•£ Keys ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ Job åŸºæœ¬ä¸Šåªæ˜¯åœ¨ä¸€ä¸ªèŠ‚ç‚¹ä¸Šå±•å¼€ï¼Œå¹¶éçœŸæ­£å¹¶è¡Œè®¡ç®—ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå› ä¸ºçŸ¥é“æ•£åˆ—åˆ†åŒºå®é™…ä¸Šæ˜¯å€¾æ–œçš„ï¼Œå¹¶ä¸” Keys æ˜¯æœ‰åºä¸”éè´Ÿçš„ã€‚ æˆ‘ä»¬å¯ä»¥ä½¿ç”¨èŒƒå›´åˆ†åŒºæ¥æ”¹è¿›åˆ†åŒºï¼Œå¹¶ä½¿å…¶æ˜¾è‘—å‡åŒ€ã€‚ Range partitioning Pair RDDs may contain keys that have an ordering defined . - Examples: Int, Char, String, â€¦ For such RDDs, range partitioning may be more efficient. Using a range partitioner, keys are partitioned according to: 1. an ordering for keys 2. a set of sorted ranges of keys å±æ€§ï¼šå…·æœ‰ç›¸åŒèŒƒå›´ Keys çš„å…ƒç»„å‡ºç°åœ¨åŒä¸€å°æœºå™¨ä¸Šã€‚ Range Partitioning: Example ä½¿ç”¨èŒƒå›´åˆ†åŒºå¯ä»¥æ˜¾ç€æ”¹å–„åˆ†å¸ƒï¼š - å‡è®¾ï¼šï¼ˆaï¼‰ Keys éè´Ÿï¼Œï¼ˆbï¼‰800æ˜¯RDDä¸­æœ€å¤§çš„ Key - èŒƒå›´é›†ï¼š[1,200]ï¼Œ[201,400]ï¼Œ[401,600]ï¼Œ[601,800] åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒèŒƒå›´åˆ†åŒºåœ¨åˆ†åŒºä¹‹é—´æŒ‰å¦‚ä¸‹æ–¹å¼åˆ†é… Keys ï¼š - partition 0: [8, 96] - partition 1: [240, 400] - partition 2: [ 401] - partition 3: [800] ç”Ÿæˆçš„åˆ†åŒºæ›´åŠ å¹³è¡¡ã€‚ Partitioning Data å¦‚ä½•ä¸ºæ•°æ®è®¾ç½®åˆ†åŒºï¼Ÿ æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥åˆ›å»ºå…·æœ‰ç‰¹å®šåˆ†åŒºçš„ RDDs ï¼š 1. åœ¨ RDD ä¸Šè°ƒç”¨ partitionBy ï¼Œæä¾›æ˜¾å¼çš„åˆ†åŒºç¨‹åºã€‚ 2. Using transformations that return RDDs with specific partitioners. Partitioning Data: partitionBy è°ƒç”¨ partitionBy ä¼šä½¿ç”¨æŒ‡å®šçš„åˆ†åŒºç¨‹åºåˆ›å»º RDD ã€‚ Example: val pairs = purchasesRdd.map(p => (p.customerld, p.price)) val tunedPartitioner = new RangePartitioner(8, pairs) val partitioned = pairs.partitionBy(tunedPartitioner).persist() åˆ›å»ºRangePartitioneréœ€è¦ï¼š 1. æŒ‡å®šæ‰€éœ€çš„åˆ†åŒºæ•°ã€‚ 2. æä¾›å¸¦æœ‰åº Keys çš„ Pair RDD ã€‚ å¯¹è¯¥ RDD è¿›è¡Œé‡‡æ ·ä»¥åˆ›å»ºä¸€ç»„åˆé€‚çš„æ’åºèŒƒå›´ã€‚ é‡è¦ï¼špartitionByçš„ç»“æœåº”å§‹ç»ˆpersist()ã€‚ å¦åˆ™ï¼Œæ¯æ¬¡ä½¿ç”¨RDDæ˜¯éƒ½ä¼šé‡å¤åˆ†åŒºæ“ä½œï¼Œè€Œåˆ†åŒºåˆä¼šæ¶‰åŠShuffleï¼","tags":"Programming","url":"articles/Spark:-Shuffling-and-Partitioning.html","loc":"articles/Spark:-Shuffling-and-Partitioning.html"},{"title":"Scala with Gradle in Intellij","text":"Create a directory (e.g., demo_proj) for your project. Run gradle init --type scala-library in terminal in the above directory. Import the directory as a Gradle project in IntelliJ. IntelliJå¦‚ä½•å¯¼å…¥Gradleé¡¹ç›® Apache Spark setup with Gradle, Scala and IntelliJ","tags":"Programming","url":"articles/Scala with Gradle in Intellij.html","loc":"articles/Scala with Gradle in Intellij.html"},{"title":"Debugging Spark Application","text":"select * from table1 as A join table as B on A.item_id = B.item_id where A.id in (1139426, 1139436) and A.date >= '2018-12-01' yarn logs -applicationId <app ID> > output_file 2019 - 02 - 21 19 : 23 : 41 ERROR ApplicationMaster : 91 - User class threw exception : org . apache . spark . sql . AnalysisException : Found duplicate column ( s ) when inserting into hdfs :// apollo - phx - nn - ha / user / lsu1 / result . parquet : `item_id` ; ...... * ---> A . *","tags":"Programming","url":"articles/Debugging-Spark-Application.html","loc":"articles/Debugging-Spark-Application.html"},{"title":"Linux","text":"1. Redirection of standard output > 2. Redirected output >> 3. Pipes | 4. cat 5. grep & awk 6. chmod 7. ps 8. unzip 9. tar 10. windows â€˜\\r\\n' to linux â€˜\\n' 11. rsync 12. SSH SSHè¿œç¨‹æ‰§è¡Œå‘½ä»¤ æ— å¯†é’¥ç™»é™† Auto disconnect 13. pip 14. è®¾ç½®ç¯å¢ƒå˜é‡ 15. lsof 16. siege 17. supervisor 18. brew 19. iTerm2 rzsz 20. lsof 22. hostname 23. kill 24. iTerm2 + powerline + oh-my-zsh 25. iconv 26. /dev ln 1. Redirection of standard output > The default standard output is the screen. > is output redirection symbol and syntax is: $ command > output.file.name https://bash.cyberciti.biz/guide/Standard_output 2. Redirected output >> Appending the output to the same file using >> operator. 3. Pipes | https://bash.cyberciti.biz/guide/Chapter_7:_Pipes_and_Filters 4. cat Displaying The Contents of Files $ cat filename $ cat file > newfile Use a pipe to filter data : $ cat file | less Concatenate files $ cat file1 file2 $ cat file1 file2 > newcombinedfile Create new text files note that if a file already exists, it will be overwritten. $ cat > filename append the output to the same file using >> operator: $ cat >> filename Copy file $ cat oldfile > newfile https://www.cyberciti.biz/faq/howto-use-cat-command-in-unix-linux-shell-script/ 5. grep & awk grep è¡Œå¤„ç† awk åˆ—å¤„ç† cat jupyter_notebook_config.json | grep password | awk -F '\"' '{print $4}' PWD=$(cat jupyter_notebook_config.json | grep password | awk -F '\"' '{print $4}') 6. chmod $ chmod +x tarbackup.sh $ ./tarbackup.sh 7. ps ps -aux æ˜¾ç¤ºæ‰€æœ‰åŒ…å«å…¶ä»–ä½¿ç”¨è€…çš„è¡Œç¨‹ ps -aux | grep ssh ä¸ grep ç»“åˆï¼ŒæŸ¥æ‰¾ç‰¹å®šè¿›ç¨‹ ps -ef | grep PID , æ‰¾åˆ°å…¶çˆ¶è¿›ç¨‹ï¼Œç„¶å kill -9 çˆ¶è¿›ç¨‹ID kill -9 pid 8. unzip sudo apt-get install unzip unzip file.zip -d destination_folde unzip 9. tar tar -czvf ***.tar.gz directory tar -xzvf ***.tar.gz https://www.cnblogs.com/52linux/archive/2012/03/04/2379738.html 10. windows â€˜\\r\\n' to linux â€˜\\n' cat -A filename vim filename && set ff=unix dos2unix tool 11. rsync upload: rsync -avh --progress --delete --exclude=analysis/ src_dir/ host:dest_dir download: rsync -avh --progress host:dest_dir ./ -a, --archive # å½’æ¡£æ¨¡å¼ï¼Œè¡¨ç¤ºä»¥é€’å½’æ–¹å¼ä¼ è¾“æ–‡ä»¶ï¼Œå¹¶ä¿æŒæ‰€æœ‰æ–‡ä»¶å±æ€§ï¼Œç­‰ä»·äº -rlptgoD -r, --recursive # å¯¹å­ç›®å½•ä»¥é€’å½’æ¨¡å¼å¤„ç† -l, --links # ä¿æŒç¬¦å·é“¾æ¥æ–‡ä»¶ -H, --hard-links # ä¿æŒç¡¬é“¾æ¥æ–‡ä»¶ -p, --perms # ä¿æŒæ–‡ä»¶æƒé™ -t, --times # ä¿æŒæ–‡ä»¶æ—¶é—´ä¿¡æ¯ -g, --group # ä¿æŒæ–‡ä»¶å±ç»„ä¿¡æ¯ -o, --owner # ä¿æŒæ–‡ä»¶å±ä¸»ä¿¡æ¯ (super-user only) -D # ä¿æŒè®¾å¤‡æ–‡ä»¶å’Œç‰¹æ®Šæ–‡ä»¶ (super-user only) -v, --verbose # è¯¦ç»†è¾“å‡ºæ¨¡å¼ -h, --human-readable # è¾“å‡ºæ–‡ä»¶å¤§å°ä½¿ç”¨æ˜“è¯»çš„å•ä½ï¼ˆå¦‚ï¼ŒKï¼ŒMç­‰ï¼‰ --exclude=PATTERN # æŒ‡å®šæ’é™¤ä¸€ä¸ªä¸éœ€è¦ä¼ è¾“çš„æ–‡ä»¶åŒ¹é…æ¨¡å¼ -exclude=\"*.iso\", --exclude={'file1.txt','dir1/*'} --exclude-from # æŒ‡å®šä¸€ä¸ªæœ¬åœ°æ–‡ä»¶ï¼Œé‡Œé¢æ˜¯éœ€è¦æ’é™¤çš„æ–‡ä»¶æ¨¡å¼ï¼Œæ¯ä¸ªæ¨¡å¼ä¸€è¡Œã€‚ --delete # åˆ é™¤é‚£äº›æ¥æ”¶ç«¯è¿˜æœ‰è€Œå‘é€ç«¯å·²ç»ä¸å­˜åœ¨çš„æ–‡ä»¶ã€‚æ³¨æ„ï¼šå¦‚æœ--excludeä¼ è¾“æ’é™¤çš„æ–‡ä»¶ï¼Œ--deleteä¹Ÿä¸ä¼šåˆ é™¤æ¥å—ç«¯çš„è¿™ä¸ªæ–‡ä»¶ã€‚å¦‚æœè¦åˆ é™¤ï¼Œéœ€è¦--delete-excludedæŒ‡å®šã€‚ä¾‹å¦‚ï¼šrsync --delete exclude='.git' æ¥å—ç«¯ä¸ä¼šå› --deleteè€Œåˆ é™¤å‘å°„ç«¯æ’é™¤åœ¨å¤–æ²¡åŒæ­¥çš„.gitæ–‡ä»¶ï¼Œå³ä¿ç•™æ¥å—ç«¯åŸæœ‰çš„.gitæ–‡ä»¶; é™¤éæŒ‡å®š--delete-excluded='.git'ï¼Œå¦‚rsync --delete exclude='.git' --delete-excluded='.git' ã€‚ --progress # åœ¨ä¼ è¾“æ—¶æ˜¾ç¤ºä¼ è¾“è¿‡ç¨‹ -nå‚æ•°æˆ–--dry-runå‚æ•°æ¨¡æ‹Ÿå°†è¦æ‰§è¡Œçš„æ“ä½œï¼Œè€Œå¹¶ä¸çœŸçš„æ‰§è¡Œã€‚é…åˆ-vå‚æ•°ä½¿ç”¨ï¼Œå¯ä»¥çœ‹åˆ°å“ªäº›å†…å®¹ä¼šè¢«åŒæ­¥è¿‡å»ã€‚ http://www.ruanyifeng.com/blog/2020/08/rsync.html https://download.samba.org/pub/rsync/rsync.html https://rsync.samba.org/how-rsync-works.html 12. SSH SSHè¿œç¨‹æ‰§è¡Œå‘½ä»¤ è¿œç¨‹æ‰§è¡Œå‘½ä»¤ï¼š ssh lsu1@xxx.xxx.xxx.xxx \"df -h\" ssh lsu1@xxx.xxx.xxx.xxx \"df -h; ls\" è¿œç¨‹æ‰§è¡Œæœ¬åœ°è„šæœ¬ï¼š ssh lsu1@xxx.xxx.xxx.xxx < test.sh ssh lsu1@xxx.xxx.xxx.xxx 'bash -s' < test.sh helloworld # å¸¦å‚æ•° æ‰§è¡Œè¿œç¨‹æœåŠ¡å™¨ä¸Šè„šæœ¬ï¼š ssh lsu1@xxx.xxx.xxx.xxx \"/home/lsu1/test.sh\" # éœ€è¦ç»å¯¹è·¯å¾„ æ— å¯†é’¥ç™»é™† SSH Client : 192.168.0.12 SSH Remote Host : 192.168.0.11 Create Authentication SSH -Kegen Keys on â€“ 192.168.0.12 ssh-keygen -t rsa ssh-keygen -t rsa -b 4096 -m pem Create .ssh Directory on â€“ 192.168.0.11 ssh 192.168.0.11 mkdir -p .ssh Upload Generated Public Keys to â€“ 192.168.0.11 cat .ssh/id_rsa.pub | ssh 192.168.0.11 'cat >> .ssh/authorized_keys' best way: ssh-copy-id -i ~/.ssh/id_rsa.pub lsu1@139.224.58.222 Set Permissions on â€“ 192.168.0.11 ssh 192.168.0.11 \"chmod 700 .ssh; chmod 640 .ssh/authorized_keys\" Set StrictModes sudo vim /etc/ssh/sshd_config ===> StrictModes no sudo service ssh restart https://www.tecmint.com/ssh-passwordless-login-using-ssh-keygen-in-5-easy-steps Auto disconnect /etc/ssh/sshd_config ClientAliveInterval 60 ClientAliveCountMax 3 restart sshdï¼š Linux: service sshd restart MAC : service: command not found MAC : brew services start sshd 13. pip cd ~ && mkdir .pip && vim .pip/pip.conf [global] index-url = https://pypi.doubanio.com/simple/ timeout = 1000 [install] use-mirrors = true mirrors = https://pypi.doubanio.com// 14. è®¾ç½®ç¯å¢ƒå˜é‡ Shellä¸´æ—¶è®¾ç½®, ç»ˆç«¯å…³é—­åå¤±æ•ˆ export PATH=/cygdrive/c/Users/YCKJ2939/anaconda3:$PATH ~/.bashrcæ°¸ä¹…è®¾ç½®ï¼Œåªå¯¹æœ¬ç”¨æˆ·å¯è§ echo 'export PATH=/cygdrive/c/Users/YCKJ2939/anaconda3:$PATH' >> ~/.bashrc source ~./bashrc /etc/profileæ°¸ä¹…è®¾ç½®ï¼Œå¯¹æ‰€æœ‰ç”¨æˆ·å¯è§ How To Read and Set Environmental and Shell Variables on a Linux VPS 15. lsof lsof -i 16. siege An HTTP / HTTPS stress tester siege http://localhost:8000/?q=pants -c10 -t10s 17. supervisor Supervisor process control system for UNIX 18. brew MAC install brew 19. iTerm2 rzsz https://juejin.cn/post/6844904176707698695 20. lsof ç«¯å£å·å ç”¨æƒ…å†µ lsof -i:port 22. hostname hostname -i 23. kill ps -ef|grep nginx|grep -v grep|cut -c 9-15|xargs kill -9 https://www.joshua317.com/article/36 24. iTerm2 + powerline + oh-my-zsh 25. iconv iconv -c -f gbk -t utf8 file_name -o new_file_name 26. /dev lsu1 @ lsu1 : ~ # lsblk NAME MAJ : MIN RM SIZE RO TYPE MOUNTPOINT vda 252 : 0 0 40 G 0 disk â””â”€ vda1 252 : 1 0 40 G 0 part / lsu1 @ lsu1 : ~ # df -h Filesystem Size Used Avail Use % Mounted on udev 975 M 0 975 M 0 % / dev tmpfs 200 M 6.5 M 193 M 4 % / run / dev / vda1 40 G 28 G 11 G 73 % / tmpfs 997 M 0 997 M 0 % / dev / shm tmpfs 5.0 M 0 5.0 M 0 % / run / lock tmpfs 997 M 0 997 M 0 % / sys / fs / cgroup overlay 40 G 28 G 11 G 73 % / var / lib / docker / overlay2 / 2263075e71 fe3ecd347c2a33571546c607048e740de7da2eac72eec365c6b429 / merged tmpfs 200 M 0 200 M 0 % / run / user / 0 lsblk æŸ¥çœ‹å¯ç”¨å¯è®¾å¤‡ï¼Œ df -h å—è®¾å¤‡ vda1 å—è®¾å¤‡æŒ‚åœ¨åˆ°ç›®å½• / ï¼Œ mount ä¸ umount æŒ‚åœ¨å’Œå¸è½½æŒ‚è½½ç‚¹ã€‚ mount /dev/nvme3n1 /data æŒ‚è½½ nvme3n1 ç¡¬ç›˜åˆ° /data ç›®å½• echo \"/dev/nvme3n1 /data ext4 defaults 0 0\" >> /etc/fstab # ä¿è¯é‡å¯ç”Ÿæ•ˆ ln ln -s /home/data /data :åˆ›å»ºç›®å½• /home/data çš„è½¯è¿æ¥ /data rm -rf /data ï¼šåˆ é™¤è½¯è¿æ¥ï¼Œä¸€å®šä¸èƒ½ rm -rf /data/ linuxé»˜è®¤ä¼šä¸å…¨ / ï¼Œè¿™æ ·åˆ é™¤ä¼šæŠŠ /home/data/ ç›®æ ‡ç›®å½•ä¸‹çš„å†…å®¹å…¨éƒ¨åˆ é™¤ï¼ï¼ï¼","tags":"Tools","url":"articles/Linux.html","loc":"articles/Linux.html"},{"title":"Scala","text":"å‰è¨€ Functional Programming Part-1: Elements of Functional Programming Pure functions and Side effects Referential Transparency First Class Function & Higher Order Functions Anonymous Functions Immutability Functions Functions Literals Syntax Where do we use function literals? Placeholder Syntax Higher Order Functions VarArgs, Named Arguments, Default Value Partially Applied Functions Part-2: Elements of Functional Programming Strict and Lazy Evaluations Pattern Matching Scala Closures Scala Basics å‰è¨€ Functional Programming Part-1: Elements of Functional Programming ä»€ä¹ˆæ˜¯å‡½æ•°å¼ç¼–ç¨‹ï¼Ÿ(Functional Programming) å‡½æ•°å¼ç¼–ç¨‹æ˜¯ä¸€ç§ä»…ä½¿ç”¨çº¯å‡½æ•°(pure functions)å’Œä¸å¯å˜å€¼(immutable values)ç¼–å†™è½¯ä»¶åº”ç”¨ç¨‹åºçš„æ–¹æ³•ã€‚ ä¸ºä»€ä¹ˆéœ€è¦å‡½æ•°å¼ç¼–ç¨‹ï¼Ÿ 1. Pure functions and Side effects 2. Referential Transparency 3. First Class Functions & Higher Order Functions 4. Anonymous Functions 5. Immutability 6. Recursion & Tail Recursion 7. Statements 8. Strict and Non-Strict (Lazy) evaluation 9. Pattern Matching 10. Closures Pure functions and Side effects ä»€ä¹ˆæ˜¯çº¯å‡½æ•°ï¼Ÿ é¦–å…ˆï¼Œä»€ä¹ˆæ˜¯å‡½æ•°ï¼Ÿ A function relates an input to an output. It is like a machine that has an input and output. And the output is related somehow to the input. There are three main part: - The input - The relationship - The output Math.sqrt(4.0) sqrtå°±æ˜¯relationship The Input solely determines the output. æ— è®ºåœ¨å“ªé‡Œæˆ–è€…å¤šå°‘æ¬¡è°ƒç”¨è¿™ä¸ªå‡½æ•°ï¼Œåªè¦è¾“å…¥å‚æ•°ç›¸åŒï¼Œå°±ä¼šå¾—åˆ°ç›¸åŒçš„è¾“å‡ºã€‚ The function doestn't change its input. The function doest't do anything else except computing the output. è¿™ä¸ªå‡½æ•°ä¸ä¼šä»æ–‡ä»¶æˆ–è€…ç»ˆç«¯è¯»å–ä»»ä½•æ•°æ®ï¼Œä¹Ÿä¸ä¼šåœ¨ç»ˆç«¯æ‰“å°æˆ–å‘æ–‡ä»¶å†™ä»»ä½•æ•°æ®ã€‚ä¹Ÿä¸ä¼šè¯»å†™ä»»ä½•å…¨å±€å˜é‡æˆ–è€…å‡½æ•°ä»¥å¤–çš„ä»»ä½•ã€‚å®é™…ä¸Šï¼Œå®ƒä¸ä¼šæœ‰IOæ“ä½œã€‚çº¯å‡½æ•°ç±»ä¼¼äºä¸“ç”¨æœºå™¨ï¼Œè·å–è¾“å…¥ï¼Œè®¡ç®—è¾“å‡ºå¹¶è¿”å›ï¼Œæ²¡æœ‰å…¶ä»–å·¥ä½œã€‚ å¦‚æœå®ƒåšäº†ä»»ä½•å½±å“å¤–ç•Œæˆ–å¤–ç•Œå¯è§çš„äº‹æƒ…ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸º å‡½æ•°çš„å‰¯ä½œç”¨(Side effect) ã€‚å‰¯ä½œç”¨å°±åƒåšä¸»è¦ç›®çš„ä»¥å¤–çš„äº‹æƒ…. å¦‚æœå‡½æ•°æ²¡æœ‰å‰¯ä½œç”¨ï¼Œå®ƒå°±æ˜¯çº¯å‡½æ•°ã€‚ å¦‚ä½•éªŒè¯å‡½æ•°æ˜¯çº¯å‡½æ•°ï¼Ÿ æ£€æµ‹å‡½æ•°çš„ å¼•ç”¨é€æ˜æ€§ (Referential Transparency) Referential Transparency ä»€ä¹ˆæ˜¯å‡½æ•°çš„å¼•ç”¨é€æ˜æ€§ï¼Ÿ å¦‚æœæˆ‘ä»¬å¯ä»¥ç”¨ç›¸åŒçš„å€¼æ›¿æ¢å®ƒè€Œä¸æ”¹å˜ç¨‹åºçš„è¡Œä¸ºï¼Œåˆ™ç§°å‡½æ•°æ˜¯å¼•ç”¨é€æ˜æ€§ã€‚ å³ï¼Œåªè¦è¾“å…¥ç›¸åŒï¼Œæ€»èƒ½å¾—åˆ°ç›¸åŒçš„è¿”å›å€¼ã€‚ e.g. 1: Replace Math . sqrt ( 4 . 0 ) with 2 . 0 # Can you do this ? # Yes . Because Math . sqrt ( 4 . 0 ) will always return 2 . 0 as long as input is 4 . 0 . So sqrt æ˜¯çº¯å‡½æ•°ã€‚ e.g. 2: // å…¨å±€å˜é‡ var g = 10 def rt ( i : Int ): Int = { g = i + g return g } val v1 = rt ( 5 ) // v1 = 15 val v2 = rt ( 5 ) // v2 = 20 å‡½æ•°rtä¸æ˜¯çº¯å‡½æ•°ï¼Œå› ä¸ºï¼š - ä¸æ»¡è¶³ç¬¬ä¸€æ¡ï¼šä¾èµ–äºå…¨å±€å˜é‡gï¼Œè¾“å‡ºä¸æ˜¯ä»…ä»…ä¾èµ–äºè¾“å…¥å‚æ•°ã€‚ - ä¸æ»¡è¶³ç¬¬ä¸‰æ¡ï¼šä¿®æ”¹äº†å¤–éƒ¨å˜é‡ï¼Œæ‰€ä»¥æ˜¯æœ‰å‰¯ä½œç”¨çš„ã€‚ è‡³æ­¤ï¼Œç†è§£äº† çº¯å‡½æ•° ï¼Œ å‰¯ä½œç”¨ ï¼Œ å¼•ç”¨é€æ˜æ€§ ã€‚ æ€»ç»“ï¼š çº¯å‡½æ•°éµå¾ªä¸€ä¸‹ä¸‰æ¡è§„åˆ™: 1. è¾“å‡ºåªä¾èµ–äºè¾“å…¥å‚æ•°å€¼ 2. å‡½æ•°ä¸ä¼šä¿®æ”¹è¾“å…¥å‚æ•°å€¼ 3. å‡½æ•°æ²¡æœ‰å‰¯ä½œç”¨ - å¦‚æœä¸ºç›¸åŒçš„å‚æ•°æä¾›ç›¸åŒçš„å€¼ï¼Œåˆ™è¯¥å‡½æ•°æ˜¯å¼•ç”¨é€æ˜çš„. - æ£€æµ‹å‡½æ•°çš„å¼•ç”¨é€æ˜æ€§æ¥åˆ¤æ–­å‡½æ•°æ˜¯å¦ä¸ºçº¯å‡½æ•°ã€‚ ä¸ºä»€ä¹ˆéœ€è¦çº¯å‡½æ•°ï¼Ÿ 1. å®‰å…¨çš„ç¼–ç¨‹æ–¹å¼ã€‚çº¯å‡½æ•°å¯¹äºä»£ç é‡ç”¨æ˜¯small, precise, simple, safe and easy. 2. å¯ç»„åˆæˆ–è€…æ¨¡å—åŒ–ã€‚ 3. å®¹æ˜“æµ‹è¯• only asserting return value 4. å¯è®°å¿†çš„ã€‚cachingç¡®å®šå‡½æ•°ï¼Œå³å‡½æ•°æ˜¯çº¯å‡½æ•°ï¼Œå¯ä»¥ç¼“å­˜è¾“å‡ºlater useã€‚ 5. æƒ°æ€§ lazy ã€‚ First Class Function & Higher Order Functions ä»€ä¹ˆæ˜¯ä¸€çº§å‡½æ•°ï¼Ÿ æŠŠå‡½æ•°å½“åšå€¼ï¼Œå³ä¸€çº§å‡½æ•°ã€‚ 1. å¯ä»¥èµ‹å€¼ç»™å˜é‡ 2. å¯ä»¥ä½œä¸ºå‚æ•°ï¼Œä¼ é€’ç»™å…¶ä»–å‡½æ•° 3. å¯ä»¥ä½œä¸ºè¿”å›å€¼ï¼Œä»å…¶ä»–å‡½æ•°è¿”å› åœ¨Scalaä¸­æ‰€æœ‰å‡½æ•°éƒ½æ˜¯ä¸€çº§å‡½æ•°ï¼Œä¸€çº§å…¬æ°‘ã€‚ ä»€ä¹ˆæ˜¯é«˜é˜¶å‡½æ•°ï¼Ÿ è‡³å°‘æ»¡è¶³ä¸€ç‚¹ï¼Œå³é«˜é˜¶å‡½æ•°ï¼š 1. å°†ä¸€ä¸ªæˆ–å¤šä¸ªå‡½æ•°ä½œä¸ºå‚æ•° 2. è¿”å›ä¸€ä¸ªå‡½æ•°ä½œä¸ºç»“æœ Anonymous Functions ä»€ä¹ˆæ˜¯åŒ¿åå‡½æ•°ï¼Ÿ æ ‡å‡†å‡½æ•°ï¼š def double ( i : Int ) : Int = { return i * 2 } åŒ¿åå‡½æ•°ï¼š ( i : Int ) => { i * 2 } : Int function literal syntax å‡½æ•°æ–‡æœ¬ åŒ¿åå‡½æ•°å¦‚ä½•è°ƒç”¨ï¼Ÿ èµ‹å€¼å˜é‡ï¼š val d = (i:Int) => {i * 2} :Int é€šè¿‡å˜é‡è°ƒç”¨ï¼š d(3) åŒ¿åå‡½æ•°çš„ç›®çš„æ˜¯ä»€ä¹ˆï¼Ÿ å†…è”å‡½æ•°ï¼Œåªä½¿ç”¨ä¸€æ¬¡çš„å‡½æ•°ï¼Œæä¾›åå­—æ˜¯æ²¡æœ‰æ„ä¹‰çš„ã€‚ e.g. åˆ›å»ºå‡½æ•°è¿”å›å¦ä¸€ä¸ªå‡½æ•°ï¼ša little tricky // è¿”å›å€¼çœç•¥ def getOps ( c : Int ) = ( i : Int ) => { // your code here val doubler = ( x : Int ) => { x * 2 } val tripler = ( x : Int ) => { x * 3 } if ( c > 0 ) doubler ( i ) else tripler ( i ) } Immutability ä»€ä¹ˆæ˜¯ä¸å˜æ€§ï¼Ÿ Immutability = program using constants ä¼˜ç‚¹ï¼š 1. æœ‰åŠ©äºé‡‡ç”¨æ•°å­¦æ–¹æ³•å’Œæ„å»ºçº¯å‡½æ•°ã€‚ 2. æœ‰åŠ©äºé¿å…å„ç§é—®é¢˜ï¼Œå¦‚ä¸å¯å˜å¯¹è±¡æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œæ˜“äºå¹¶å‘ç¼–ç¨‹ã€‚ How can we program without a variable? æ–¹æ³•ä¸€ï¼š def iFactorial ( n : Int ): Int = { var i = n var f = 1 while ( i > 0 ){ f = f * i i = i - 1 } return f } iFactorial ( 5 ) // = 120 iFactorialå‡½æ•°æ˜¯çº¯å‡½æ•°å—ï¼Ÿ å¯ä»¥ä¸ç”¨å˜é‡å®ç°iFactorialå‡½æ•°å—ï¼Ÿ é€’å½’ã€‚è¿­ä»£è½¬é€’å½’ convert loops to recursion and avoid mutation def iFactorial ( n : Int ) : Int = { if ( n <= 0 ) return 1 else return n * iFactorial ( n - 1 ) } æ–¹æ³•äºŒï¼š å¯å˜æ€§å¯èƒ½æœ‰å…¶æ˜æ˜¾çš„ä¼˜åŠ¿. Functions ; æ˜¯å¯é€‰çš„ã€‚ä¸€è¡Œå¤šæ¡è¯­å¥æ—¶ï¼Œå¯ä»¥ç”¨ ; é—´éš” return å…³é”®å­—æ˜¯å¯é€‰çš„ã€‚å‡½æ•°æ€»æ˜¯è¿”å›æœ€åä¸€æ¬¡æ‰§è¡Œè¡¨è¾¾å¼çš„å€¼ å•è¡Œå‡½æ•°ä½“çš„èŠ±æ‹¬å· { } æ˜¯å¯é€‰çš„ è¿”å›å€¼ç±»å‹æ˜¯å¯é€‰çš„ï¼Œåªè¦ç¼–è¯‘å™¨å¯ä»¥æ¨æ–­è¿”å›å€¼ç±»å‹ ä¸è¦å¿˜è®°å‡½æ•°ä½“å‰çš„ = æ— å‚å‡½æ•° ( ) æ˜¯å¯é€‰çš„ A simple example: def myMax ( x : Int , y : Int ) : Int = { if (x > y) return x ; else return y ; } çœç•¥ ; å’Œ return ï¼š def myMax ( x : Int , y : Int ) : Int = { if ( x > y ) x else y } ä¸€è¡Œå‡½æ•°ä½“ï¼š def myMax ( x : Int , y : Int ) : Int = { if ( x > y ) x else y } å•è¡Œå‡½æ•°ä½“çš„èŠ±æ‹¬å· { } æ˜¯å¯é€‰çš„ï¼š def myMax ( x : Int , y : Int ) : Int = if ( x > y ) x else y è¿”å›å€¼ç±»å‹æ˜¯å¯é€‰çš„ï¼š def myMax ( x : Int , y : Int ) = if ( x > y ) x else y è¿™ç§å•è¡Œ functions å’Œ methods åœ¨Scalaä¸­å¸¸è§ã€‚åŒæ ·Scalaä¸­å¤šè¡Œå‡½æ•°ä¹Ÿå¾ˆå¸¸è§ï¼Œä½†æ˜¯å‡½æ•°ä½“éœ€è¦ä¸€å¯¹èŠ±æ‹¬å· { } ï¼š def myMax ( x : Int , y : Int ) = { if ( x > y ) x else y } æ— å‚å‡½æ•° ( ) æ˜¯å¯é€‰çš„ï¼š ä¿ç•™ ( ) ï¼šå½“å‡½æ•°æœ‰å‰¯ä½œç”¨æ—¶ä½¿ç”¨ def hWorld() = println(\"Hello World!\") val h = hWorld() val h = hWorld çœç•¥ ( ) ï¼šå½“å‡½æ•°æ²¡æœ‰å‰¯ä½œç”¨æ—¶ä½¿ç”¨ï¼Œå³çº¯å‡½æ•°ä¸ä½¿ç”¨ ( ) def hWorld = println(\"Hello World!\") val h = hWorld æƒ¯ä¾‹ï¼šæ— å‚å‡½æ•°æ²¡æœ‰ ( ) è¡¨æ˜å‰¯ä½œç”¨ Functions Literals Syntax ä¸åŒçš„åå­—ï¼Œç›¸åŒçš„æ„ä¹‰ï¼š - Anonymous functions - Function literals - Lambda expression æˆ‘æ¯”è¾ƒå€¾å‘äºFunction literalsï¼Œå› ä¸ºå‡½æ•°å¼ç¼–ç¨‹çš„åŸºæœ¬æ€æƒ³ä¹‹ä¸€æ˜¯å‡½æ•°è¢«å½“ä½œ first class citizens , å¯ä»¥è±¡æ“ä½œ values ä¸€æ ·æ“ä½œå®ƒï¼š 1. å¯ä»¥èµ‹å€¼ç»™å˜é‡ 2. å¯ä»¥ä½œä¸ºå‚æ•°ï¼Œä¼ é€’ç»™å…¶ä»–å‡½æ•° 3. å¯ä»¥ä½œä¸ºè¿”å›å€¼ï¼Œä»é«˜é˜¶å‡½æ•°è¿”å› å¯ä»¥ç”¨ literal åˆ›å»º values ï¼š val s = \"Hello World!\" // create a string value using a string literal val l = 5 | val l:Long = 5 | val l = 5:Long // create a integer value using a integer literal Can we create a function value using a literal? ( parameterName : type , ...) => { function body return [ expr ] } : [ return type ] æ— å‡½æ•°å = å˜æˆ => è¿”å›å€¼ç±»å‹ç§»åˆ°æœ«å°¾ val f = (x:Int) => { x + 5 } val f = (x:Int) => { x + 5 }:Int å¦‚æœæŠŠè¿”å›å€¼ç±»å‹ç§»åˆ°å‰é¢ï¼Œå¿…é¡»åŒ…å«è¾“å…¥ç±»å‹å’Œè¿”å›ç±»å‹ã€‚ä¸æ¨èè¿™ç§å†™æ³•ï¼ŒScalaä¼šè‡ªåŠ¨æ¨æ–­ï¼š // also like val l:Long = 5 val f:Int=> Int = (x:Int) => { x + 5 } e.g. åˆ›å»ºä¸€ä¸ªå‡½æ•°å€¼æ¥æ”¶ä¸€ä¸ªæ•´å‹å’Œä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œè¿æ¥åè¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚ myFun(5, \"-\") è¿”å› -5- val myFun:(Int, String)=>String = (x:Int, s:Sring) => { s + x + s }:String val myFun = (x:Int, s:Sring) => { s + x + s } // æ¨èå†™æ³• Where do we use function literals? Pass it to a higher order functions Return it from higher order functions e.g. val data= List(-250, 57, 54, -33, 43) data.map( (x:Int) => x + 10 ) >>> [[-240, 67, 64, -23, 53]] å½“åªæœ‰ä¸€ä¸ªå‚æ•°æ—¶ï¼Œå‚æ•°ç±»å‹å’Œ ( ) å¯çœç•¥ï¼š data.map( x => x + 10 ) Placeholder Syntax Higher Order Functions VarArgs, Named Arguments, Default Value Partially Applied Functions Part-2: Elements of Functional Programming Strict and Lazy Evaluations Pattern Matching Scala Closures Scala Basics","tags":"Programming","url":"articles/Scala.html","loc":"articles/Scala.html"},{"title":"Spark RDD","text":"æ ¸å¿ƒæ¦‚å¿µå’ŒæŠ½è±¡ RDD RDD Operations Basics Understanding closures Action RDD Persistence Resiliency é«˜çº§ä¸»é¢˜ Execution & Scheduling Caching & Persistence Shared Variables Broadcast Variables Accumulators References Spark RDDè¦ç‚¹æ€»ç»“ï¼š Spark RDDå¼¹æ€§åˆ†å¸ƒå¼æ•°æ®é›† 1. RDDç®€ä»‹ - RDDçš„æ¦‚è¿° - RDDçš„å±æ€§ 2. RDDçš„åˆ›å»ºæ–¹å¼ - ä»æ–‡ä»¶ç³»ç»Ÿä¸­åŠ è½½æ•°æ®åˆ›å»ºRDD - é€šè¿‡å¹¶è¡Œé›†åˆåˆ›å»ºRDD 3. RDDçš„å¤„ç†è¿‡ç¨‹ - RDDçš„æ•´ä½“å¤„ç†æµç¨‹ - Transformationç®—å­ - Actionç®—å­ - ç¼–å†™WordCountè¯é¢‘ç»Ÿè®¡æ¡ˆä¾‹ 4. RDDçš„ä¾èµ–å…³ç³» 5. RDDæœºåˆ¶ - æŒä¹…åŒ–æœºåˆ¶ - å®¹é”™æœºåˆ¶ 6. Sparkçš„ä»»åŠ¡è°ƒåº¦ - DAGçš„æ¦‚å¿µ - ä»»åŠ¡è°ƒåº¦æµç¨‹ æ ¸å¿ƒæ¦‚å¿µå’ŒæŠ½è±¡ RDD RDD è¿™æ˜¯ä¸€ä¸ªæ ¸å¿ƒæŠ½è±¡ï¼Œæ—¢èƒ½å®ç°è®¡ç®—çš„é«˜æ•ˆæ‰§è¡Œï¼Œåˆèƒ½çµæ´»æ–¹ä¾¿çš„å½¢å¼åŒ–å®šä¹‰è®¡ç®— ä¸ºä»€ä¹ˆéœ€è¦ä¸€ä¸ªæ–°çš„æŠ½è±¡ï¼Ÿ MapReduceä¸­çš„è¿­ä»£è®¡ç®—ï¼š 1. åç»­jobsä¹‹é—´çš„å…³ç³»ä»…ä¸ºç”¨æˆ·ä»£ç æ‰€çŸ¥ï¼Œè€Œä¸æ˜¯æ¡†æ¶ã€‚æ‰€ä»¥ï¼Œæ¡†æ¶æ— æ³•ä¼˜åŒ–æ•´ä¸ªè®¡ç®—ã€‚ 2. æ¡†æ¶å¿…é¡»å¯é åœ°æŒä¹…ä¿å­˜ä¸­é—´æ•°æ®ï¼Œä»è€Œäº§ç”Ÿè¿‡å¤šçš„IO Sparkå°†æ•°æ®ä¿å­˜åœ¨å†…å­˜ä¸­ï¼Œæœ‰æ•ˆåœ°æ¶ˆé™¤äº†ä¸­é—´ç£ç›˜æŒä¹…æ€§ï¼Œä»è€Œæ”¹å–„äº†å®Œæˆæ—¶é—´ RDD Operations RDDsæ”¯æŒä¸¤ç§ç±»å‹æ“ä½œï¼š Transformations ï¼šä»å·²çš„æ•°æ®é›†ä¸­åˆ›å»ºä¸€ä¸ªæ–°çš„æ•°æ®é›†ã€‚ Actions ï¼šåœ¨æ•°æ®é›†ä¸Šæ‰§è¡Œå®Œä¸€ä¸ªè®¡ç®—åï¼Œå‘ driver program è¿”å›ä¸€ä¸ªå€¼ã€‚ ä¾‹å¦‚ï¼š map ï¼šæ˜¯ä¸€ä¸ª transformation ï¼Œé€šè¿‡ä¸€ä¸ªå‡½æ•°ä¼ é€’æ¯ä¸ªæ•°æ®é›†å…ƒç´ ï¼Œå¹¶è¿”å›ä¸€ä¸ªè¡¨ç¤ºç»“æœçš„æ–°RDDã€‚ reduce ï¼šæ˜¯ä¸€ä¸ª action ,ä½¿ç”¨æŸä¸ªå‡½æ•°èšåˆRDDçš„æ‰€æœ‰å…ƒç´ ï¼Œå¹¶å°†æœ€ç»ˆç»“æœè¿”å›ç»™ driver program ã€‚ Sparkä¸­æ‰€æœ‰çš„ transformations éƒ½æ˜¯ æƒ°æ€§çš„ ï¼Œå› ä¸ºä»–ä»¬ä¸ä¼šç«‹å³è®¡ç®—ä»–ä»¬çš„ç»“æœã€‚ç›¸åï¼Œä»–ä»¬åªè®°å¾—åº”ç”¨äºæŸäº›åŸºç¡€æ•°æ®é›†çš„è½¬æ¢ã€‚ transformations ä»…åœ¨ actions éœ€è¦å°†ç»“æœè¿”å›åˆ° driver program æ—¶è®¡ç®—ã€‚è¿™ç§è®¾è®¡ä½¿Sparkèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°è¿è¡Œã€‚ é»˜è®¤æƒ…å†µä¸‹ï¼Œå½“æ¯ä¸€æ¬¡åœ¨è½¬æ¢åçš„RDDä¸Šæ‰§è¡Œä¸€ä¸ª action æ—¶ï¼Œå®ƒéƒ½ä¼šé‡æ–°è®¡ç®—ã€‚ä½†æ˜¯ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨æŒä¹…åŒ–ï¼ˆæˆ–ç¼“å­˜ï¼‰çš„æ–¹æ³•åœ¨å†…å­˜ä¸­ä¿ç•™RDDï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒSparkä¼šåœ¨ç¾¤é›†ä¸Šä¿ç•™å…ƒç´ ï¼Œä»¥ä¾¿åœ¨ä¸‹æ¬¡æŸ¥è¯¢æ—¶æ›´å¿«åœ°è®¿é—®ã€‚ å½“ç„¶ä¹Ÿæ˜¯æ”¯æŒåœ¨ç£ç›˜ä¸Šä¿ç•™RDDï¼Œæˆ–åœ¨å¤šä¸ªèŠ‚ç‚¹ä¹‹é—´å¤åˆ¶çš„ã€‚ Basics 1 ï¼š lines = sc . textFile ( \"data.txt\" ) 2 ï¼š lineLengths = lines . map ( lambda s : len ( s )) 3 ï¼š to talLength = lineLengths . reduce ( lambda a , b : a + b ) 1: ä»å¤–éƒ¨æ–‡ä»¶å®šä¹‰åŸºç¡€RDDã€‚ æ­¤æ•°æ®é›†æœªåŠ è½½åˆ°å†…å­˜ä¸­æˆ–ä»¥å…¶ä»–æ–¹å¼æ“ä½œï¼š lines ä»…ä»…æ˜¯æŒ‡å‘æ–‡ä»¶çš„æŒ‡é’ˆã€‚ 2: å°† lineLengths å®šä¹‰ä¸º map è½¬æ¢çš„ç»“æœã€‚ç”±äºæƒ°æ€§ lineLengths ä¸ä¼šç«‹å³è®¡ç®—ã€‚ 3: æœ€ç»ˆè¿è¡Œ reduce ï¼Œæ˜¯ä¸€ä¸ª action ã€‚æ­¤æ—¶Sparkå°†è®¡ç®—åˆ†è§£ä¸ºåœ¨ä¸åŒæœºå™¨ä¸Šè¿è¡Œçš„ Tasks ï¼Œå¹¶ä¸”æ¯å°æœºå™¨éƒ½è¿è¡Œå…¶ map çš„éƒ¨åˆ†å’Œæœ¬åœ°çš„ reduce ï¼Œä»…è¿”å›å…¶å¯¹ driver program çš„ç»“æœã€‚ å¦‚æœç¨åéœ€è¦å†æ¬¡ä½¿ç”¨ lineLengths ï¼Œå¯ä»¥ç”¨ lineLengths.persist() åœ¨ reduce ä¹‹å‰ï¼Œå°† lineLengths åœ¨ç¬¬ä¸€æ¬¡è®¡ç®—ä¹‹åä¿å­˜åœ¨å†…å­˜ä¸­ã€‚ Understanding closures Sparkçš„ä¸€ä¸ªéš¾ç‚¹æ˜¯åœ¨è·¨é›†ç¾¤æ‰§è¡Œä»£ç æ—¶ç†è§£å˜é‡å’Œæ–¹æ³•çš„èŒƒå›´å’Œç”Ÿå‘½å‘¨æœŸã€‚ ä¿®æ”¹å…¶èŒƒå›´ä¹‹å¤–çš„å˜é‡çš„RDDæ“ä½œå¯èƒ½ç»å¸¸å¼•èµ·æ··æ·†ã€‚ å‡½æ•°å¼ç¼–ç¨‹ï¼šç†è§£é—­åŒ…å’Œå»¶è¿Ÿè®¡ç®— 1. Example æ ¹æ®æ˜¯å¦åœ¨è¿è¡Œåœ¨åŒä¸€JVMä¸­å¯èƒ½è¡¨ç°ä¸åŒ Sparkåº”ç”¨ç¨‹åºè¿è¡Œï¼šæœ¬åœ°æ¨¡å¼ vs. é›†ç¾¤æ¨¡å¼ ä½¿ç”¨ foreach() å¢åŠ  counter ï¼š counter = 0 rdd = sc . parallelize ( data ) # Wrong : Don 't do this!! def increment_counter(x): global counter counter += x rdd.foreach(increment_counter) print(\"Counter value: \", counter) 2. Local vs. cluster modes - ä¸Šè¿°ä»£ç çš„è¡Œä¸ºæ˜¯æœªå®šä¹‰çš„ï¼Œå¹¶ä¸”ä¸åŒæ¨¡å¼ä¸‹è¿è¡Œæƒ…å†µä¸åŒã€‚ä¸ºäº†æ‰§è¡Œ Job ï¼ŒSparkå°†RDDæ“ä½œçš„å¤„ç†åˆ†è§£ä¸º Tasks ï¼Œæ¯ä¸ª Task ç”± Executor æ‰§è¡Œã€‚åœ¨æ‰§è¡Œä¹‹å‰ï¼ŒSparkä¼šè®¡ç®— Task çš„é—­åŒ…ã€‚é—­åŒ…æ˜¯ Executor åœ¨RDDä¸Šè¿›è¡Œè®¡ç®—çš„æ—¶å€™å¿…é¡»å¯è§çš„é‚£äº›å˜é‡å’Œæ–¹æ³•ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹æ˜¯ foreach() ï¼‰ã€‚é—­åŒ…ä¼šè¢«åºåˆ—åŒ–å¹¶å‘é€ç»™æ¯ä¸ª Executor ã€‚ å‘é€ç»™æ¯ä¸ª Executor çš„é—­åŒ…ä¸­çš„å˜é‡æ˜¯å‰¯æœ¬ï¼Œå› æ­¤ï¼Œå½“ foreach() å‡½æ•°å†…å¼•ç”¨ counter æ—¶ï¼Œå®ƒä¸å†æ˜¯ driver èŠ‚ç‚¹ä¸Šçš„ counter ã€‚ driver èŠ‚ç‚¹çš„å†…å­˜ä¸­ä»æœ‰ä¸€ä¸ª counter ï¼Œä½†è¯¥å˜é‡æ˜¯å¯¹ Executor ä¸å¯è§çš„ï¼ Executor åªèƒ½çœ‹åˆ°åºåˆ—åŒ–é—­åŒ…çš„å‰¯æœ¬ã€‚å› æ­¤ï¼Œ counter çš„æœ€ç»ˆå€¼ä»ç„¶ä¸º0ï¼Œå› ä¸º counter ä¸Šçš„æ‰€æœ‰æ“ä½œéƒ½å¼•ç”¨äº†åºåˆ—åŒ–é—­åŒ…å†…çš„å€¼ã€‚ åœ¨æœ¬åœ°æ¨¡å¼ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œè¯¥ foreach() å‡½æ•°å®é™…ä¸Šå°†åœ¨ä¸ driver ç›¸åŒçš„JVMå†…æ‰§è¡Œï¼Œå¹¶ä¸”ä¼šå¼•ç”¨ç›¸åŒçš„åŸå§‹ counter ï¼Œè¿™æ ·æ˜¯å¯èƒ½å®é™…æ›´æ–°å®ƒã€‚ Sparkä¸­çš„ Accumulator ä¸“é—¨ç”¨äºæä¾›ä¸€ç§æœºåˆ¶ï¼Œç”¨äºåœ¨é›†ç¾¤ä¸­çš„å·¥ä½œèŠ‚ç‚¹ä¹‹é—´æ‰§è¡Œæ‹†åˆ†æ—¶å®‰å…¨åœ°æ›´æ–°å˜é‡ã€‚ Action RDD Persistence Resiliency Sparkå¦‚ä½•å®ç°å¼¹æ€§è®¡ç®—ï¼Ÿï¼ˆå°½ç®¡é›†ç¾¤å‡ºç°æœºå™¨æ•…éšœï¼Œä½†ä»å¯ä»¥ç»§ç»­è®¡ç®—æ“ä½œï¼‰ 1. tracking lineage 2. assuming deterministic & side-effect free execution of transformations(including closures) 3. assuming idempotency for actions 4. increasing durability of a data set æé«˜æ•°æ®é›†çš„æŒä¹…æ€§ It is important to keep in mind that all the closures pass to Spark, must be deterministic and side effect free. Actions require a stronger property, idempotency. æ‰€æœ‰çš„é—­åŒ…éƒ½ä¼ é€’ç»™Sparkï¼Œå¿…é¡»æ˜¯ç¡®å®šæ€§çš„ï¼Œå¹¶ä¸”æ²¡æœ‰å‰¯ä½œç”¨ã€‚ What is the lineage? åˆ†åŒºä¾èµ–å…³ç³»å›¾ ï¼ŒåŒ…å«è®¡ç®—ä¸­æ¶‰åŠæ•°æ®æºçš„æ‰€æœ‰åˆ†åŒºã€‚ What happens if the dependencies of a failed partition fails as well ? é‡æ–°å¯åŠ¨è®¡ç®—ã€‚é¦–å…ˆé‡æ–°è®¡ç®—è¿™ä¸ªåˆ†åŒºçš„ä¾èµ–ï¼Œç„¶åå†è®¡ç®—è¿™ä¸ªåˆ†åŒºã€‚ Key Questions: 1. æ•°æ®é›†å¿…é¡»å…·å¤‡å“ªäº›åŠŸèƒ½æ‰èƒ½å®ç°ä¸ºRDDï¼Ÿ partitions, iterator and dependencies é«˜çº§ä¸»é¢˜ Execution & Scheduling å½“åœ¨Sparkä¸Šè¿è¡Œæˆ‘ä»¬çš„åº”ç”¨ç¨‹åº ( è°ƒç”¨ä¸€ä¸ªAction ) æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ 1. SparkContext ï¼šæ˜¯åº”ç”¨çš„æ ¸å¿ƒ - å‘Šè¯‰åº”ç”¨å¦‚ä½•è®¿é—®é›†ç¾¤ - åè°ƒé›†ç¾¤ä¸Šçš„è¿›ç¨‹é›†æ¥è¿è¡Œæˆ‘ä»¬çš„åº”ç”¨ - åœ¨åŒä¸€åº”ç”¨ç¨‹åºå†…ï¼Œè°ƒåº¦å¤šä¸ªå¹¶å‘ä½œä¸š - åœ¨ä¸åŒåº”ç”¨ç¨‹åºé—´ï¼Œæ§åˆ¶åŠ¨æ€èµ„æºåˆ†é… Cluster Manager : ç”¨äºè·å–ç¾¤é›†èµ„æºçš„ä¸€ä¸ªå¤–éƒ¨æœåŠ¡ã€‚ä¾‹å¦‚ï¼š YARN , Mesos or a standalone Spark cluster.(èµ„æºç»çºªäºº) Jobs, stages, tasks Job ï¼šåœ¨å“åº” Spark action æ—¶è€Œäº§ç”Ÿçš„æ´»åŠ¨ stages ï¼šå°† Job åˆ†è§£æˆæ›´å°çš„ tasks é›†åˆï¼Œå«åš stages Tasks ï¼š job scheduler ä¸ºæ‰€æœ‰çš„ job stage åˆ›å»º Tasks Task ï¼šç”± Executor æ‰§è¡Œçš„ä¸€ä¸ªå•ä½å·¥ä½œ Action -> Job -> Job stages -> Tasks æœ€ç»ˆï¼Œ Tasks è¢«åˆ†å‘ç»™ Executors ï¼Œæ‰§è¡Œå®é™…çš„å·¥ä½œã€‚ Example : å›¾ 1 . Invoking an action Job stages å’Œ Tasksçš„åŒºåˆ«ï¼Ÿ - Job stage ï¼š æ˜¯è·¨è¶Šç‰©åŒ–è¾¹ç•Œçš„æµæ°´çº¿è®¡ç®—ã€‚å®šä¹‰åœ¨RDD levelï¼Œä¸æ˜¯å¯ç«‹å³å¯æ‰§è¡Œçš„ã€‚a pipelined computation spanning between materialization boundaries. not immediately executable. Task ï¼š æ˜¯ç»‘å®šåˆ°ç‰¹å®šåˆ†åŒºçš„job stageï¼Œæ˜¯å¯ç«‹å³å¯æ‰§è¡Œçš„ã€‚a job stage bound to particular partitions. immediately executable. The idea behind the job stages is to pipeline computation as much as possible, avoiding the unnecessary data materializations. Transformations with narrow dependencies allow pipelining For example, if you applied two filter transformations in a row, it is not necessary to serialize and deserialize data in between. You can simply pass the data through the next predicate. Data materialization occurs in a few places. when reading, shuffling, or passing data to an action. This is where the distinction between narrow and wide dependencies comes up. - Materialization happens when reading, shuffling or passing data to an action. Narrow dependencies allow pipelining. Wide dependencies forbid it. Caching & Persistence 1. Sparkå¦‚ä½•ç®¡ç†ä¸­é—´æ•°æ®ï¼Ÿ 2. å¦‚ä½•å‘Sparkæç¤ºæˆ‘ä»¬çš„è®¿é—®æ¨¡å¼ä»¥è·å¾—æ›´å¥½çš„å¼¹æ€§å’Œæ€§èƒ½ï¼Ÿ Shared Variables Sparkä¸­çš„ç¬¬äºŒä¸ªæŠ½è±¡æ˜¯å¯ä»¥åœ¨å¹¶è¡Œæ“ä½œä¸­ä½¿ç”¨çš„ å…±äº«å˜é‡ ã€‚ é»˜è®¤æƒ…å†µä¸‹ï¼Œå½“Sparkå¹¶è¡Œè¿è¡Œä¸€ä¸ªå‡½æ•°ä½œä¸ºä¸åŒèŠ‚ç‚¹ä¸Šçš„ä¸€ç»„ Tasks æ—¶ï¼Œå®ƒä¼šå°†å‡½æ•°ä¸­ä½¿ç”¨çš„æ¯ä¸ª å˜é‡çš„å‰¯æœ¬ å‘é€ç»™æ¯ä¸ª Task ã€‚å³Sparkå®é™…ä¸Šæ“ä½œçš„æ˜¯è¿™ä¸ªå‡½æ•°æ‰€ç”¨å˜é‡çš„ä¸€ä¸ªç‹¬ç«‹å‰¯æœ¬ã€‚è¿™äº›å˜é‡ä¼šè¢«å¤åˆ¶åˆ°æ¯å°æœºå™¨ä¸Šï¼Œå¹¶ä¸”è¿™äº›å˜é‡åœ¨è¿œç¨‹æœºå™¨ä¸Šçš„æ‰€æœ‰æ›´æ–°éƒ½ä¸ä¼šä¼ é€’å› driver program ã€‚ æœ‰æ—¶ï¼Œå˜é‡éœ€è¦è·¨ä»»åŠ¡å…±äº«ï¼Œæˆ–è€…åœ¨ä»»åŠ¡å’Œé©±åŠ¨ç¨‹åºä¹‹é—´å…±äº«ã€‚é€šå¸¸è·¨ä»»åŠ¡çš„è¯»å†™å…±äº«å˜é‡æ˜¯ä½æ•ˆçš„ï¼Œä½†æ˜¯ï¼ŒSparkè¿˜æ˜¯ä¸ºä¸¤ç§å¸¸è§çš„ä½¿ç”¨æ¨¡å¼æä¾›äº†ä¸¤ç§æœ‰é™çš„å…±äº«å˜é‡ï¼š å¹¿æ’­å˜é‡ ( Broadcast Variables ) å’Œç´¯åŠ å™¨ ( Accumulator ) ã€‚ Broadcast Variables 1. ä¸ºä»€ä¹ˆéœ€è¦å¹¿æ’­å˜é‡ï¼Ÿ å¦‚æœæˆ‘ä»¬è¦åœ¨åˆ†å¸ƒå¼è®¡ç®—é‡Œé¢åˆ†å‘å¤§çš„å¯¹è±¡ï¼Œä¾‹å¦‚ï¼šå­—å…¸ï¼Œæ¨¡å‹ç­‰ï¼Œè¿™ä¸ªéƒ½ä¼šç”± Driver ç«¯è¿›è¡Œåˆ†å‘ã€‚ä¸€èˆ¬æ¥è®²ï¼Œå¦‚æœè¿™ä¸ªå˜é‡ä¸æ˜¯å¹¿æ’­å˜é‡ï¼Œé‚£ä¹ˆæ¯ä¸ª Task å°±ä¼šåˆ†å‘ä¸€ä»½ï¼Œè¿™åœ¨ Task æ•°ç›®ååˆ†å¤šçš„æƒ…å†µä¸‹ Driver çš„å¸¦å®½ä¼šæˆä¸ºç³»ç»Ÿçš„ç“¶é¢ˆï¼Œè€Œä¸”ä¼šå¤§é‡æ¶ˆè€— Task æœåŠ¡å™¨ä¸Šçš„èµ„æºï¼Œå¦‚æœå°†è¿™ä¸ªå˜é‡å£°æ˜ä¸º å¹¿æ’­å˜é‡ ï¼Œé‚£ä¹ˆåªæ˜¯æ¯ä¸ª Executor æ‹¥æœ‰ä¸€ä»½ï¼Œç”±è¿™ä¸ª Executor å¯åŠ¨çš„ Task ä¼šå…±äº«è¿™ä¸ªå˜é‡ï¼ŒèŠ‚çœäº†é€šä¿¡çš„æˆæœ¬å’ŒæœåŠ¡å™¨çš„èµ„æºã€‚ æ³¨ï¼š - å¹¿æ’­å˜é‡æ˜¯åªè¯»çš„å…±äº«å˜é‡ - ç”¨äºå…±äº«å­—å…¸å’Œæ¨¡å‹ - èƒ½ä¸èƒ½å°†ä¸€ä¸ªRDDä½¿ç”¨å¹¿æ’­å˜é‡å¹¿æ’­å‡ºå»ï¼Ÿ ä¸èƒ½ï¼Œå› ä¸ºRDDæ˜¯ä¸å­˜å‚¨æ•°æ®çš„ã€‚å¯ä»¥å°†RDDçš„ç»“æœå¹¿æ’­å‡ºå» - å¹¿æ’­å˜é‡åªèƒ½åœ¨ Driver ç«¯å®šä¹‰å’Œä¿®æ”¹ï¼Œä¸èƒ½åœ¨ Executor ç«¯å®šä¹‰å’Œä¿®æ”¹ - å¦‚æœ Executor ç«¯ç”¨åˆ°äº† Driver çš„å˜é‡ï¼Œå¦‚æœä¸ä½¿ç”¨ å¹¿æ’­å˜é‡ åœ¨ Executor æœ‰å¤šå°‘ Task å°±æœ‰å¤šå°‘ Driver ç«¯çš„å˜é‡å‰¯æœ¬ - å¦‚æœ Executor ç«¯ç”¨åˆ°äº† Driver çš„å˜é‡ï¼Œå¦‚æœä½¿ç”¨ å¹¿æ’­å˜é‡ åœ¨æ¯ä¸ª Executor ä¸­åªæœ‰ä¸€ä»½ Driver ç«¯çš„å˜é‡å‰¯æœ¬ 2. ä½¿ç”¨å¹¿æ’­å˜é‡ é€šè¿‡è°ƒç”¨ SparkContext.broadcast(v) ä»å˜é‡ v åˆ›å»ºå¹¿æ’­å˜é‡ã€‚ å¹¿æ’­å˜é‡æ˜¯ v çš„åŒ…è£…å™¨ï¼Œå¯ä»¥é€šè¿‡è°ƒç”¨ value æ–¹æ³•è®¿é—®å…¶å€¼ï¼š >> broadcastVar = sc.broadcast([1, 2, 3]) <pyspark.broadcast.Broadcast object at 0x102789f10> >> broadcastVar.value [1, 2, 3] åˆ›å»ºå¹¿æ’­å˜é‡åï¼Œåº”è¯¥åœ¨ç¾¤é›†ä¸Šè¿è¡Œçš„ä»»ä½•å‡½æ•°ä¸­ä½¿ç”¨å®ƒè€Œä¸æ˜¯å€¼vï¼Œè¿™æ ·vä¸ä¼šå¤šæ¬¡ä¼ é€åˆ°èŠ‚ç‚¹ã€‚ å¦å¤–ï¼Œåœ¨å¹¿æ’­ä¹‹åä¸åº”ä¿®æ”¹å¯¹è±¡vï¼Œä»¥ç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹è·å¾—å¹¿æ’­å˜é‡çš„ç›¸åŒå€¼ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœç¨åå°†å˜é‡å‘é€åˆ°æ–°èŠ‚ç‚¹ï¼‰ã€‚ Accumulators åœ¨sparkåº”ç”¨ç¨‹åºä¸­ï¼Œæˆ‘ä»¬ç»å¸¸ä¼šæœ‰è¿™æ ·çš„éœ€æ±‚ï¼Œå¦‚å¼‚å¸¸ç›‘æ§ï¼Œè°ƒè¯•ï¼Œè®°å½•ç¬¦åˆæŸç‰¹æ€§çš„æ•°æ®çš„æ•°ç›®ï¼Œè¿™ç§éœ€æ±‚éƒ½éœ€è¦ç”¨åˆ°è®¡æ•°å™¨ï¼Œå¦‚æœä¸€ä¸ªå˜é‡ä¸è¢«å£°æ˜ä¸ºä¸€ä¸ª Accumulator ï¼Œé‚£ä¹ˆå®ƒå°†åœ¨è¢«æ”¹å˜æ—¶ä¸ä¼šå† driver ç«¯è¿›è¡Œå…¨å±€æ±‡æ€»ï¼Œå³åœ¨åˆ†å¸ƒå¼è¿è¡Œæ—¶æ¯ä¸ª Task è¿è¡Œçš„åªæ˜¯åŸå§‹å˜é‡çš„ä¸€ä¸ªå‰¯æœ¬ï¼Œå¹¶ä¸èƒ½æ”¹å˜åŸå§‹å˜é‡çš„å€¼ï¼Œä½†æ˜¯å½“è¿™ä¸ªå˜é‡è¢«å£°æ˜ä¸º Accumulator åï¼Œè¯¥å˜é‡å°±ä¼šæœ‰åˆ†å¸ƒå¼è®¡æ•°çš„åŠŸèƒ½ã€‚ 1. ä½¿ç”¨ç´¯åŠ å™¨ - Driver ç«¯åˆ›å»ºï¼š SparkContext.accumulator(v) - Executor ç«¯æ›´æ–°ï¼šé›†ç¾¤ä¸Šè¿è¡Œçš„ Task æ›´æ–°ï¼š add å’Œ += - Driver ç«¯è¯»å–ï¼š value >> accum = sc.accumulator(0) >> accum Accumulator<id=0, value=0> >> sc.parallelize([1, 2, 3, 4]).foreach(lambda x: accum.add(x)) ... 10/09/29 18:41:08 INFO SparkContext: Tasks finished in 0.317106 s >> accum.value 10 æ³¨ï¼š ç´¯åŠ å™¨ä¸ä¼šæ”¹å˜Sparkçš„æƒ°æ€§æ¨¡å‹ã€‚ å¦‚æœåœ¨RDDä¸Šçš„æ“ä½œä¸­æ›´æ–°å®ƒä»¬ï¼Œåˆ™åªæœ‰åœ¨RDDä½œä¸º action éƒ¨åˆ†è®¡ç®—æ—¶æ‰æ›´æ–°å®ƒçš„å€¼ã€‚ å› æ­¤ï¼Œåœ¨åƒ map() è¿™æ ·çš„æƒ°æ€§ transformation ä¸­è¿›è¡Œç´¯ç§¯å™¨æ›´æ–°æ—¶ï¼Œä¸èƒ½ä¿è¯æ‰§è¡Œç´¯åŠ å™¨æ›´æ–°ã€‚ accum = sc . accumulator ( 0 ) def g ( x ) : accum . add ( x ) return f ( x ) data . map ( g ) # Here, accum is still 0 because no actions have caused the `map` to be computed. References [1] Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing [2] RDD Programming Guide [3] Coursera: Spark RDD [4] StackOverflow: Internal Work of Spark [5] Advanced Apache Spark- Sameer Farooqui (Databricks) [6] A Deeper Understanding of Spark Internals - Aaron Davidson (Databricks) [7] Introduction to AmpLab Spark Internals","tags":"Programming","url":"articles/Spark-RDD.html","loc":"articles/Spark-RDD.html"},{"title":"Adaboost","text":"Boosting AdaBoostç®—æ³• AdaBoostç¼ºç‚¹ ç®—æ³•åŸç† AdaBoosté‡ç‚¹ å¼•ç”¨ å¼•ï¼šç†è§£CARTåˆ†ç±»å›å½’æ ‘ Boosting Boosting , short for Adaptive Boosting, is a machine learning ensemble meta-algorithm for primarily reducing bias , and also variance in supervised learning, and a family of machine learning algorithms that convert weak learners to strong ones. AdaBoostç®—æ³• åœ¨ç®—æ³•åˆå§‹åŒ–é˜¶æ®µï¼Œä¸ºæ¯ä¸€ä¸ªæ ·æœ¬èµ‹äºˆä¸€ä¸ªç›¸ç­‰çš„æƒé‡,åŒç­‰æ¦‚ç‡åˆ†å¸ƒï¼ˆæ ·æœ¬æ•°çš„å€’æ•°ï¼‰ï¼Œå³æ¯ä¸ªæ ·æœ¬åœ¨å¼€å§‹éƒ½æ˜¯ä¸€æ ·é‡è¦çš„ã€‚æ¥ä¸‹æ¥ï¼Œæ¯ä¸€æ¬¡è®­ç»ƒåå¾—åˆ°çš„æ¨¡å‹ï¼Œå¯¹æ•°æ®ç‚¹çš„ä¼°è®¡ä¼šæœ‰æ‰€å·®å¼‚ï¼Œæ‰€ä»¥åœ¨æ¯ä¸€æ­¥ç»“æŸåï¼Œæˆ‘ä»¬éœ€è¦å¯¹æƒé‡è¿›è¡Œå¤„ç†ï¼Œè€Œå¤„ç†çš„æ–¹å¼å°±æ˜¯é€šè¿‡å¢åŠ é”™åˆ†ç±»çš„æ ·æœ¬ç‚¹çš„æƒé‡ï¼ŒåŒæ—¶å‡å°‘åˆ†ç±»æ­£ç¡®çš„æ ·æœ¬ç‚¹çš„æƒé‡ã€‚è¿™æ ·èƒ½å¤Ÿç¡®ä¿ï¼Œå¦‚æœæŸäº›ç‚¹ç»å¸¸è¢«åˆ†é”™ï¼Œé‚£ä¹ˆå°±ä¼šè¢«\"ä¸¥é‡å…³æ³¨\"ï¼Œä¹Ÿå°±ä¼šè¢«èµ‹äºˆä¸€ä¸ªå¾ˆé«˜çš„æƒé‡ã€‚ç„¶åç­‰è¿›è¡Œäº†Næ¬¡è¿­ä»£ï¼ˆè¿­ä»£æ¬¡æ•°ç”±ç”¨æˆ·æŒ‡å®šï¼‰ï¼Œå°†ä¼šå¾—åˆ°Nä¸ªç®€å•çš„å¼±å­¦ä¹ å™¨ï¼Œæœ€åå°†å®ƒä»¬ç»„åˆèµ·æ¥ï¼Œå¯ä»¥å¯¹å®ƒä»¬è¿›è¡ŒåŠ æƒï¼ˆé”™è¯¯ç‡è¶Šå¤§çš„å¼±å­¦ä¹ å™¨å…¶æƒé‡å€¼è¶Šå°ï¼Œé”™è¯¯ç‡è¶Šå°çš„å¼±åˆ†ç±»å™¨æƒé‡å€¼è¶Šå¤§ï¼‰æˆ–è€…è®©å®ƒä»¬è¿›è¡ŒæŠ•ç¥¨ç­‰å¾—åˆ°ä¸€ä¸ªæœ€ç»ˆçš„æ¨¡å‹ï¼Œå³å¸¦æƒåŠ æ³•æ¨¡å‹ã€‚ AdaBoostç¼ºç‚¹ AdaBoostå¯¹å™ªå£°å’Œç¦»ç¾¤ç‚¹æ•æ„Ÿ å¯æ‰©å±•æ€§æ–¹é¢ï¼Œç”±äºæå‡çš„æ—¶åºæ€§ï¼Œä¸èƒ½è¿›è¡Œå¹¶è¡Œå¤„ç†ã€‚ ç®—æ³•åŸç† åˆå§‹æƒé‡ï¼Œå‡åŒ€åˆ†å¸ƒï¼š $$D_i=(w_{11}, â€¦ ,w_{1i}, â€¦ ,w_{1N}), w_{1i}=\\frac{1}{N}$$ m=1,2,â€¦,Mè¿­ä»£ï¼š 2.1 ç”±å¸¦æƒæ•°æ®é›†å­¦ä¹ å¼±åˆ†ç±»å™¨ï¼š $$G_m(x)$$ 2.2 å¼±åˆ†ç±»å™¨$G_m(x)$åœ¨åŠ æƒæ•°æ®é›†ä¸Šçš„åˆ†ç±»è¯¯å·®ï¼šæ˜¯è¢«$G_m(x)$è¯¯åˆ†ç±»æ ·æœ¬çš„æƒé‡ä¹‹å’Œã€‚ $$e_m=\\sum_{i=1}&#94;N w_{mi}I(G_m(x_i) \\neq y_i)=\\sum_{G_m \\neq y_i}w_{mi}$$ 2.3 The weight of weak learners: $$\\alpha_m=\\frac{1}{2}\\log\\frac{1-e_m}{e_m}$$ 2.4 Re-Weighting: $$w_{m+1,i}=\\frac{w_{mi}}{Z_m}exp(-\\alpha_my_iG_m(x_i)),$$ $$Z_m=\\sum_{i=1}&#94;Nw_{mi}exp(-\\alpha_my_iG_m(x_i))$$ å¼±åˆ†ç±»å™¨çš„çº¿æ€§ç»„åˆï¼š $$f(x)=\\sum_{m=1}&#94;M\\alpha_mG_m(x)$$ Strong learner: $$G(x)=sign(f(x))$$ AdaBoosté‡ç‚¹ AdaBoostæ€æ ·å®ç°æ›´åŠ å…³æ³¨è¯¯åˆ†ç±»çš„æ•°æ®ï¼Ÿ é€šè¿‡ç»™æ•°æ®æ ·æœ¬å¢åŠ æƒé‡ Weighted data ï¼Œåˆ†é”™çš„æ•°æ®åœ¨ä¸‹ä¸€è½®å­¦ä¹ ä¸­æé«˜æƒé‡ï¼Œåä¹‹å‡å°æƒé‡ã€‚ \"re-weighting\" ä¸ºä»€ä¹ˆé€šè¿‡è°ƒé«˜è¯¯åˆ†ç±»æ•°æ®çš„æƒé‡å¯ä»¥ä½¿ä¸‹ä¸€è½®çš„å¼±åˆ†ç±»å™¨æ›´åŠ å…³æ³¨ï¼Ÿ(æ•°æ®æƒé‡çš„æ€æƒ³) é€‰æ‹©å†³ç­–ç‚¹ä¸å¸¦æƒåˆ†ç±»è¯¯å·® å¼±åˆ†ç±»å™¨çš„åˆ†ç±»è¯¯å·®ç”±è¯¯åˆ†ç±»æƒé‡ç´¯åŠ ï¼Œå½“å¯»æ‰¾æœ€ä½³åˆ’åˆ†ç‚¹æ—¶ï¼Œæ€»æ˜¯å¯»æ‰¾è¯¯å·®æœ€å°çš„ï¼Œåˆ™æƒé‡é«˜çš„æ•°æ®ä¼šå°½å¯èƒ½åˆ†å¯¹ï¼Œæ‰èƒ½ä½¿è¯¯å·®å°½å¯èƒ½çš„å°ï¼Œç”±æ­¤å®ç°æ›´åŠ å…³æ³¨è¯¯åˆ†ç±»çš„ç‚¹ã€‚ æ•°æ®æƒé‡ä¸»è¦ç”¨äºå¼±åˆ†ç±»å™¨å¯»æ‰¾å…¶åˆ†ç±»è¯¯å·®æœ€å°çš„å†³ç­–ç‚¹ æ•°æ®æƒé‡å’Œå¼±åˆ†ç±»å™¨æƒé‡ AdaBoostä¸»è¦ä¸ºå‡å°‘åå·® Adaboostä½¿ç”¨çš„æ˜¯è‡ªé€‚åº”çš„æ–¹æ³•ï¼Œå…¶ä¸­æ¦‚ç‡åˆ†å¸ƒå¼å˜åŒ–çš„ï¼Œå…³æ³¨çš„æ˜¯éš¾åˆ†ç±»çš„æ ·æœ¬ã€‚ å¼•ç”¨ PPT - A Gentle Introduction to Gradient Boosting Scikit-learn - GRADIENT BOOSTING","tags":"ML","url":"articles/Adaboost.html","loc":"articles/Adaboost.html"},{"title":"CART","text":"ID3 CART CARTç®—æ³• å¼•å­ï¼šä¸€äº›æœºå™¨å­¦ä¹ ç®—æ³•ï¼ˆå¦‚çº¿æ€§å›å½’ï¼‰åˆ›å»ºçš„æ¨¡å‹éœ€è¦æ‹Ÿåˆæ‰€æœ‰çš„æ ·æœ¬æ•°æ®ã€‚ é—®é¢˜ï¼š 1ï¼šæ•°æ®ç‰¹å¾ä¼—å¤šä¸”å…¶é—´å…³ç³»ç¹æ‚è€Œå¯†åˆ‡ï¼Œæ„å»ºå…¨å±€æ¨¡å‹æ¯”è¾ƒå›°éš¾ã€‚ 2ï¼šçœŸå®ä¸–ç•Œçš„æ•°æ®å¤šæ•°æ˜¯éçº¿æ€§çš„ï¼Œæ— æ³•ç”¨å…¨å±€çº¿æ€§æ¨¡å‹æ‹Ÿåˆã€‚ è§£å†³æ–¹æ³•ï¼š å°†æ•°æ®é›†åˆ’åˆ†ä¸ºå¤šä¸ªæ˜“äºå»ºæ¨¡çš„å­æ•°æ®é›†ï¼Œå­æ•°æ®é›†å¯ä»¥ç”¨å„ç§æŠ€æœ¯å»ºæ¨¡ã€‚ä¾ç„¶éš¾ä»¥å»ºæ¨¡çš„å­æ•°æ®é›†å¯ä»¥ç»§ç»­åˆ’åˆ†ã€‚åœ¨è¿™ç§åˆ’åˆ†æ–¹å¼ä¸‹ï¼Œ æ ‘ç»“æ„ å’Œ å›å½’æ³• ç›¸å½“æœ‰ç”¨ã€‚ ID3 æ¦‚è¿°ï¼š ID3å†³ç­–æ ‘å¯ä»¥æœ‰å¤šä¸ªåˆ†æ”¯ï¼Œä½†æ˜¯ä¸èƒ½å¤„ç†ç‰¹å¾å€¼ä¸ºè¿ç»­çš„æƒ…å†µã€‚å†³ç­–æ ‘æ˜¯ä¸€ç§è´ªå¿ƒç®—æ³•ï¼Œæ¯æ¬¡é€‰å–çš„åˆ†å‰²æ•°æ®çš„ç‰¹å¾éƒ½æ˜¯å½“å‰çš„æœ€ä½³é€‰æ‹©ï¼Œå¹¶ä¸å…³å¿ƒæ˜¯å¦è¾¾åˆ°æœ€ä¼˜ã€‚åœ¨ID3ä¸­ï¼Œæ¯æ¬¡æ ¹æ®\"æœ€å¤§ä¿¡æ¯ç†µå¢ç›Š\"é€‰å–å½“å‰æœ€ä½³çš„ç‰¹å¾æ¥åˆ†å‰²æ•°æ®ï¼Œå¹¶æŒ‰ç…§è¯¥ç‰¹å¾çš„æ‰€æœ‰å–å€¼æ¥åˆ‡åˆ†ï¼Œä¸€æ—¦æŒ‰æŸç‰¹å¾åˆ‡åˆ†åï¼Œè¯¥ç‰¹å¾åœ¨ä¹‹åçš„ç®—æ³•æ‰§è¡Œä¸­ï¼Œå°†ä¸å†èµ·ä½œç”¨ã€‚ID3ç®—æ³•æ ¸å¿ƒæ˜¯æ ¹æ®\"æœ€å¤§ä¿¡æ¯ç†µå¢ç›Š\"åŸåˆ™é€‰æ‹©åˆ’åˆ†å½“å‰æ•°æ®é›†çš„æœ€å¥½ç‰¹å¾ã€‚åœ¨å»ºç«‹å†³ç­–æ ‘çš„è¿‡ç¨‹ä¸­ï¼Œæ ¹æ®ç‰¹å¾å±æ€§åˆ’åˆ†æ•°æ®ï¼Œä½¿å¾—åŸæœ¬\"æ··ä¹±\"çš„æ•°æ®çš„ç†µ(æ··ä¹±åº¦)å‡å°‘ï¼ŒæŒ‰ç…§ä¸åŒç‰¹å¾åˆ’åˆ†æ•°æ®ç†µå‡å°‘çš„ç¨‹åº¦ä¼šä¸ä¸€æ ·ã€‚åœ¨ID3ä¸­é€‰æ‹©ç†µå‡å°‘ç¨‹åº¦æœ€å¤§çš„ç‰¹å¾æ¥åˆ’åˆ†æ•°æ®ï¼ˆè´ªå¿ƒï¼‰ï¼Œä¹Ÿå°±æ˜¯\"æœ€å¤§ä¿¡æ¯ç†µå¢ç›Š\"åŸåˆ™ã€‚ ID3ç®—æ³•ç¼ºç‚¹ï¼š ID3ä¸èƒ½ç›´æ¥å¤„ç†è¿ç»­å‹ç‰¹å¾ã€‚ æ•°æ®é›†åˆ‡åˆ†è¿‡äºè¿…é€Ÿã€‚ ä¿¡æ¯å¢ç›Šä½œä¸ºç‰¹å¾é€‰æ‹©æ ‡å‡†çš„ç¼ºé™·ï¼šä¿¡æ¯å¢ç›Šåœ¨ç‰¹å¾å€¼å¤šçš„ç‰¹å¾ä¸Šè®¡ç®—ç»“æœå¤§äºç‰¹å¾å€¼å°‘çš„ç‰¹å¾ï¼Œè¿™ä¼šå¯¼è‡´ ID3 åå‘é€‰æ‹©æœ‰è¾ƒå¤šåˆ†æçš„ç‰¹å¾ï¼Œè€Œè¯¥ç‰¹å¾ä¸ä¸€å®šæ˜¯æœ€ä¼˜çš„é€‰æ‹©ã€‚ CART CARTæ˜¯åˆ†ç±»å›å½’æ ‘ã€‚ å†³ç­–æ ‘æ¨¡å‹æ˜¯å°†è¾“å…¥ç©ºé—´åˆ’åˆ†æˆè‹¥å¹²ä¸ªåŒºåŸŸã€‚CARTæ˜¯äºŒå‰æ ‘ï¼Œæ¯ä¸€æ¬¡å°†åŒºåŸŸäºŒåˆ†ï¼Œå­åŒºåŸŸé€’å½’ã€‚ CARTæ ‘çš„æŸå¤±å‡½æ•°ï¼š $Loss = \\min_{j, s}[\\min_{c_1}L(y&#94;{(i)}, c_1) + \\min_{c_2}L(y&#94;{(i)}, c_2)]$ $c_m$ æ˜¯å­åŒºåŸŸä¸Šçš„å‡å€¼ï¼š $c_m = \\frac{1}{N_m}\\sum_{x_i \\in R_m(j, s))}y_i, \\ \\ \\ x \\in R_m, \\ \\ m = 1, 2$ $x&#94;(j)$ : é€‰æ‹©ç¬¬jä¸ªç‰¹å¾ä½œä¸ºåˆ‡åˆ†å˜é‡ s ï¼šé€‰æ‹©è¯¥ç‰¹å¾çš„ç‰¹å¾å€¼sä½œä¸ºåˆ‡åˆ†ç‚¹ $R_m$ ï¼šåˆ’åˆ†å‡ºçš„å­åŒºåŸŸ æ‰€ä»¥åœ¨CARTæ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬éœ€è¦éå†è¾“å…¥ç‰¹å¾$x&#94;{(j)}$ï¼Œæ‰¾åˆ°æœ€ä½³åˆ’åˆ†ç‚¹ s ï¼Œå³æŸå¤±å‡½æ•°å€¼æœ€å°ã€‚ CARTç®—æ³• å¯¹äºåˆ†ç±»é—®é¢˜ï¼Œé‡‡ç”¨åŸºå°¼ç³»æ•°é€‰æ‹©æœ€ä¼˜ç‰¹å¾ï¼ŒåŒæ—¶å†³å®šè¯¥ç‰¹å¾çš„æœ€ä¼˜åˆ’åˆ†ç‚¹ã€‚ å¯¹äºå›å½’é—®é¢˜ï¼Œå¸¸é€‰ç”¨ L2 è·ç¦»ä½œä¸ºæŸå¤±å‡½æ•°$L(y&#94;{(i)}, c)$ï¼Œè¿™ç§å›å½’æ ‘ç§°ä¸º æœ€å°äºŒä¹˜å›å½’æ ‘ ã€‚ é€‰æ‹© (j, s) $$Loss = \\min_{j, s}[\\min_{c_1} \\sum_{x_i \\in R_1(j, s))}(y_i - c_1)&#94;2 + \\min_{c_2} \\sum_{x_i \\in R_2(j, s))}(y_i - c_2)&#94;2]$$ ç”¨é€‰å®šçš„ (j, s) åˆ’åˆ†åŒºåŸŸå¹¶è¾“å‡ºç›¸åº”åŒºåŸŸçš„å‡å€¼ $$R_1(j, s) = {x | x&#94;{(j) \\leq s}}, \\ \\ R_2(j, s) = {x | x&#94;{(j) > s}}$$ $$c_m = \\frac{1}{N_m}\\sum_{x_i \\in R_m(j, s))}y_i, \\ \\ \\ x \\in R_m, \\ \\ m = 1, 2$$ åœ¨ä¸¤ä¸ªå­åŒºåŸŸä¸Šé€’å½’1ï¼Œ 2æ­¥éª¤ç›´åˆ°æ»¡è¶³ç»ˆæ­¢æ¡ä»¶ å°†è¾“å…¥ç©ºé—´åˆ’åˆ†ä¸º M ä¸ªåŒºåŸŸ $R_1, R_2 ,â€¦, R_M$ ï¼Œç”Ÿæˆå†³ç­–æ ‘","tags":"ML","url":"articles/CART.html","loc":"articles/CART.html"},{"title":"Information Theory","text":"Information Theory ä¿¡æ¯$X$ ä¿¡æ¯é‡$H(X)$ Information Entropy ä¿¡æ¯ç†µçš„è®¡ç®— Information Gain Information Theory ä¿¡æ¯$X$ ä¿¡æ¯$X$å³ä¿¡æº $X$ï¼šè¡¨ç¤ºä¸€æ®µä¿¡æ¯ï¼Œå¦‚æ–‡æœ¬ã€è¯­éŸ³ç­‰ç­‰ã€‚ ä¿¡æºçš„ä¸ç¡®å®šæ€§ ï¼šä¿¡æºå‘å‡ºçš„æ¶ˆæ¯ä¸ç¡®å®šæ€§è¶Šå¤§ï¼Œæ”¶ä¿¡è€…è·å–çš„ä¿¡æ¯é‡å°±è¶Šå¤§ã€‚å¦‚æœä¿¡æºå‘é€çš„æ¶ˆæ¯æ˜¯ç¡®åˆ‡çš„ï¼Œåˆ™å¯¹æ”¶ä¿¡è€…æ¥è¯´æ²¡æœ‰ä»»ä½•ä»·å€¼ï¼ˆæ²¡æœ‰ä¿¡æ¯é‡ï¼‰ã€‚è¡¡é‡ä¸ç¡®å®šæ€§çš„æ–¹æ³•å°±æ˜¯è€ƒå¯Ÿä¿¡æº$X$çš„æ¦‚ç‡ç©ºé—´ã€‚XåŒ…å«çš„çŠ¶æ€è¶Šå¤šï¼ŒçŠ¶æ€$X_i$çš„æ¦‚ç‡$P_i$è¶Šå°ï¼Œåˆ™ä¸ç¡®å®šæ€§è¶Šå¤§ï¼Œæ‰€å«æœ‰çš„ä¿¡æ¯é‡è¶Šå¤§ã€‚ ä¿¡æ¯é‡$H(X)$ å¦‚ä½•è¡¡é‡ä¿¡æ¯$X$çš„å¤§å°ï¼Œå¦‚ä½•è¡¡é‡ä¿¡æ¯$X$æ‰€åŒ…å«çš„ä¿¡æ¯é‡ï¼Ÿ $H(X_1) > H(X_2); H(X_1) = H(X_2);H(X_1) < H(X_2)$ è‡ªä¿¡æ¯é‡H(X) ï¼šä¸€ä¸ªäº‹ä»¶(æ¶ˆæ¯)æœ¬èº«æ‰€åŒ…å«çš„ä¿¡æ¯é‡ï¼Œç”±äº‹ä»¶çš„ä¸ç¡®å®šæ€§å†³å®šçš„ã€‚ å¦‚ä½•ç”¨æ•°å­¦æ¨¡å‹è¡¨ç¤º$X$çš„ä¿¡æ¯é‡ï¼Ÿ 1. $H(X) <=> \\frac{1}{P(X)}$ å•è°ƒæ€§ ï¼š ä¿¡æ¯é‡$H(X)$ä¸ä¿¡æ¯$X$å‡ºç°çš„æ¦‚ç‡$P(X)$æˆåæ¯”ï¼Œå³ä¿¡æ¯$X$å‡ºç°çš„æ¦‚ç‡è¶Šå¤§ï¼Œåˆ™$X$çš„ä¿¡æ¯é‡è¶Šå°ã€‚ 2. $H(X_1, X_2) <=> H(X_1) + H(X_2)$ å¯åŠ æ€§ ï¼šä¿¡æ¯$X_1$ä¸$X_2$æ˜¯ç‹¬ç«‹éšæœºå˜é‡å¯åŠ (æš‚ä¸”ç®€å•è®¤ä¸ºç‹¬ç«‹ï¼Œä¸ç‹¬ç«‹æœ‰æ¡ä»¶ç†µ) 3. $H(X)\\geq0$ éè´Ÿæ€§ å¯»æ‰¾ä¸€ä¸ªå‡½æ•°$H$åŒæ—¶æ»¡è¶³ä»¥ä¸Šä¸‰ç‚¹ï¼Œå³ï¼š éšæœºäº‹ä»¶$X_i$å‘ç”Ÿæ¦‚ç‡ä¸º$P(X_i)$ï¼Œåˆ™ ä¿¡æ¯é‡å‡½æ•° å®šä¹‰ä¸ºï¼š $$H(X)=\\log\\frac{1}{P(X)}=-\\log{P(X)}$$ å¯åŠ æ€§è¯æ˜ï¼š$H(X_1,X_2)=\\log\\frac{1}{P(X_1,X_2)}=\\log\\frac{1}{P(X_1)P(X_2)}= \\log\\frac{1}{P(X_1)}+\\log\\frac{1}{P(X_2)}$ï¼Œ$X_1$,$X_2$ç›¸äº’ç‹¬ç«‹ Information Entropy å®šä¹‰ï¼šä¿¡æ¯é‡$H(X)$åœ¨$P(X)$åˆ†å¸ƒä¸‹çš„æ•°å­¦æœŸæœ›ï¼š $$Entropy(X)=E_x[H(X)]=-\\sum_xp(x)\\log{p(x)}$$ çƒ­åŠ›å­¦ç¬¬äºŒå®šå¾‹ è–›å®šè°”.ã€Šç”Ÿå‘½æ˜¯ä»€ä¹ˆã€‹ ï¼ˆç¬¬å…­ç«  æœ‰åºï¼Œæ— åºå’Œç†µï¼‰ åŸºæœ¬æ€æƒ³ï¼šä¸€ä¸ªæ­£å¸¸çš„äººè‹¥è¦ç»´æŒé«˜åºçš„çŠ¶æ€ï¼Œåˆ™å¿…é¡»è¦å¸æ”¶è´Ÿç†µæ¥ç»´æŒé«˜åºç¨³å®šçš„çŠ¶æ€ï¼Œå¦åˆ™æˆ‘ä»¬çš„ç†µä¼šè¶‹äºå¢å¤§è€Œå˜çš„æ— åºã€‚æ‰€ä»¥äººéœ€è¦åƒé£Ÿç‰©ï¼Œé£Ÿç‰©æ˜¯é«˜åºç¨³å®šçš„ï¼Œç»è¿‡å¸æ”¶å˜å¾—æ— åºäº§ç”Ÿè´Ÿç†µæ¥ç»´æŒæˆ‘ä»¬é«˜åºç¨³å®šçŠ¶æ€ã€‚ ä¿¡æ¯ç†µå¯ä»¥æè¿°æ•°æ®çš„æ··åˆç¨‹åº¦ã€‚ ç†µè¶Šå¤§ï¼Œæ··åˆåº¦è¶Šé«˜ï¼Œæ•°æ®çº¯åº¦è¶Šä½ã€‚ ä¿¡æ¯ç†µçš„è®¡ç®— æ•°æ®é›†$D$ï¼š X X X | O O O X X X O O - $ori_entropy(X)$ï¼šæœ€åˆæ•´ä¸ªç³»ç»Ÿï¼ˆæ•°æ®é›†$D$ï¼‰çš„å›ºå®šç†µï¼Œå³ ç»éªŒç†µ ï¼ˆæèˆªï¼Œç»Ÿè®¡å­¦ä¹ æ–¹æ³•ï¼‰ $$ori_entropy(D)=-\\frac{1}{2}\\log\\frac{1}{2}-\\frac{1}{2}\\log\\frac{1}{2}=1$$ - æ ¹æ®æŸä¸ªç‰¹å¾å°†æ•°æ®é›†$D$åˆ’åˆ†ä¸º$D_-$(X X X)å’Œ$D_+$(O O O X X X O O)ï¼š $$entropy(D_-)=0$$ $$entropy(D_+)=-\\frac{2}{7}\\log\\frac{2}{7}-\\frac{5}{7}\\log\\frac{5}{7}$$ å³æ•°æ®é›†åˆ’åˆ†åä¸¤ä¸ªå­æ•°æ®é›†çš„ä¿¡æ¯ç†µã€‚ ç”±è¿™æ ·åˆ’åˆ†æ•°æ®é›†ä¹‹åï¼Œæ•´ä¸ªç³»ç»Ÿï¼ˆæ•°æ®é›†$D$ï¼‰çš„ä¿¡æ¯ç†µæœ‰ä½•å˜åŒ–å‘¢ï¼Ÿ ç”±æ­¤å¼•å…¥äº† ä¿¡æ¯å¢ç›Š(Information Gain) ã€‚ def cal_entropy ( dataset ) : '''Calculate the datasets' entropy . : param dataset : The dataset needs to calculated . ''' dataset_size = len(dataset) label_count = {} for data in dataset: label = data[-1] if label not in label_count: label_count[label] = 0 label_count[label] += 1 entropy = -sum([(count / dataset_size) * log((count / dataset_size), 2) for count in label_count.values()]) return entropy def cond_entropy(dataset, feature_idx): ''' Calculate the weighted entropy of several sub datasets . : param dataset : The raw dataset : param feature_idx : The index of feature splited the dataset . ''' dataset_size = len(dataset) sub_datasets = {} for data in dataset: feature_value = data[feature_idx] if feature_value not in sub_datasets: sub_datasets[feature_value] = [] sub_datasets[feature_value].append(data) # Sub dataset' s weighted entropy cond_entropy = sum ( [ (len(sub_dataset) / dataset_size) * cal_entropy(sub_dataset) for sub_dataset in sub_datasets.values() ] ) return cond_entropy Information Gain ä¿¡æ¯å¢ç›Šï¼šåŸå§‹æ•°æ®é›†$D$çš„ç†µ å‡å» æŒ‰ç‰¹å¾$A$åˆ’åˆ†è‹¥å¹²ä¸ªå­æ•°æ®é›†$D_i$çš„åŠ æƒç†µ ä¿¡æ¯å¢ç›Šï¼šç”±äºç†µçš„å‡å°ï¼Œè€Œå¢åŠ ä¿¡æ¯çš„è·å¾—æ˜¯å¤šå°‘ã€‚ ä¸€ä¸ªç‰¹å¾çš„ä¿¡æ¯å¢ç›Šå°±æ˜¯ç”±äºä½¿ç”¨è¿™ä¸ªç‰¹å¾åˆ†å‰²æ•°æ®é›†è€Œå¯¼è‡´çš„æœŸæœ›ç†µé™ä½ã€‚åœ¨ä¿¡æ¯å¢ç›Šä¸­ï¼Œè¡¡é‡æ ‡å‡†æ˜¯çœ‹ç‰¹å¾èƒ½å¤Ÿä¸ºåˆ†ç±»ç³»ç»Ÿå¸¦æ¥å¤šå°‘ä¿¡æ¯ï¼Œå¸¦æ¥çš„ä¿¡æ¯è¶Šå¤šï¼Œè¯¥ç‰¹å¾è¶Šé‡è¦ã€‚å¯¹ä¸€ä¸ªç‰¹å¾è€Œè¨€ï¼Œç³»ç»Ÿæœ‰å®ƒå’Œæ²¡å®ƒæ—¶ä¿¡æ¯é‡å°†å‘ç”Ÿå˜åŒ–ï¼Œè€Œå‰åä¿¡æ¯é‡çš„å·®å€¼å°±æ˜¯è¿™ä¸ªç‰¹å¾ç»™ç³»ç»Ÿå¸¦æ¥çš„ä¿¡æ¯é‡ï¼ˆç³»ç»Ÿç†µé™ä½ï¼Œåˆ™ä¿¡æ¯é‡å‡å°ï¼Œåˆ™è·å–æ›´å¤šçš„ä¿¡æ¯é‡ï¼Œå³ä¿¡æ¯å¢ç›Šï¼‰ã€‚ $$ IG =ori_entropy-\\sum_i w_i \\cdot entropy(D_i)=ori_entropy-\\sum_i \\frac{|D_i|}{|D|} \\cdot entropy(D_i)$$ ä¿¡æ¯å¢ç›Šè¶Šå¤§è¶Šå¥½ï¼Œè¿˜æ˜¯è¶Šå°è¶Šå¥½ï¼Ÿ ä¿¡æ¯å¢ç›Šæ˜¯ï¼šåŸå§‹æ•°æ®é›†$D$çš„ç†µå‡å»æŒ‰ç‰¹å¾$A$åˆ’åˆ†è‹¥å¹²ä¸ªå­æ•°æ®é›†$D_i$çš„åŠ æƒç†µã€‚æˆ‘ä»¬çš„ç›®çš„æ˜¯ä½¿æ¯ä¸€ä¸ªå­é›†çš„ç†µæœ€å°ï¼ˆæœ€å°ä»£è¡¨æ¯ä¸ªå­é›†éƒ½æ˜¯ä¸€ç±»æ•°æ®ï¼Œé«˜åº¦æœ‰åºçš„çŠ¶æ€ï¼Œé«˜çº¯åº¦ï¼‰ï¼Œå³åŠ æƒç†µå°½é‡å°ï¼Œåˆ™IGè¶Šå¤§ã€‚ æ ¹æ®IGå‡†åˆ™çš„ç‰¹å¾é€‰æ‹©æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ å¯¹è®­ç»ƒæ•°æ®é›†ï¼ˆæˆ–å­é›†ï¼‰$D$ï¼Œè®¡ç®—å…¶æ¯ä¸€ä¸ªç‰¹å¾çš„ä¿¡æ¯å¢ç›Šï¼Œé€‰æ‹©ä¿¡æ¯å¢ç›Šæœ€å¤§çš„ç‰¹å¾ã€‚ def info_gain ( entropy , cond_entropy ) : return entropy - cond_entropy","tags":"ML","url":"articles/Information-Theory.html","loc":"articles/Information-Theory.html"},{"title":"Data Structure and Algorithm in Python","text":"Sort Quick Sort å¼•ä¾‹ï¼šè·å…°å›½æ——é—®é¢˜ğŸ‡³ğŸ‡± Heap Sort Heap å †çš„å®šä¹‰ å †çš„ç‰¹ç‚¹ä¸ä¼˜åŠ¿ å¤§æ ¹å †çš„å®ç° å»ºç«‹å¤§æ ¹å † å †åŒ– å †æ’åº BFS & DFS BFS DFS Recursion Template Example: Divide and Conquer Template Example: Dynamic Programming Example: Sort Quick Sort å¼•ä¾‹ï¼šè·å…°å›½æ——é—®é¢˜ğŸ‡³ğŸ‡± Heap Sort https://docs.python.org/3/library/heapq.html#heapq.heapify æ—¶é—´å¤æ‚åº¦O(N*logN)ï¼Œé¢å¤–ç©ºé—´å¤æ‚åº¦O(1)ã€‚ å †ç»“æ„éå¸¸é‡è¦ å †ç»“æ„çš„ heapInsert å’Œ heapify å †ç»“æ„çš„å¢å¤§å’Œå‡å°‘ å¦‚æœåªæ˜¯å»ºå †çš„è¿‡ç¨‹ï¼Œæ—¶é—´å¤æ‚åº¦ä¸ºO(N) ä¼˜å…ˆçº§é˜Ÿåˆ—ç»“æ„ï¼Œå°±æ˜¯å †ç»“æ„ Heap å †çš„å®šä¹‰ å †ç»“æ„ å°±æ˜¯ä¸€ä¸ª å®Œå…¨äºŒå‰æ ‘ ï¼Œæ•°ç»„çš„ç»“æ„å®ç°ï¼Œé€šè¿‡çº¦å®šä¸‹æ ‡è§„åˆ™ã€‚ å¯¹äºä»»æ„ä¸‹æ ‡ä¸º i çš„ç»“ç‚¹ï¼Œ å·¦å­©å­ï¼š 2*i + 1 å³å­©å­ï¼š 2*i + 2 çˆ¶èŠ‚ç‚¹ï¼š (i-1) // 2 å¤§æ ¹å † ï¼šåœ¨ä¸€æ£µå®Œå…¨äºŒå‰æ ‘ä¸­ï¼Œä»»ä½•ä¸€æ£µå­æ ‘çš„æœ€å¤§å€¼éƒ½æ˜¯è¿™æ£µå­æ ‘çš„æ ¹ï¼Œæ‰€å½¢æˆçš„ç»“æ„å«å¤§æ ¹å †ã€‚å°æ ¹å †ç±»ä¼¼ã€‚ å †çš„ç‰¹ç‚¹ä¸ä¼˜åŠ¿ å¤§/å°æ ¹å †æœ‰ä¸€ä¸ªå¾ˆé‡è¦çš„å±æ€§ï¼šå®ƒçš„æœ€å¤§/å°å…ƒç´ å§‹ç»ˆæ˜¯æ ¹èŠ‚ç‚¹ heap[0] ã€‚ å †çš„è°ƒæ•´ä»£ä»·åªå’Œ å±‚æ•° æœ‰å…³ï¼Œæ‰€ä»¥ å…¥å † å’Œ å‡ºå † çš„ä»£ä»·åªæœ‰ O(lgN) ã€‚ å¤§æ ¹å †çš„å®ç° This implementation uses arrays for which heap[i] > heap[2*i+1] and heap[i] > heap[2*i+2] for all i , counting elements from zero. ç»™å®šæ•°ç»„ï¼Œéƒ½å¯æ ¹æ®çº¦å®š è§†å…¶ä¸ºå † ï¼Œä½†å…¶ä¸æ˜¯å¤§æ ¹å †ï¼Œ å¦‚ä½•å°†æ•°ç»„è°ƒæ•´ä¸ºå¤§æ ¹å † ï¼Ÿ å»ºç«‹å¤§æ ¹å † heapInsert : ç»å†ä¸€ä¸ªæ–°ç»“ç‚¹åŠ å…¥ä¸€ä¸ªå·²ç»è°ƒæ•´å¥½çš„å †ä¸­ï¼ŒåŒæ—¶å¾€ä¸Šè°ƒæ•´çš„è¿‡ç¨‹ã€‚è°ƒæ•´åœæ­¢æ¡ä»¶ï¼šå½“åŠ å…¥ç»“ç‚¹å€¼ä¸å¤§äºå…¶çˆ¶èŠ‚ç‚¹æ—¶ï¼Œ è°ƒæ•´åœæ­¢ã€‚ å †åœ¨æ•°ç»„ä¸Šå¯ä¼¸ç¼© def insertHeap ( arr , index ) : par_i = ( index - 1 ) // 2 while par_i >= 0 and arr [ index ] > arr [ par_i ] : # æ’å…¥ç»“ç‚¹å€¼æ¯”çˆ¶ç»“ç‚¹å¤§æ—¶ ï¼Œ å¾€ä¸Šè°ƒæ•´ arr [ index ] , arr [ par_i ] = arr [ par_i ] , arr [ index ] # ä¸çˆ¶ç»“ç‚¹äº¤æ¢ index = par_i # æ’å…¥ç»“ç‚¹æ¥åˆ°çˆ¶èŠ‚ç‚¹çš„ä½ç½® par_i = ( index - 1 ) // 2 def createHeap ( arr ) : if arr == None or len ( arr ) < 2 : return arr for i in range ( len ( arr )) : # ä¾æ¬¡å°†ç»“ç‚¹åŠ å…¥å †ä¸­ ï¼Œ æœ€ç»ˆå°†æ•°ç»„ ï¼ˆ å † ï¼‰ è°ƒæ•´ä¸ºå¤§æ ¹å † insertHeap ( arr , i ) return arr æ—¶é—´å¤æ‚åº¦åˆ†æï¼š O(N) å½“ç¬¬ i ä¸ªç»“ç‚¹åŠ å…¥å †ä¸­æ—¶ï¼Œ 0 ~ i-1 å·²ç»è°ƒæ•´ä¸ºå¤§æ ¹å †ï¼Œå…¶é«˜åº¦ä¸º O(log(i-1)) ï¼Œå³è°ƒæ•´ä»£ä»·ä¸º O(log(i-1)) ã€‚(æ²¿å…¶çˆ¶ç»“ç‚¹ä¾æ¬¡å‘ä¸Š> æ¯”è¾ƒè°ƒæ•´) æ‰€ä»¥, N ä¸ªç»“ç‚¹çš„è°ƒæ•´ä»£ä»·ä¸ºï¼š O(lg1) + O(lg2) + ... + O(lgN) æ”¶æ•›äº O(N) å †åŒ– def heapify ( arr , index , heapSize ) : left = 2 * index + 1 # å·¦å­©å­æœªè¶Šç•Œ ï¼Œ åœ¨å †ä¸Š ï¼Œ ç»§ç»­å¾ªç¯åˆ¤æ–­æ˜¯å¦ä¸‹æ²‰ while left < heapSize : # 1. æ±‚å·¦å³å­©å­æœ€å¤§çš„ä¸‹æ ‡ largest = left + 1 if ( left + 1 ) < heapSize and arr [ left+1 ] > arr [ left ] else left # 2. æœ€å¤§å­©å­å’Œæœ¬ç»“ç‚¹æœ€å¤§çš„ä¸‹æ ‡ largest = index if arr [ index ] >= arr [ largest ] else largest # 3. å¦‚æœæœ€å¤§çš„ç»“ç‚¹å°±æ˜¯è‡ªèº« ï¼Œ heapifyå®Œæˆè·³å‡º if largest == index : break # 4. å¦åˆ™ ï¼Œ äº¤æ¢ä¸‹æ²‰ arr [ largest ] , arr [ index ] = arr [ index ] , arr [ largest ] index = largest left = 2 * index + 1 å †æ’åº å †å¤§å°ï¼šheapSize = len(arr) æ•°ç»„æœ€åä¸€ä¸ªæ•°ä¸‹æ ‡ï¼šheapSize -= 1 æŠŠæ•°ç»„ arr åˆ›å»ºä¸ºå¤§æ ¹å † å †é¡¶ arr[0] ä¸æ•°ç»„æœ€åä¸€ä¸ªæ•° arr[heapSize] äº¤æ¢ å°†å †çš„å¤§å°ç¼©å° heapSize -= 1 0~heapSize åš heapify è‡³ 2 å¾ªç¯ï¼Œç›´åˆ°å †å¤§å°å‡åˆ°0ï¼Œæ•°ç»„æœ‰åº def heapSort ( arr ) : createHeap ( arr ) heapSize = len ( arr ) while heapSize > 1 : heapSize -= 1 arr [ 0 ] , arr [ heapSize ] = arr [ heapSize ] , arr [ 0 ] heapify ( arr , 0 , heapSize ) BFS & DFS BFS def bfs ( graph , start , end ) : queue = [] queue . append ( [ start ] ) visted . add ( start ) while queue : node = queue . pop () # æ ‡è®°å·²è¢«è®¿é—® visted . add ( node ) process ( node ) # 1. å¯»æ‰¾åç»§ç»“ç‚¹ 2. æ£€æŸ¥åç»§ç»“ç‚¹æ˜¯å¦è¢«è®¿é—® nodes = generate_related_nodes ( node ) queue . push ( nodes ) # other process work .... DFS # Recursion visted = set () def dfs ( node , visted ) : visted . add ( node ) # process current node here ... for next_node in node . children () : if next_node not in visted : dfs ( next_node , visted ) # Non - Recursion def dfs ( tree ) : if not tree . root : return None visted , stack = [], [ tree . root ] while stack : node = stack . pop () visted . add ( node ) process ( node ) nodes = generate_related_node ( node ) stack . push ( nodes ) # other processing work ... Recursion ç”¨ç›¸åŒçš„æ–¹æ³•è§£å†³è§„æ¨¡ä¸åŒçš„ç›¸åŒé—®é¢˜ã€‚ ç›¸åŒçš„æ–¹æ³•ï¼šå‡½æ•° é—®é¢˜çš„è§„æ¨¡ï¼š å‡½æ•°å‚æ•°æ§åˆ¶ é€’å½’æ˜¯ä¸€ç§ç‰¹æ®Šçš„å¾ªç¯ï¼Œé€šè¿‡ å‡½æ•°ä½“ å¾ªç¯ã€‚ factorial(6): 6 * factorial(5) 6 * (5 * factorial(4)) 6 * (5 * (4 * factorial(3))) 6 * (5 * (4 * (3 * factorial(2)))) 6 * (5 * (4 * (3 * ( 2 * factorial(1))))) 6 * (5 * (4 * (3 * ( 2 * 1)))) 6 * (5 * (4 * (3 * 2))) 6 * (5 * (4 * 6)) 6 * (5 * 24) 6 * 120 720 æŠŠé—®é¢˜è½¬åŒ–ä¸ºè§„æ¨¡ç¼©å°äº†çš„åŒç±»å­é—®é¢˜ æœ‰æ˜ç¡®çš„ä¸éœ€è¦ç»§ç»­è¿›è¡Œé€’å½’çš„æ¡ä»¶ï¼ˆbase caseï¼‰ Template def recursion ( level , param1 , param2 , ... ) : # recursion terminator if level > MAX_LEVEL : print_result return # process logic in current level process_data ( level , data ... ) # drill down self . recursion ( level + 1 , p1 , p2 , ... ) # reverse the current level status if needed reverse_state ( level ) Example: Divide and Conquer é€’å½’çš„é«˜é˜¶ç®—æ³•åº”ç”¨ï¼šåˆ†æ²» Template def divide_conquer ( problem , param1 , param2 , ... ) : # recursion terminator if problem is None : print_result return # prepare data data = prepare_data ( problem ) subproblem = split_problem ( problem , data ) # conquer subproblem subresult1 = self . divide_conquer ( problem [ 0 ], p1 , p2 , ... ) subresult2 = self . divide_conquer ( problem [ 1 ], p1 , p2 , ... ) subresult3 = self . divide_conquer ( problem [ 2 ], p1 , p2 , ... ) ... # process and generate the final result result = process_result ( subresult1 , subresult2 , subresult3 , ... ) Example: 23. Merge k Sorted Lists Dynamic Programming æ‰€æœ‰çš„åŠ¨æ€è§„åˆ’éƒ½æ˜¯ç”±æš´åŠ›é€’å½’ä¼˜åŒ–è€Œæ¥ åŠ¨æ€è§„åˆ’æ˜¯ä¸€ç§åˆ†é˜¶æ®µæ±‚è§£å†³ç­–é—®é¢˜çš„æ•°å­¦æ€æƒ³ã€‚ ä¸‰ä¸ªé‡è¦çš„æ¦‚å¿µï¼š çŠ¶æ€ ï¼ˆæœ€ä¼˜å­ç»“æ„ï¼‰ã€ é€’æ¨æ–¹ç¨‹ ã€ è¾¹ç•Œ ã€‚ åŠ¨æ€è§„åˆ’åˆ©ç”¨ è‡ªåº•å‘ä¸Šçš„é€’æ¨ æ–¹å¼ï¼Œå®ç°æ—¶é—´å’Œç©ºé—´ä¸Šçš„æœ€ä¼˜åŒ–ã€‚ é€’å½’å±•å¼€è¿‡ç¨‹ä¸­å­˜åœ¨é‡å¤çŠ¶æ€ï¼Œå³é‡å å­é—®é¢˜ é‡å¤çŠ¶æ€æ— åæ•ˆæ€§ï¼šä¸åˆ°è¾¾è¿™ä¸ªçŠ¶æ€çš„è·¯å¾„æ— å…³ï¼Œå³åªè¦è¿™ä¸ªçŠ¶æ€å‚æ•°ç¡®å®šï¼Œåˆ™è¿”å›å€¼ç¡®å®šã€‚ æš´åŠ›é€’å½’åˆ°åŠ¨æ€è§„åˆ’çš„è§£æ³•ï¼š 1. æ‰¾å‡ºéœ€è¦æ±‚è§£çš„ çŠ¶æ€ä½ç½® 2. å›åˆ°Base caseä¸­è®¾ç½®ä¸è¢«ä¾èµ–çš„ è¾¹ç•ŒçŠ¶æ€ 3. åˆ†æ æ™®éçŠ¶æ€ å¦‚ä½•ä¾èµ– Example: One-dimensional DP 70. Climbing Stairs Two-dimensional DP 64. Minimum Path Sum 120. Triangle æ›´æ–°ä¸­â€¦","tags":"Algorithms","url":"articles/Data-Structure-and-Algorithm-in-Python.html","loc":"articles/Data-Structure-and-Algorithm-in-Python.html"},{"title":"Hexo blog sync and migration","text":"Overview Deploy env files to github Env building in a new computer Sync operation on two computers Overview HEXO â”œâ”€â”€.deploy_git/ â”œâ”€â”€node_modules/ â”œâ”€â”€public/ â”œâ”€â”€scaffolds/ â”œâ”€â”€source/ â”œâ”€â”€themes/ â”œâ”€â”€_config.yml â”œâ”€â”€.gitignore â”œâ”€â”€db.json â”œâ”€â”€debug.log â””â”€â”€package.json .deploy_git which same as public/ : hexo g -d â€”-> username.github.io static files : deploy github env files : local Deploy env files to github The env files is deployed to github and does not affect the hosting of static files . 1. Create a new hexo branch on gituhb web, and set it as the default branch to store the env files . 2. git clone hexo-branch 3. cd username.github.io & remove all files except â€˜.git/' 4. git add -A 5. git commit -m \"comment\" 6. git push origin hexo (hexo branch have been cleared.) 7. copy .git/ to Hexo/ ( Now, the hexo project has become a local repository associated with the remote hexo branch. ) git add . & git commit -m \"some description\" & git push origin hexo : push env files to hexo branch. hexo g -d : deploy web & push static files to master branch. Env building in a new computer install hexo: npm install -g hexo-cli git clone git@github.com:username/username.github.io.git npm install hexo g & hexo s http://localhost:4000/ Sync operation on two computers git pull origin hexo When have written blog, first commit env files, then deploy blog. - git add . - git commit -m \"comment\" - git push origin hexo - hexo g -d","tags":"Tools","url":"articles/Hexo-blog-sync-and-migration.html","loc":"articles/Hexo-blog-sync-and-migration.html"},{"title":"Leetcode Index","text":"1. Two Sum 2. Add Two Numbers 4. Median of Two Sorted Arrays 5. Longest Palindromic Substring 8. String to Integer (atoi) 13. Roman to Integer 15. 3Sum 20. Valid Parentheses 21. Merge Two Sorted Lists 23. Merge k Sorted Lists 24. Swap Nodes in Pairs 25. Reverse Nodes in k-Group 26. Remove Duplicates from Sorted Array 28. Implement strStr() 33. Search in Rotated Sorted Array 46. Permutations 47. Permutations II 48. Rotate Image 53. Maximum Subarray 54. Spiral Matrix 55. Jump Game 56. Merge Intervals 71. Simplify Path 73. Set Matrix Zeroes 75. Sort Colors 79. Word Search 88. Merge Sorted Array 91. Decode Ways 94. Binary Tree Inorder Traversal 98. Validate Binary Search Tree 101. Symmetric Tree 102. Binary Tree Level Order Traversal 103. Binary Tree Zigzag Level Order Traversal 106. Construct Binary Tree from Inorder and Postorder Traversal 112. Path Sum 114. Flatten Binary Tree to Linked List 116. Populating Next Right Pointers in Each Node 117. Populating Next Right Pointers in Each Node II 121. Best Time to Buy and Sell Stock 124. Binary Tree Maximum Path Sum 125. Valid Palindrome 138. Copy List with Random Pointer 141. Linked List Cycle 146. LRU Cache 151. Reverse Words in a String 153. Find Minimum in Rotated Sorted Array 160. Intersection of Two Linked Lists 162. Find Peak Element 165. Compare Version Numbers 168. Excel Sheet Column Title 171. Excel Sheet Column Number 173. Binary Search Tree Iterator 174. Dungeon Game 186. Reverse Words in a String II 189. Rotate Array 191. Number of 1 Bits 200. Number of Islands 204. Count Primes 206. Reverse Linked List 208. Implement Trie (Prefix Tree) 212. Word Search II 213. House Robber II 215. Kth Largest Element in an Array 218. The Skyline Problem 232. Implement Queue using Stacks 235. Lowest Common Ancestor of a Binary Search Tree 236. Lowest Common Ancestor of a Binary Tree 237. Delete Node in a Linked List 238. Product of Array Except Self 258. Add Digits 268. Missing Number 270. Closest Binary Search Tree Value 273. Integer to English Words 285. Inorder Successor in BST 297. Serialize and Deserialize Binary Tree 300. Longest Increasing Subsequence 333. Largest BST Subtree 348. Design Tic-Tac-Toe 365. Water and Jug Problem 387. First Unique Character in a String 419. Battleships in a Board 445. Add Two Numbers II 452. Minimum Number of Arrows to Burst Balloons 513. Find Bottom Left Tree Value 567. Permutation in String 591. Tag Validator 631. Design Excel Sum Formula 642. Design Search Autocomplete System 650. 2 Keys Keyboard 651. 4 Keys Keyboard 654. Maximum Binary Tree 672. Bulb Switcher II","tags":"Algorithms","url":"articles/Leetcode-Index.html","loc":"articles/Leetcode-Index.html"},{"title":"Vim","text":"Install vim ~/.vimrc Vimçš„è®¾è®¡å“²å­¦ windows â€˜\\r\\n' to linux â€˜\\n' æ›¿æ¢ Install vim apt install libncurses5 - dev git clone git @github . com : vim / vim . git cd vim # YouCompleteMe unavailable : requires Vim compiled with Python ( 3.6.0 + ) support . . / configure -- enable - pythoninterp = yes -- enable - cscope -- enable - fontset -- with - python3 - config - dir =/ opt / conda / envs / blog / lib / python3 .8 / config - 3.8 - x86_64 - linux - gnu -- enable - python3interp = yes -- with - python3 - command = python3 .8 make make install ~/.vimrc https://github.com/jerrylsu/vimrc Install Pluge curl -fLo ~/.vim/autoload/plug.vim --create-dirs https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim vim :PlugeInstall Uninstall Pluge \" æ³¨é‡Š .vimrcä¸­çš„æ’ä»¶ï¼Œ:source ~/.vimrc :PlugeClean Vimçš„è®¾è®¡å“²å­¦ operation æ“ä½œ: d, delete c, change y motion åŠ¨ä½œ: w, word b, back f, findæŸ¥æ‰¾å…‰æ ‡åçš„å­—ç¬¦(:å†’å·ï¼Œå­—æ¯a)å¹¶è·³è½¬ï¼Œ f: , fa å¸¸ç”¨ç»„åˆï¼š cw, change word åˆ é™¤ä¸€ä¸ªè¯ï¼ˆåˆ é™¤å…‰æ ‡ä»¥åçš„è¯ï¼‰ï¼Œå¹¶è¿›å…¥å†™æ¨¡å¼ã€‚ ciw, change in word åˆ é™¤ä¸€ä¸ªè¯ï¼ˆå…‰æ ‡åœ¨è¯ä¸­ï¼‰ï¼Œå¹¶è¿›å…¥å†™æ¨¡å¼ã€‚ i æ˜¯æ’å…¥ï¼Œå¦‚æœåšäº†æ˜ å°„ noremap f i ï¼Œåˆ™ cfw ci\", change in \" åˆ é™¤æŸç§ç¬¦å·ï¼ˆå¦‚åŒå¼•å·\"ï¼‰ä¹‹é—´çš„æ‰€æœ‰å†…å®¹ï¼Œå¹¶è¿›å…¥å†™æ¨¡å¼ã€‚ dw, diw, di\", yw, yiw, yi\" åŒç† df:, cf:, yf: windows â€˜\\r\\n' to linux â€˜\\n' vim filename && set ff=unix æ›¿æ¢ :s/from/to/g https://www.cnblogs.com/wind-wang/p/5768000.html","tags":"Tools","url":"articles/Vim.html","loc":"articles/Vim.html"},{"title":"Building Python Package with Pybuilder","text":"Building Python Package Building Python Package git + venv + pybuilder [1] virtualenv user guide [2] å»–é›ªå³°-virtualenv [3] pybuilder tutorial [4] Managing Your Python Project with Git and PyBuilder [5] examples How to add non-python file into a distribution? [1] Install additional files [2] doc ä½¿ç”¨ project.install_file(target, source) å®‰è£…épythonæ–‡ä»¶ã€‚ target path ï¼šå¯ä»¥æ˜¯ç»å¯¹è·¯å¾„ï¼Œä¹Ÿå¯ä»¥æ˜¯ç›¸å¯¹äºå®‰è£…å‰ç¼€( /usr/ on most linux systems)ã€‚ source path ï¼šå¿…é¡»æ˜¯ distribution directory ç›®å½•ã€‚å› ä¸ºé»˜è®¤æƒ…å†µä¸‹non-pythonæ–‡ä»¶æœªå¤åˆ¶åˆ°åˆ†å‘ç›®å½•ï¼Œå› æ­¤å¿…é¡»ä½¿ç”¨ copy_resources æ’ä»¶æ¥åŒ…å«å®ƒä»¬ã€‚ use_plugin ( \"copy_resources\" ) @init def initialize ( project ) : project . get_property ( \"copy_resources_glob\" ). append ( \"src/main/resources/my-config.yaml\" ) project . set_property ( \"copy_resources_target\" , \"$dir_dist\" ) project . install_file ( \"/etc/defaults\" , \"src/main/resources/my-config.yaml\" )","tags":"Programming","url":"articles/Building-Python-Package-with-Pybuilder.html","loc":"articles/Building-Python-Package-with-Pybuilder.html"},{"title":"Git","text":"1. ä»“åº“ç®¡ç† Create Repository Add File to Local Repository Associated Remote Repo(GitHub) Push GitHub Repository 2. åˆ†æ”¯ç®¡ç† åˆ›å»ºåˆ†æ”¯ åˆ‡æ¢åˆ†æ”¯ åˆ›å»ºå¹¶åˆ‡æ¢åˆ†æ”¯ æŸ¥çœ‹æ‰€æœ‰æœ¬åœ°åˆ†æ”¯ åˆå¹¶åˆ†æ”¯ åˆ é™¤æœ¬åœ°åˆ†æ”¯ åˆ é™¤è¿œç¨‹åˆ†æ”¯ è¿œç¨‹æ–°å»ºåˆ†æ”¯ Remove files/dir from git repo æ‹‰å–è¿œç¨‹åˆ†æ”¯ 3. åœ¨æäº¤æ ‘ä¸Šçš„ç§»åŠ¨ åˆ†ç¦»HEADæŒ‡é’ˆ ç›¸å¯¹å¼•ç”¨ å¼ºåˆ¶ä¿®æ”¹åˆ†æ”¯ä½ç½® 5. æ’¤é”€å˜æ›´ 6. æ•´ç†æäº¤åˆ†æ”¯ 4. æ¢å¤æœ¬åœ°commitæäº¤ å¯è§†åŒ–Learn Git Branching 1. ä»“åº“ç®¡ç† Create Repository $ mkdir myrepo $ cd myrepo $ git init Initialized empty Git repository in /Users/jerrylsu/myrepo/.git/ Add File to Local Repository $ git status $ git diff filename Check working directory status, and view changes made to the filemname. $ git add filename $ git commit -m \"write commend\" $ git commit --amend ä¿®æ”¹æœ€åä¸€æ¬¡æäº¤ï¼Œé¿å…æ–°å¼€ä¸€ä¸ªcommitæäº¤åˆ°historyï¼ Associated Remote Repo(GitHub) $ git remote add origin [SSH address] Note : origin is an alias for the remote repository address. Push GitHub Repository $ git push origin branch_name Now, we can push the latest changes to our local branch to the remote GitHub repository, which is associated above! 2. åˆ†æ”¯ç®¡ç† åˆ›å»ºåˆ†æ”¯ git branch branch_name åˆ‡æ¢åˆ†æ”¯ git checkout branch_name åˆ›å»ºå¹¶åˆ‡æ¢åˆ†æ”¯ git checkout -b branch_name æŸ¥çœ‹æ‰€æœ‰æœ¬åœ°åˆ†æ”¯ $ git branch åˆå¹¶åˆ†æ”¯ å°†å…¶ä»–åˆ†æ”¯branch_nameåˆå¹¶åˆ°å½“å‰åˆ†æ”¯ git merge branch_name å°†å½“å‰åˆ†æ”¯åˆå¹¶åˆ°å…¶ä»–åˆ†æ”¯branch_name,çº¿æ€§çš„ä¸²æ¥åˆ°åˆ†æ”¯branch_nameå git rebase branch_name åˆ é™¤æœ¬åœ°åˆ†æ”¯ git branch -d branch_name åˆ é™¤è¿œç¨‹åˆ†æ”¯ git branch -r -d origin/branch_name git push origin:branch_name ??? è¿œç¨‹æ–°å»ºåˆ†æ”¯ å°†æœ¬åœ°åˆ†æ”¯æ¨é€åˆ°è¿œç¨‹ä¸å­˜åœ¨çš„åˆ†æ”¯ï¼Œå®ç°è¿œç¨‹åˆ†æ”¯æ–°å»º git push origin local_branch:remote_branch Remove files/dir from git repo $ git rm --cached file.txt $ git rm -r --cached dir $ git commit -m \"remove file.txt\" And to push changes to remote repo $ git push origin branch_name æ‹‰å–è¿œç¨‹åˆ†æ”¯ å…ˆæ‹‰è¿œç¨‹masteråˆ†æ”¯ï¼š git clone ... æ‹‰å–è¿œç¨‹åˆ†æ”¯ï¼š git fetch origin remote_branch_name:local_branch_name æŸ¥çœ‹æ‹‰å–åˆ°æœ¬åœ°çš„åˆ†æ”¯ï¼š git checkout local_branch_name 3. åœ¨æäº¤æ ‘ä¸Šçš„ç§»åŠ¨ HEAD æ€»æ˜¯æŒ‡å‘å½“å‰åˆ†æ”¯ä¸Šæœ€è¿‘ä¸€æ¬¡æäº¤è®°å½•ã€‚å¤§å¤šæ•°ä¿®æ”¹æäº¤æ ‘çš„ Git å‘½ä»¤éƒ½æ˜¯ä»æ”¹å˜ HEAD çš„æŒ‡å‘å¼€å§‹çš„ã€‚ HEAD é€šå¸¸æƒ…å†µä¸‹æ˜¯æŒ‡å‘åˆ†æ”¯åçš„ã€‚åœ¨ä½ æäº¤æ—¶ï¼Œæ”¹å˜äº†åˆ†æ”¯çš„çŠ¶æ€ï¼Œè¿™ä¸€å˜åŒ–é€šè¿‡ HEAD å˜å¾—å¯è§ã€‚ åˆ†ç¦»HEADæŒ‡é’ˆ å¯ä»¥ç”¨åˆ‡æ¢åˆ†æ”¯çš„å‘½ä»¤æ¥åˆ‡æ¢åˆ°ç‰¹å®šä¸€æ¬¡çš„æäº¤ï¼Œæäº¤åæ˜¯å“ˆå¸Œå€¼commit_hashã€‚ git checkout commit_hash(fed2) HEADåˆ†ç¦»å¹¶æŒ‡å‘è¿™ä¸ªç‰¹å®šçš„æäº¤ git log è·å–æäº¤çš„å“ˆå¸Œå€¼ï¼Œä¾‹å¦‚fed2da64c0efc5293610bdd892f82a58e8cbc5d8ï¼Œå¦‚æœå¯ä»¥å”¯ä¸€æ ‡è¯†ï¼Œå–å‰ç¼€å³å¯fed2ã€‚ ç›¸å¯¹å¼•ç”¨ ç›¸å¯¹å¼•ç”¨æ›´æ–¹ä¾¿,ä½¿ç”¨ç›¸å¯¹å¼•ç”¨å¯ä»¥ä»ä¸€ä¸ªæ˜“äºè®°å¿†çš„åœ°æ–¹ï¼ˆæ¯”å¦‚ bugFix åˆ†æ”¯æˆ– HEAD ï¼‰å¼€å§‹è®¡ç®— ä½¿ç”¨ &#94; åé€€1ä¸ªæäº¤è®°å½•ï¼Œå¦‚ git checkout main&#94; æˆ– git checkout main&#94;&#94; ï¼ŒHEADæŒ‡å‘mainåˆ†æ”¯çš„çˆ¶èŠ‚ç‚¹å’Œçˆ¶çˆ¶èŠ‚ç‚¹ ä½¿ç”¨ ~<num> åé€€numæ­¥æäº¤è®°å½•ï¼Œå¦‚ ~3 ã€‚ ~ ä¸æ¥æ•°å­—ç­‰ä»·äº &#94; git checkout fed2 # åˆ†ç¦»HEADæŒ‡å‘fed2è¿™æ¬¡æäº¤ git checkout HEAD&#94; # HEADä¸Šç§» git checkout HEAD&#94; # HEADç»§ç»­ä¸Šç§» å¼ºåˆ¶ä¿®æ”¹åˆ†æ”¯ä½ç½® git branch -f main HEAD&#94;3/commit_hash 5. æ’¤é”€å˜æ›´ git reset commit_hash 6. æ•´ç†æäº¤åˆ†æ”¯ å°†commit_hash1ä¸commit_hash2ä¸¤æ¬¡æäº¤ä¸²æ¥åˆ°å½“å‰åˆ†æ”¯ä¸‹ï¼Œå½“å‰åˆ†æ”¯æŒ‡é’ˆç§»åŠ¨åˆ°ä¸²æ¥å¤´éƒ¨commit_hash2ã€‚ç±»ä¼¼äº git rebase git cherry-pick commit_hash1 commit_hash2 4. æ¢å¤æœ¬åœ°commitæäº¤ è·å–commit idï¼š git log æ¢å¤æœ¬åœ°commitæäº¤ï¼š git reset --hard commit_id gitå¸¸ç”¨","tags":"Tools","url":"articles/Git.html","loc":"articles/Git.html"},{"title":"Keeping a fork synced with the origin repo","text":"In the future, if you will modify code, you should pull the lastest upstream repo first ! (starting from step 5 above) 1. for k upstream_repo_url 2. git clone or igin_repo_url 3. git remote add upstream upstream_url 4. git remote -v 5. git pull upstream dev - git fetch upstream - git checkout dev - git merge upstream / dev 6. git checkout - b dev_01 ( modify code ... ) 7. git push or igin dev_01 8. pull request master: release dev: develop self-built branch: (as dev_01) In the future, if you will modify code, you should pull the lastest upstream repo first ! (starting from step 5 above)","tags":"Tools","url":"articles/Keeping-a-fork-synced-with-the-origin-repo.html","loc":"articles/Keeping-a-fork-synced-with-the-origin-repo.html"}]};